{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "from IPython.core.display import HTML \n",
    "Image(url= \"https://cdn.downtoearth.org.in/library/large/2020-03-01/0.01792700_1583044755_coronavirus-illustration-carousel.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COVID-19 Global Outlook: modelling, prediction and sentiment analysis \n",
    "\n",
    "In the context of the global COVID-19 pandemic, we follow the suggestions from Kaggle's competitions in order to provide useful insights about the virus' spread. Starting from a global exploratory analysis, then we focus on virus' modelling and prediction for the countries with the largest number of confirmed cases. For modelling, we implement SIR Model with some extensions and, for prediction, logistic and Gompertz model. At the end, we choose the best model based on R2 score, check the predictions' numbers about confirmed and fatalities for the next time interval and display some results from NLTK Sentiment analysis. \n",
    "\n",
    "Data: [COVID19 Global Forecasting](https://www.kaggle.com/c/covid19-global-forecasting-week-4)\n",
    "Consulted kernels: \n",
    "\n",
    "**TABLE OF CONTENTS**\n",
    "\n",
    "1. [Exploratory data analysis (EDA)](#section1)\n",
    "\n",
    "    1.1. [Worldwide Trend](#section11)\n",
    "    \n",
    "    1.2. [Country-Wise growth](#section12)\n",
    "    \n",
    "    1.3. [Zoom up to](#section13)\n",
    "    \n",
    "      1.3.1. [US](#section131)\n",
    "      \n",
    "      1.3.2. [Europe](#section132)\n",
    "      \n",
    "      1.3.3. [Asia](#section133)\n",
    "      \n",
    "    \n",
    "2. [Modelling](#section2)\n",
    "\n",
    "    2.1. [SIR model](#section21)\n",
    "    \n",
    "    2.2. [SIR-Model with Lockdown](#section22)\n",
    "    \n",
    "      2.2.1. [Fitting SIR with Lockdown to data](#section131)\n",
    "      \n",
    "    2.3. [SIR with time-dependent R_0 and CFR](#section21)\n",
    "    \n",
    "      2.3.1. [Fitting extended SIR to data](#section131)\n",
    "    \n",
    "    \n",
    "3. [Prediction](#section3)\n",
    "\n",
    "    3.1. [Logistic model](#section31)\n",
    "    \n",
    "    3.2. [Gompertz model](#section32)\n",
    "    \n",
    "    \n",
    "4. [NLTK Sentiment Analysis](#section4)\n",
    "\n",
    "    4.1. [Sentiment polarity](#section41)\n",
    "  \n",
    "    \n",
    "5. [Conclusions](#section5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_kg_hide-input": true,
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "\n",
    "# --- plotly ---\n",
    "from plotly import tools, subplots\n",
    "import plotly.offline as py\n",
    "py.init_notebook_mode(connected=True)\n",
    "import plotly.graph_objs as go\n",
    "import plotly.express as px\n",
    "import plotly.figure_factory as ff\n",
    "import plotly.io as pio\n",
    "pio.templates.default = \"plotly_white\"\n",
    "\n",
    "!pip install kaggle\n",
    "import kaggle\n",
    "\n",
    "kaggle competitions download -c covid19-global-forecasting-week-4\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting kaggle\n",
      "  Using cached https://files.pythonhosted.org/packages/62/ab/bb20f9b9e24f9a6250f95a432f8d9a7d745f8d24039d7a5a6eaadb7783ba/kaggle-1.5.6.tar.gz\n",
      "Requirement already satisfied: urllib3<1.25,>=1.21.1 in c:\\users\\marco dibuono\\anaconda3\\lib\\site-packages (from kaggle) (1.24.2)\n",
      "Requirement already satisfied: six>=1.10 in c:\\users\\marco dibuono\\anaconda3\\lib\\site-packages (from kaggle) (1.12.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\marco dibuono\\anaconda3\\lib\\site-packages (from kaggle) (2019.9.11)\n",
      "Requirement already satisfied: python-dateutil in c:\\users\\marco dibuono\\anaconda3\\lib\\site-packages (from kaggle) (2.8.0)\n",
      "Requirement already satisfied: requests in c:\\users\\marco dibuono\\anaconda3\\lib\\site-packages (from kaggle) (2.22.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\marco dibuono\\anaconda3\\lib\\site-packages (from kaggle) (4.36.1)\n",
      "Collecting python-slugify (from kaggle)\n",
      "  Using cached https://files.pythonhosted.org/packages/92/5f/7b84a0bba8a0fdd50c046f8b57dcf179dc16237ad33446079b7c484de04c/python-slugify-4.0.0.tar.gz\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in c:\\users\\marco dibuono\\anaconda3\\lib\\site-packages (from requests->kaggle) (2.8)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in c:\\users\\marco dibuono\\anaconda3\\lib\\site-packages (from requests->kaggle) (3.0.4)\n",
      "Collecting text-unidecode>=1.3 (from python-slugify->kaggle)\n",
      "  Using cached https://files.pythonhosted.org/packages/a6/a5/c0b6468d3824fe3fde30dbb5e1f687b291608f9473681bbf7dabbf5a87d7/text_unidecode-1.3-py2.py3-none-any.whl\n",
      "Building wheels for collected packages: kaggle, python-slugify\n",
      "  Building wheel for kaggle (setup.py): started\n",
      "  Building wheel for kaggle (setup.py): finished with status 'done'\n",
      "  Created wheel for kaggle: filename=kaggle-1.5.6-cp37-none-any.whl size=72864 sha256=3c9eadc06e9be4470d1a8115e60d40505524a4426fe3bd8485e3845a60462d5d\n",
      "  Stored in directory: C:\\Users\\Marco Dibuono\\AppData\\Local\\pip\\Cache\\wheels\\57\\4e\\e8\\bb28d035162fb8f17f8ca5d42c3230e284c6aa565b42b72674\n",
      "  Building wheel for python-slugify (setup.py): started\n",
      "  Building wheel for python-slugify (setup.py): finished with status 'done'\n",
      "  Created wheel for python-slugify: filename=python_slugify-4.0.0-py2.py3-none-any.whl size=5493 sha256=450a184ae1a92a5fbfeefaf0ce72cf2c438663fb9017032d8fdeca35a08067b2\n",
      "  Stored in directory: C:\\Users\\Marco Dibuono\\AppData\\Local\\pip\\Cache\\wheels\\11\\94\\81\\312969455540cb0e6a773e5d68a73c14128bfdfd4a7969bb4f\n",
      "Successfully built kaggle python-slugify\n",
      "Installing collected packages: text-unidecode, python-slugify, kaggle\n",
      "Successfully installed kaggle-1.5.6 python-slugify-4.0.0 text-unidecode-1.3\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_kg_hide-input": true,
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File b'../input/covid19-global-forecasting-week-4/submission.csv' does not exist: b'../input/covid19-global-forecasting-week-4/submission.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-6db02efde5cc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0msubmission_example\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"../input/covid19-global-forecasting-week-4/submission.csv\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mtest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"../input/covid19-global-forecasting-week-4/test.csv\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mtrain\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"../input/covid19-global-forecasting-week-4/train.csv\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    683\u001b[0m         )\n\u001b[0;32m    684\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 685\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    686\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    687\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    455\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    456\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 457\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    458\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    459\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    893\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    894\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 895\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    896\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    897\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1133\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"c\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1134\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"c\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1135\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1136\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1137\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"python\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1915\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"usecols\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1916\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1917\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1918\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1919\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] File b'../input/covid19-global-forecasting-week-4/submission.csv' does not exist: b'../input/covid19-global-forecasting-week-4/submission.csv'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "train.rename({'Country_Region': 'country', 'Province_State': 'province', 'Id': 'id', 'Date': 'date', 'ConfirmedCases': 'confirmed', 'Fatalities': 'fatalities'}, axis=1, inplace=True)\n",
    "test.rename({'Country_Region': 'country', 'Province_State': 'province', 'Id': 'id', 'Date': 'date', 'ConfirmedCases': 'confirmed', 'Fatalities': 'fatalities'}, axis=1, inplace=True)\n",
    "train['country_province'] = train['country'].fillna('') + '/' + train['province'].fillna('')\n",
    "test['country_province'] = test['country'].fillna('') + '/' + test['province'].fillna('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **1. Exploratory data analysis (EDA)** <a id=\"section1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **1.1. Worldwide Trend** <a id=\"section11\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ww_df = train.groupby('date')[['confirmed', 'fatalities']].sum().reset_index()\n",
    "ww_df['new_case'] = ww_df['confirmed'] - ww_df['confirmed'].shift(1)\n",
    "ww_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ww_melt_df = pd.melt(ww_df, id_vars=['date'], value_vars=['confirmed', 'fatalities', 'new_case'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.line(ww_melt_df, x=\"date\", y=\"value\", color='variable', \n",
    "              title=\"Worldwide Confirmed/Death Cases Over Time\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.line(ww_melt_df, x=\"date\", y=\"value\", color='variable',\n",
    "              title=\"Worldwide Confirmed/Death Cases Over Time (Log scale)\",\n",
    "             log_y=True)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ww_df['mortality'] = ww_df['fatalities'] / ww_df['confirmed']\n",
    "\n",
    "fig = px.line(ww_df, x=\"date\", y=\"mortality\", \n",
    "              title=\"Worldwide Mortality Rate Over Time\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **1.2. Country-Wise growth** <a id=\"section12\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_df = train.groupby(['date', 'country'])[['confirmed', 'fatalities']].sum().reset_index()\n",
    "target_date = country_df['date'].max()\n",
    "\n",
    "print('Date: ', target_date)\n",
    "for i in [1, 10, 100, 1000, 10000]:\n",
    "    n_countries = len(country_df.query('(date == @target_date) & confirmed > @i'))\n",
    "    print(f'{n_countries} countries have more than {i} confirmed cases')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_country_df = country_df.query('(date == @target_date) & (confirmed > 1000)').sort_values('confirmed', ascending=False)\n",
    "top_country_df = top_country_df.iloc[0:7]\n",
    "top_country_melt_df = pd.melt(top_country_df, id_vars='country', value_vars=['confirmed', 'fatalities'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.bar(top_country_melt_df.iloc[::-1],\n",
    "             x='value', y='country', color='variable', barmode='group',\n",
    "             title=f'Confirmed Cases/Deaths on {target_date}', text='value', height=1500, orientation='h')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top10_countries = top_country_df.sort_values('confirmed', ascending=False).iloc[:10]['country'].unique()\n",
    "top10_countries_df = country_df[country_df['country'].isin(top10_countries)]\n",
    "fig = px.line(top10_countries_df,\n",
    "              x='date', y='confirmed', color='country',\n",
    "              title=f'Confirmed Cases for top 10 country as of {target_date}')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top10_countries = top_country_df.sort_values('fatalities', ascending=False).iloc[:10]['country'].unique()\n",
    "top10_countries_df = country_df[country_df['country'].isin(top10_countries)]\n",
    "fig = px.line(top10_countries_df,\n",
    "              x='date', y='fatalities', color='country',\n",
    "              title=f'Fatalities for top 10 country as of {target_date}')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_country_df = country_df.query('(date == @target_date) & (confirmed > 100)')\n",
    "top_country_df['mortality_rate'] = top_country_df['fatalities'] / top_country_df['confirmed']\n",
    "top_country_df = top_country_df.sort_values('mortality_rate', ascending=False)\n",
    "\n",
    "fig = px.bar(top_country_df[:15].iloc[::-1],\n",
    "             x='mortality_rate', y='country',\n",
    "             title=f'Mortality rate HIGH: top 15 countries on {target_date}', text='mortality_rate', height=800, orientation='h')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.bar(top_country_df[-15:],\n",
    "             x='mortality_rate', y='country',\n",
    "             title=f'Mortality rate LOW: top 15 countries on {target_date}', text='mortality_rate', height=800, orientation='h')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter_geo(country_df, locations=\"country\", locationmode='country names', \n",
    "                     color=\"confirmed\", size='confirmed', hover_name=\"country\", \n",
    "                     hover_data=['confirmed', 'fatalities'],\n",
    "                     range_color= [0, country_df['confirmed'].max()], \n",
    "                     projection=\"natural earth\", animation_frame=\"date\", \n",
    "                     title='COVID-19: Confirmed cases spread Over Time', color_continuous_scale=\"portland\")\n",
    "# fig.update(layout_coloraxis_showscale=False)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter_geo(country_df, locations=\"country\", locationmode='country names', \n",
    "                     color=\"fatalities\", size='fatalities', hover_name=\"country\", \n",
    "                     hover_data=['confirmed', 'fatalities'],\n",
    "                     range_color= [0, country_df['confirmed'].max()], \n",
    "                     projection=\"natural earth\", animation_frame=\"date\", \n",
    "                     title='COVID-19: Fatalities growth Over Time', color_continuous_scale=\"portland\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **1.3. Zoom up to** <a id=\"section13\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **1.3.1. US** <a id=\"section131\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "usa_state_code_df = pd.read_csv(\"../input/usa-state-code/usa_states2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data frame only for US. \n",
    "\n",
    "train_us = train.query('country == \"US\"')\n",
    "train_us['mortality_rate'] = train_us['fatalities'] / train_us['confirmed']\n",
    "\n",
    "# Convert province column to its 2-char code name,\n",
    "state_name_to_code = dict(zip(usa_state_code_df['state_name'], usa_state_code_df['state_code']))\n",
    "train_us['province_code'] = train_us['province'].map(state_name_to_code)\n",
    "\n",
    "# Only show latest days.\n",
    "train_us_latest = train_us.query('date == @target_date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.choropleth(train_us_latest, locations='province_code', locationmode=\"USA-states\",\n",
    "                    color='confirmed', scope=\"usa\", hover_data=['province', 'fatalities', 'mortality_rate'],\n",
    "                    title=f'Confirmed cases in US on {target_date}')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.choropleth(train_us_latest, locations='province_code', locationmode=\"USA-states\",\n",
    "                    color='mortality_rate', scope=\"usa\", hover_data=['province', 'fatalities', 'mortality_rate'],\n",
    "                    title=f'Mortality rate in US on {target_date}')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **1.3.2. Europe** <a id=\"section132\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "europe_country_list =list([\n",
    "    'Austria','Belgium','Bulgaria','Croatia','Cyprus','Czechia','Denmark','Estonia','Finland','France','Germany','Greece','Hungary','Ireland',\n",
    "    'Italy', 'Latvia','Luxembourg','Lithuania','Malta','Norway','Netherlands','Poland','Portugal','Romania','Slovakia','Slovenia',\n",
    "    'Spain', 'Sweden', 'United Kingdom', 'Iceland', 'Russia', 'Switzerland', 'Serbia', 'Ukraine', 'Belarus',\n",
    "    'Albania', 'Bosnia and Herzegovina', 'Kosovo', 'Moldova', 'Montenegro', 'North Macedonia'])\n",
    "\n",
    "country_df['date'] = pd.to_datetime(country_df['date'])\n",
    "train_europe = country_df[country_df['country'].isin(europe_country_list)]\n",
    "#train_europe['date_str'] = pd.to_datetime(train_europe['date'])\n",
    "train_europe_latest = train_europe.query('date == @target_date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.choropleth(train_europe_latest, locations=\"country\", \n",
    "                    locationmode='country names', color=\"confirmed\", \n",
    "                    hover_name=\"country\", range_color=[1, 100000], \n",
    "                    color_continuous_scale='portland', \n",
    "                    title=f'European Countries with Confirmed Cases as of {target_date}', scope='europe', height=500)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "europe_country_list =list([\n",
    "    'France','Germany',\n",
    "    'Italy', \n",
    "    'Spain','United Kingdom','Belgium','Netherlands',\"Austria\",\"Portugal\",\"Norway\"])\n",
    "\n",
    "country_df['date'] = pd.to_datetime(country_df['date'])\n",
    "train_europe = country_df[country_df['country'].isin(europe_country_list)]\n",
    "train_europe_march = train_europe.query('date > \"2020-03-01\"')\n",
    "fig = px.line(train_europe_march,\n",
    "              x='date', y='confirmed', color='country',\n",
    "              title=f'Confirmed cases by country in Europe, as of {target_date}')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.line(train_europe_march,\n",
    "              x='date', y='fatalities', color='country',\n",
    "              title=f'Fatalities by country in Europe, as of {target_date}')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_europe_march['prev_confirmed'] = train_europe_march.groupby('country')['confirmed'].shift(1)\n",
    "train_europe_march['new_case'] = train_europe_march['confirmed'] - train_europe_march['prev_confirmed']\n",
    "fig = px.line(train_europe_march,\n",
    "              x='date', y='new_case', color='country',\n",
    "              title=f'DAILY NEW Confirmed cases by country in Europe')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **1.3.3. Asia** <a id=\"section133\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_latest = country_df.query('date == @target_date')\n",
    "\n",
    "fig = px.choropleth(country_latest, locations=\"country\", \n",
    "                    locationmode='country names', color=\"confirmed\", \n",
    "                    hover_name=\"country\", range_color=[1, 50000], \n",
    "                    color_continuous_scale='portland', \n",
    "                    title=f'Asian Countries with Confirmed Cases as of {target_date}', scope='asia', height=800)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "china_df = train.query('country == \"China\"')\n",
    "china_df['prev_confirmed'] = china_df.groupby('country')['confirmed'].shift(1)\n",
    "china_df['new_case'] = china_df['confirmed'] - china_df['prev_confirmed']\n",
    "china_df.loc[china_df['new_case'] < 0, 'new_case'] = 0.\n",
    "fig = px.line(china_df,\n",
    "              x='date', y='new_case', color='province',\n",
    "              title=f'DAILY NEW Confirmed cases in China by province')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **2. Modelling** <a id=\"section2\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2.1. SIR Model** <a id=\"section21\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "import mpld3\n",
    "mpld3.enable_notebook()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have seen some general behavior of the virus in agregated data, for the country where the coronavirus was originated and for four other interesting countries. There's a lot of information to be extracted from this data; for example, we haven't analyzed the effects of long/lat of countries. However, since our main purpose is to develop a predective model in order to understand the key factors that impact the COVID-19 transmission, I'll move on to one of the most famous epidemiologic models: SIR. \n",
    "\n",
    "SIR is a simple model that considers a population that belongs to one of the following states:\n",
    "1. **Susceptible (S)**. The individual hasn't contracted the disease, but she can be infected due to transmisison from infected people\n",
    "2. **Infected (I)**. This person has contracted the disease\n",
    "3. **Recovered/Deceased (R)**. The disease may lead to one of two destinies: either the person survives, hence developing inmunity to the disease, or the person is deceased. \n",
    "\n",
    "<img src=\"https://www.lewuathe.com/assets/img/posts/2020-03-11-covid-19-dynamics-with-sir-model/sir.png\" width=\"500px\">\n",
    "Image by Kai Sasaki from [lewuathe.com](https://www.lewuathe.com/covid-19-dynamics-with-sir-model.html)\n",
    "\n",
    "There are many versions of this model, considering birth and death (SIRD with demography), with intermediate states, etc. However, since we are in the early stages of the COVID-19 expansion and our interest is focused in the short term, we will consider that people develops immunity (in the long term, immunity may be lost and the COVID-19 may come back within a certain seasonality like the common flu) and there is no transition from recovered to the remaining two states. With this, the differential equations that govern the system are:\n",
    "\n",
    "$$ {dS \\over dt} = - {\\beta S I \\over N} $$\n",
    "\n",
    "$$ {dI \\over dt} = {\\beta S I \\over N} - \\gamma I$$\n",
    "\n",
    "$$ {dR \\over dt} = \\gamma I$$\n",
    "\n",
    "Where $\\beta$ is the contagion rate of the pathogen and $\\gamma$ is the recovery rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_example = pd.read_csv(\"../input/covid19-global-forecasting-week-4/submission.csv\")\n",
    "test = pd.read_csv(\"../input/covid19-global-forecasting-week-4/test.csv\")\n",
    "train = pd.read_csv(\"../input/covid19-global-forecasting-week-4/train.csv\")\n",
    "\n",
    "train[\"Country_Region\"] = [country_name.replace(\"'\",\"\") for country_name in train[\"Country_Region\"]]\n",
    "train = train.groupby(['Country_Region', 'Date'], as_index=False)\n",
    "train = train.aggregate(np.sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.integrate import odeint\n",
    "\n",
    "# The SIR model differential equations.\n",
    "def deriv(y, t, N, beta, gamma):\n",
    "    S, I, R = y\n",
    "    dSdt = -beta * S * I / N\n",
    "    dIdt = beta * S * I / N - gamma * I\n",
    "    dRdt = gamma * I\n",
    "    return dSdt, dIdt, dRdt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now want to add *cumulative* Deaths $X$ to the model: $X(t) = \\textit{number of deaths from day 0 to day t}$ for $t\\geq 14$, else $0$. \n",
    "\n",
    "Recursively, the number of cumulative deaths on day $t$ is equal to the number of cumulative deaths on day $t-1$ (that's $=X(t-1)$) plus the number of newly infected 13 days prior multiplied with the case fatality rate $\\alpha$ (alpha) (I chose 13 days as that is reported as the average time from infection until death in [this study](https://wwwnc.cdc.gov/eid/article/26/6/20-0320_article)).\n",
    "\n",
    "Now, the number of newly infected 13 days prior (that's the people who can die on day $t$) is equal to the number of infected 14 days prior multiplied with the expected amount of people an infected person infects per day (that's $\\beta$). So the number of newly infected 13 days prior is $\\beta \\cdot I(t-14)$.\n",
    "\n",
    "Putting it all together: $X(t) = X(t-1) + \\alpha \\cdot \\beta \\cdot I(t-14)$.\n",
    "\n",
    "This is equal to the closed form formula $X(t) = \\alpha \\cdot \\beta \\cdot \\displaystyle \\sum_{i=0}^{t-14} I(i)$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SIR_model(N, D, R_0, CaseFatalityRate, max_days):\n",
    "    '''\n",
    "    N: total population\n",
    "    D, R_0, CaseFatalityRate: see texts above\n",
    "    '''\n",
    "    I0, R0 = 1, 0  # Initial number of infected and recovered individuals (1 infected, 0 recovered) [this R0 has nothing to do with the basic reproduction number R0]\n",
    "    S0 = N - I0 - R0 # Initial number of susceptible (everyone else)\n",
    "\n",
    "    gamma = 1.0 / D  # see texts above\n",
    "    beta = R_0 * gamma  # see texts above\n",
    "    alpha = CaseFatalityRate\n",
    "\n",
    "    t = np.linspace(0, max_days, max_days) # Grid of time points (in days)\n",
    "\n",
    "    # Initial conditions vector\n",
    "    y0 = S0, I0, R0\n",
    "    # Integrate the SIR equations over the time grid, t.\n",
    "    ret = odeint(deriv, y0, t, args=(N, beta, gamma))\n",
    "    S, I, R = ret.T\n",
    "\n",
    "    # Adding deaths (see text above)\n",
    "    X = np.zeros(max_days)\n",
    "    for day in range(13, max_days):\n",
    "        X[day] = sum(I[:day-13])\n",
    "    X = alpha * beta * X\n",
    "\n",
    "\n",
    "    # Plot the data on three separate curves for S(t), I(t) and R(t)\n",
    "    f, ax = plt.subplots(1,1,figsize=(10,4))\n",
    "    ax.plot(t, S, 'b', alpha=0.7, linewidth=2, label='Susceptible')\n",
    "    ax.plot(t, I, 'y', alpha=0.7, linewidth=2, label='Infected')\n",
    "    ax.plot(t, X, 'r', alpha=0.7, linewidth=2, label='Dead')\n",
    "    ax.plot(t, R, 'g', alpha=0.7, linewidth=2, label='Recovered')\n",
    "\n",
    "    ax.set_xlabel('Time (days)')\n",
    "    ax.title.set_text('SIR-Model. Total Population: ' + str(N) + \", Days Infectious: \" + str(D) + \", R_0: \" + str(R_0) + \", CFR: \" + str(CaseFatalityRate*100) + \"%\")\n",
    "    # ax.set_ylabel('Number (1000s)')\n",
    "    # ax.set_ylim(0,1.2)\n",
    "    ax.yaxis.set_tick_params(length=0)\n",
    "    ax.xaxis.set_tick_params(length=0)\n",
    "    ax.grid(b=True, which='major', c='w', lw=2, ls='-')\n",
    "    legend = ax.legend()\n",
    "    legend.get_frame().set_alpha(0.5)\n",
    "    for spine in ('top', 'right', 'bottom', 'left'):\n",
    "        ax.spines[spine].set_visible(False)\n",
    "    plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **2.2. SIR-Model with Lockdown** <a id=\"section22\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now want to find suitable parameters (Days infectious, R_0, CFR) for the SIR model\n",
    "\n",
    "As I said before, the number of confirmed cases is likely far off from the real number (as not the whole population is getting tested) and thus is not very useful to fit our data to a SIR-Model.\n",
    "\n",
    "So, we'll mainly use the number of deceased from the dataset to find parameters for the SIR model. What's important to note is that many countries implemented a *lockdown* that greatly reduces the basic reproduction number R_0; thus, we first tweak the model to allow for a second R_0_2 to come into effect on day L (for lockdown)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SIR_model_with_lockdown(N, D, R_0, CaseFatalityRate, max_days, L, R_0_2):\n",
    "    '''\n",
    "    N: total population\n",
    "    D, R_0, CaseFatalityRate, ...: see texts above\n",
    "    '''\n",
    "    # BEFORE LOCKDOWN (same code as first model)\n",
    "    I0, R0 = 1, 0  # Initial number of infected and recovered individuals (1 infected, 0 recovered) [this R0 has nothing to do with the basic reproduction number R0]\n",
    "    S0 = N - I0 - R0 # Initial number of susceptible (everyone else)\n",
    "\n",
    "    gamma = 1.0 / D  # see texts above\n",
    "    beta = R_0 * gamma  # see texts above\n",
    "    alpha = CaseFatalityRate\n",
    "\n",
    "    t = np.linspace(0, L, L)  # Grid of time points (in days)\n",
    "    \n",
    "    # Initial conditions vector\n",
    "    y0 = S0, I0, R0\n",
    "    # Integrate the SIR equations over the time grid, t.\n",
    "    ret = odeint(deriv, y0, t, args=(N, beta, gamma))\n",
    "    S, I, R = ret.T\n",
    "    \n",
    "    \n",
    "    # AFTER LOCKDOWN\n",
    "    I0_2, R0_2, S0_2 = I[-1], R[-1], S[-1]  # beginning of lockdown -> starting Infected/Susceptible/Recovered numbers are the numbers at the end of no-lockdown period\n",
    "\n",
    "    gamma = 1.0 / D  # same after lockdown\n",
    "    beta_2 = R_0_2 * gamma\n",
    "    alpha = CaseFatalityRate  # same after lockdown\n",
    "\n",
    "    t_2 = np.linspace(0, max_days - L + 1, max_days - L + 1)\n",
    "    \n",
    "    # Initial conditions vector\n",
    "    y0_2 = S0_2, I0_2, R0_2\n",
    "    # Integrate the SIR equations over the time grid, t.\n",
    "    ret_2 = odeint(deriv, y0_2, t_2, args=(N, beta_2, gamma))\n",
    "    S_2, I_2, R_2 = ret_2.T\n",
    "\n",
    "    \n",
    "    # COMBINING PERIODS\n",
    "    S_full = np.concatenate((S, S_2[1:]))\n",
    "    I_full = np.concatenate((I, I_2[1:]))\n",
    "    R_full = np.concatenate((R, R_2[1:]))\n",
    "    t_full = np.linspace(0, max_days, max_days)\n",
    "    \n",
    "    # Adding deaths\n",
    "    X = np.zeros(max_days)\n",
    "    for day in range(13, max_days):\n",
    "        for valid_day in range(day-13):\n",
    "            if valid_day < L:\n",
    "                X[day] += alpha * beta * I_full[valid_day]\n",
    "            else:\n",
    "                X[day] += alpha * beta_2 * I_full[valid_day]\n",
    "\n",
    "    \n",
    "\n",
    "    # Plot the data on three separate curves for S(t), I(t) and R(t)\n",
    "    f, ax = plt.subplots(1,1,figsize=(10,4))\n",
    "    ax.plot(t_full, S_full, 'b', alpha=0.7, linewidth=2, label='Susceptible')\n",
    "    ax.plot(t_full, I_full, 'y', alpha=0.7, linewidth=2, label='Infected')\n",
    "    ax.plot(t_full, X, 'r', alpha=0.7, linewidth=2, label='Dead')\n",
    "    ax.plot(t_full, R_full, 'g', alpha=0.7, linewidth=2, label='Recovered')\n",
    "\n",
    "    ax.set_xlabel('Time (days)')\n",
    "    ax.title.set_text('SIR-Model with Lockdown. Total Population: ' + str(N) + \n",
    "                      \", Days Infectious: \" + str(D) + \", R_0: \" + str(R_0) + \n",
    "                      \", CFR: \" + str(CaseFatalityRate*100) + \" R_0_2: \" + str(R_0_2) + \n",
    "                      \", L: \" + str(L) + \" days\")\n",
    "    # ax.set_ylabel('Number (1000s)')\n",
    "    # ax.set_ylim(0,1.2)\n",
    "    plt.text(L,N/20,'Lockdown')\n",
    "    plt.plot(L, 0, marker='o', markersize=6, color=\"red\")\n",
    "    ax.yaxis.set_tick_params(length=0)\n",
    "    ax.xaxis.set_tick_params(length=0)\n",
    "    ax.grid(b=True, which='major', c='w', lw=2, ls='-')\n",
    "    legend = ax.legend()\n",
    "    legend.get_frame().set_alpha(0.5)\n",
    "    for spine in ('top', 'right', 'bottom', 'left'):\n",
    "        ax.spines[spine].set_visible(False)\n",
    "    plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **2.3 Fitting SIR with Lockdown to data** <a id=\"section23\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now try to fit the SIR-Model's Dead Curve to real data by tweaking the variables. Some of them are constant:\n",
    "* max_days is set to len(train.groupby(\"Date\").sum().index) so that we can compare against all available data\n",
    "* N is fixed for each country, that's just the total population\n",
    "* L is fixed for each country (the date it went into lockdown)\n",
    "* D is set to vary from 5 to 20 (according to this study, it takes on avg. 5 days to show symptoms, at most 14; according to this source (German), people are infectious up to 5 days after onset of symptoms).\n",
    "* CFR set to vary from  0.1%−10% \n",
    "* R_0 and R_0_2 are set to vary from 0.1 to 3.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SIR_model_with_lockdown_deaths(x, N, D, R_0, CaseFatalityRate, max_days, L, R_0_2):\n",
    "    # BEFORE LOCKDOWN (same code as first model)\n",
    "    I0, R0 = 1, 0  # Initial number of infected and recovered individuals (1 infected, 0 recovered) [this R0 has nothing to do with the basic reproduction number R0]\n",
    "    S0 = N - I0 - R0 # Initial number of susceptible (everyone else)\n",
    "\n",
    "    gamma = 1.0 / D  # see texts above\n",
    "    beta = R_0 * gamma  # see texts above\n",
    "    alpha = CaseFatalityRate\n",
    "\n",
    "    t = np.linspace(0, L, L)  # Grid of time points (in days)\n",
    "    \n",
    "    # Initial conditions vector\n",
    "    y0 = S0, I0, R0\n",
    "    # Integrate the SIR equations over the time grid, t.\n",
    "    ret = odeint(deriv, y0, t, args=(N, beta, gamma))\n",
    "    S, I, R = ret.T\n",
    "    \n",
    "    \n",
    "    # AFTER LOCKDOWN\n",
    "    I0_2, R0_2, S0_2 = I[-1], R[-1], S[-1]  # beginning of lockdown -> starting Infected/Susceptible/Recovered numbers are the numbers at the end of no-lockdown period\n",
    "\n",
    "    gamma = 1.0 / D  # same after lockdown\n",
    "    beta_2 = R_0_2 * gamma\n",
    "    alpha = CaseFatalityRate  # same after lockdown\n",
    "\n",
    "    t_2 = np.linspace(0, max_days - L + 1, max_days - L + 1)\n",
    "    \n",
    "    # Initial conditions vector\n",
    "    y0_2 = S0_2, I0_2, R0_2\n",
    "    # Integrate the SIR equations over the time grid, t.\n",
    "    ret_2 = odeint(deriv, y0_2, t_2, args=(N, beta_2, gamma))\n",
    "    S_2, I_2, R_2 = ret_2.T\n",
    "\n",
    "    \n",
    "    # COMBINING PERIODS\n",
    "    S_full = np.concatenate((S, S_2[1:]))\n",
    "    I_full = np.concatenate((I, I_2[1:]))\n",
    "    R_full = np.concatenate((R, R_2[1:]))\n",
    "    t_full = np.linspace(0, max_days, max_days)\n",
    "    \n",
    "    # Adding deaths\n",
    "    X = np.zeros(max_days)\n",
    "    for day in range(13, max_days):\n",
    "        for valid_day in range(day-13):\n",
    "            if valid_day < L:\n",
    "                X[day] += alpha * beta * I_full[valid_day]\n",
    "            else:\n",
    "                X[day] += alpha * beta_2 * I_full[valid_day]\n",
    "    return X[x]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The (hidden as it's almost the same as before) code above defines a function with signature\n",
    "SIR_model_with_lockdown_deaths(x, N, D, R_0, CaseFatalityRate, max_days, L, R_0_2)\n",
    "that takes as input the same variables as before and an x and returns the number of fatalities on day x. This function will be used to find suited parameters D, CFR, R_0 and R_0_2 for the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install lmfit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lmfit import Model\n",
    "\n",
    "# Load countries data file (from https://www.kaggle.com/saga21/covid-global-forecast-sir-model-ml-regressions)\n",
    "world_population = pd.read_csv(\"../input/population-by-country-2020/population_by_country_2020.csv\")\n",
    "\n",
    "# Select desired columns and rename some of them\n",
    "world_population = world_population[['Country (or dependency)', 'Population (2020)', 'Density (P/Km²)', 'Land Area (Km²)', 'Med. Age', 'Urban Pop %']]\n",
    "world_population.columns = ['Country (or dependency)', 'Population (2020)', 'Density', 'Land Area', 'Med Age', 'Urban Pop']\n",
    "\n",
    "# Replace United States by US\n",
    "world_population.loc[world_population['Country (or dependency)']=='United States', 'Country (or dependency)'] = 'US'\n",
    "\n",
    "# Remove the % character from Urban Pop values\n",
    "world_population['Urban Pop'] = world_population['Urban Pop'].str.rstrip('%')\n",
    "\n",
    "# Replace Urban Pop and Med Age \"N.A\" by their respective modes, then transform to int\n",
    "world_population.loc[world_population['Urban Pop']=='N.A.', 'Urban Pop'] = int(world_population.loc[world_population['Urban Pop']!='N.A.', 'Urban Pop'].mode()[0])\n",
    "world_population['Urban Pop'] = world_population['Urban Pop'].astype('int16')\n",
    "world_population.loc[world_population['Med Age']=='N.A.', 'Med Age'] = int(world_population.loc[world_population['Med Age']!='N.A.', 'Med Age'].mode()[0])\n",
    "world_population['Med Age'] = world_population['Med Age'].astype('int16')\n",
    "\n",
    "world_population.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now define \n",
    "1. `fit_SIR`: this function takes a country name, lockdown data (and opt. region name) and first gathers the data (fatalities progression, population, etc.) and then fits the `SIR_model_with_lockdown_deaths`-function from above with fixed N (population), max_days (however many dates are supplied), L (lockdown date) and varying D, R_0, R_0_2, CFR. The function returns the lmfit-module's result object and the country name. The result object contains all we want to know about the curve fitting.\n",
    "2. `fitted_plot`: this function takes a lmfit-result-object and country name and plots the fitted SIR-model against the real curve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lockdown_dates = {\"Italy\": \"2020-03-10\", \"Spain\": \"2020-03-15\", \"US\": \"2020-03-20\", \"Germany\": \"2020-03-23\", \"France\": \"2020-03-17\", \"United Kingdom\":\"2020-03-23\", \"China\":\"2020-01-23\", \"Iran\":\"2020-03-25\"}\n",
    "\n",
    "def fit_SIR(country_name, lockdown_date=None):\n",
    "    \"\"\"\n",
    "    y_data: the fatalities data of one country/region (array)\n",
    "    population: total population of country\n",
    "    lockdown_date: format YYYY-MM-DD\n",
    "    \"\"\"\n",
    "    if lockdown_date is None:\n",
    "        lockdown_date = lockdown_dates[country_name]\n",
    "        \n",
    "    y_data = train[(train[\"Country_Region\"] == country_name)].Fatalities.values\n",
    "    max_days = len(train.groupby(\"Date\").sum().index) # constant for all countries\n",
    "\n",
    "    # country specific values\n",
    "    N = world_population.loc[world_population['Country (or dependency)'] == country_name][\"Population (2020)\"].values[0]\n",
    "    L = train.groupby(\"Date\").sum().index.tolist().index(lockdown_date)  # index of the lockdown date\n",
    "\n",
    "    # x_data is just [0, 1, ..., max_days] array\n",
    "    x_data = np.linspace(0, max_days - 1, max_days, dtype=int)\n",
    "    \n",
    "    # curve fitting from here\n",
    "    mod = Model(SIR_model_with_lockdown_deaths)\n",
    "\n",
    "    # initial values and bounds\n",
    "    mod.set_param_hint('N', value=N)\n",
    "    mod.set_param_hint('max_days', value=max_days)\n",
    "    mod.set_param_hint('L', value=L)\n",
    "    mod.set_param_hint('D', value=10, min=4, max=25)\n",
    "    mod.set_param_hint('CaseFatalityRate', value=0.01, min=0.0001, max=0.1)\n",
    "    mod.set_param_hint('R_0', value=2.0, min=0.1, max=5.0)\n",
    "    mod.set_param_hint('R_0_2', value=2.0, min=0.1, max=5.0)\n",
    "\n",
    "    params = mod.make_params()\n",
    "\n",
    "    # fixing constant parameters\n",
    "    params['N'].vary = False\n",
    "    params['max_days'].vary = False\n",
    "    params['L'].vary = False\n",
    "\n",
    "    result = mod.fit(y_data, params, x=x_data, method=\"least_squares\")\n",
    "    \n",
    "    return result, country_name\n",
    "\n",
    "def fitted_plot(result, country_name, region_name=None):\n",
    "    y_data = train[(train[\"Country_Region\"] == country_name)].Fatalities.values\n",
    "    max_days = len(train.groupby(\"Date\").sum().index) # constant for all countries\n",
    "    x_data = np.linspace(0, max_days - 1, max_days, dtype=int)\n",
    "    x_ticks = train[train[\"Country_Region\"] == \"Germany\"].Date.values  # same for all countries\n",
    "    \n",
    "    plt.figure(figsize=(10,5))\n",
    "    \n",
    "    real_data, = plt.plot(x_data, y_data, 'bo', label=\"real data\")\n",
    "    SIR_fit = plt.plot(x_data, result.best_fit, 'r-', label=\"SIR model\")\n",
    "    \n",
    "    plt.xlabel(\"Day\")\n",
    "    plt.xticks(x_data[::10], x_ticks[::10])\n",
    "    plt.ylabel(\"Fatalities\")\n",
    "    plt.title(\"Real Data vs SIR-Model in \" + country_name)\n",
    "    plt.legend(numpoints=1, loc=2, frameon=None)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result, _ = fit_SIR(\"Italy\")\n",
    "print(result.fit_report())\n",
    "fitted_plot(result, \"Italy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result, _ = fit_SIR(\"Spain\")\n",
    "print(result.fit_report())\n",
    "fitted_plot(result, \"Spain\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result, _ = fit_SIR(\"Germany\")\n",
    "print(result.fit_report())\n",
    "fitted_plot(result, \"Germany\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result, _ = fit_SIR(\"France\")\n",
    "print(result.fit_report())\n",
    "fitted_plot(result, \"France\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result, _ = fit_SIR(\"US\")\n",
    "print(result.fit_report())\n",
    "fitted_plot(result, \"US\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result, _ = fit_SIR(\"United Kingdom\")\n",
    "print(result.fit_report())\n",
    "fitted_plot(result, \"United Kingdom\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result, _ = fit_SIR(\"China\")\n",
    "print(result.fit_report())\n",
    "fitted_plot(result, \"China\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result, _ = fit_SIR(\"Iran\")\n",
    "print(result.fit_report())\n",
    "fitted_plot(result, \"Iran\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **2.4 SIR with time-dependent R_0 and CFR** <a id=\"section24\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While the prior models are able to capture some of the aspects of the virus quite well, it's not that hard to fit the curves to the outbreak period as they all look quite similar. To make better predictions, we now treat R_0 and CFR as functions. For example, there is no determined \"Lockdown\" date anymore at which R_0 jumps to a different value; it can now change continuously. Also, the CFR was until now treated as constant, however, with more people infected, treatment becomes less available and the case fatality rate increases. Now, CFR is treated as a function of the ratio $\\frac{I(t)}{N}$ (the fraction of infected of the total population):\n",
    "\n",
    "$CFR(t) = s \\cdot \\frac{I(t)}{N} + \\alpha_{OPT}$, with $s$ being some arbitrary but fixed scaling factor and $\\alpha_{OPT}$ being the CFR with optimal treatment available.\n",
    "\n",
    "$R_{0}$ will be fitted to one of several different possible distributions we'll look at."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extended_deriv(y, t, N, beta, gamma):\n",
    "    S, I, R = y\n",
    "    dSdt = -beta(t) * S * I / N\n",
    "    dIdt = beta(t) * S * I / N - gamma * I\n",
    "    dRdt = gamma * I\n",
    "    return dSdt, dIdt, dRdt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extended_SIR(N, D, max_days, CFR_OPT, CFR_scaling_factor, R_0, **R_0_kwargs):\n",
    "    '''\n",
    "    R_0: callable\n",
    "    '''\n",
    "    I0, R0 = 1, 0  # Initial number of infected and recovered individuals (1 infected, 0 recovered) [this R0 has nothing to do with the basic reproduction number R0]\n",
    "    S0 = N - I0 - R0 # Initial number of susceptible (everyone else)\n",
    "\n",
    "    gamma = 1.0 / D  # see texts above\n",
    "\n",
    "    def beta(t):\n",
    "        return R_0(t, **R_0_kwargs) * gamma\n",
    "\n",
    "    t = np.linspace(0, max_days, max_days)  # Grid of time points (in days)\n",
    "    \n",
    "    # Initial conditions vector\n",
    "    y0 = S0, I0, R0\n",
    "    # Integrate the SIR equations over the time grid, t.\n",
    "    ret = odeint(extended_deriv, y0, t, args=(N, beta, gamma))\n",
    "    S, I, R = ret.T\n",
    "\n",
    "    def CFR(t):\n",
    "        return CFR_OPT + CFR_scaling_factor * (I[t] / N)\n",
    "\n",
    "    # Adding deaths\n",
    "    X = np.zeros(max_days)\n",
    "    for day in range(13, max_days):\n",
    "        for valid_day in range(day-13):\n",
    "            X[day] += CFR(valid_day) * beta(valid_day) * I[valid_day]\n",
    "\n",
    "    return t, S, I, R, X, [R_0(t, **R_0_kwargs) for t in range(max_days)], N, [CFR(t) for t in range(max_days)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_extended_SIR(t, S, I, R, X, R_0, N, CFR):\n",
    "    # Plot the data on three separate curves for S(t), I(t) and R(t)\n",
    "    f, ax = plt.subplots(1,1,figsize=(10,4))\n",
    "    ax.plot(t, S, 'b', alpha=0.7, linewidth=2, label='Susceptible')\n",
    "    ax.plot(t, I, 'y', alpha=0.7, linewidth=2, label='Infected')\n",
    "    ax.plot(t, X, 'r', alpha=0.7, linewidth=2, label='Dead')\n",
    "    ax.plot(t, R, 'g', alpha=0.7, linewidth=2, label='Recovered')\n",
    "\n",
    "    ax.set_xlabel('Time (days)')\n",
    "    ax.title.set_text('SIR-Model with varying R_0 and CFR')\n",
    "    # ax.set_ylabel('Number (1000s)')\n",
    "    # ax.set_ylim(0,1.2)\n",
    "    ax.yaxis.set_tick_params(length=0)\n",
    "    ax.xaxis.set_tick_params(length=0)\n",
    "    ax.grid(b=True, which='major', c='w', lw=2, ls='-')\n",
    "    legend = ax.legend()\n",
    "    legend.get_frame().set_alpha(0.5)\n",
    "    for spine in ('top', 'right', 'bottom', 'left'):\n",
    "        ax.spines[spine].set_visible(False)\n",
    "    plt.show();\n",
    "    \n",
    "    \n",
    "    # plt.figure(figsize=(10,4))\n",
    "    \n",
    "    f = plt.figure(figsize=(10,4))\n",
    "    \n",
    "    # sp1\n",
    "    ax1 = f.add_subplot(121)\n",
    "    ax1.plot(t, R_0, 'b--', alpha=0.7, linewidth=2, label='R_0')\n",
    "    \n",
    "    ax1.set_xlabel('Time (days)')\n",
    "    ax1.title.set_text('R_0 over time')\n",
    "    # ax.set_ylabel('Number (1000s)')\n",
    "    # ax.set_ylim(0,1.2)\n",
    "    ax1.yaxis.set_tick_params(length=0)\n",
    "    ax1.xaxis.set_tick_params(length=0)\n",
    "    ax1.grid(b=True, which='major', c='w', lw=2, ls='-')\n",
    "    legend = ax1.legend()\n",
    "    legend.get_frame().set_alpha(0.5)\n",
    "    for spine in ('top', 'right', 'bottom', 'left'):\n",
    "        ax.spines[spine].set_visible(False)\n",
    "\n",
    "    # sp2\n",
    "    ax2 = f.add_subplot(122)\n",
    "    ax2.plot(t, CFR, 'r--', alpha=0.7, linewidth=2, label='CFR')\n",
    "    \n",
    "    ax2.set_xlabel('Time (days)')\n",
    "    ax2.title.set_text('CFR over time')\n",
    "    # ax.set_ylabel('Number (1000s)')\n",
    "    # ax.set_ylim(0,1.2)\n",
    "    ax2.yaxis.set_tick_params(length=0)\n",
    "    ax2.xaxis.set_tick_params(length=0)\n",
    "    ax2.grid(b=True, which='major', c='w', lw=2, ls='-')\n",
    "    legend = ax2.legend()\n",
    "    legend.get_frame().set_alpha(0.5)\n",
    "    for spine in ('top', 'right', 'bottom', 'left'):\n",
    "        ax.spines[spine].set_visible(False)\n",
    "\n",
    "    plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 1_000\n",
    "D = 4\n",
    "max_days = 100\n",
    "\n",
    "I0, R0 = 1, 0\n",
    "S0 = N - I0 - R0\n",
    "s = CFR_scaling_factor = 0.1\n",
    "CFR_OPT = 0.02  # noone in hospital -> only 2% die\n",
    "\n",
    "def new_R0(t, a, b, c):\n",
    "    return a / (1 + (t/c)**b)\n",
    "\n",
    "\n",
    "plot_extended_SIR(*extended_SIR(N, D, max_days, CFR_OPT, CFR_scaling_factor, new_R0, a=3.0, b=1.5, c=50))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2.4.1. Fitting extended SIR to data** <a id=\"section241\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_extended_SIR(country_name, R_0_function, region_name=None, fit_method=\"least_squares\", **R_0_kwargs):\n",
    "\n",
    "    y_data = train[(train[\"Country_Region\"] == country_name)].Fatalities.values\n",
    "    max_days = len(train.groupby(\"Date\").sum().index) # constant for all countries\n",
    "    # country specific values\n",
    "    N = world_population.loc[world_population['Country (or dependency)'] == country_name][\"Population (2020)\"].values[0]\n",
    "\n",
    "    # x_data is just [0, 1, ..., max_days] array\n",
    "    x_data = np.linspace(0, max_days - 1, max_days, dtype=int)\n",
    "\n",
    "    # curve fitting from here\n",
    "    def extended_SIR_deaths(x, N, D, max_days, CFR_OPT, CFR_scaling_factor, **R_0_kwargs):\n",
    "        t_, S_, I_, R_, X, R_0_, N_, CFR_ = extended_SIR(N, D, max_days, CFR_OPT, CFR_scaling_factor, R_0=R_0_function, **R_0_kwargs)\n",
    "        return X[x]\n",
    "\n",
    "    mod = Model(extended_SIR_deaths)\n",
    "\n",
    "    # initial values and bounds\n",
    "    mod.set_param_hint('N', value=N, vary=False)\n",
    "    mod.set_param_hint('max_days', value=max_days, vary=False)\n",
    "\n",
    "    mod.set_param_hint('D', value=10, min=4, max=25)\n",
    "    mod.set_param_hint('CFR_OPT', value=0.01, min=0.0001, max=0.1)\n",
    "    mod.set_param_hint('CFR_scaling_factor', value=0.1, min=0.0001, max=1.0)\n",
    "    if R_0_kwargs:\n",
    "        for arg in R_0_kwargs:\n",
    "            mod.set_param_hint(arg, value=R_0_kwargs[arg])\n",
    "\n",
    "    params = mod.make_params()\n",
    "    # print(params)\n",
    "    result = mod.fit(y_data, params, method=fit_method, x=x_data)\n",
    "    \n",
    "    # fetch some result parameters\n",
    "    CFR_OPT = result.params[\"CFR_OPT\"].value\n",
    "    CFR_scaling_factor = result.params[\"CFR_scaling_factor\"].value\n",
    "    R_0_result_params = {}\n",
    "    for val in R_0_kwargs:\n",
    "        R_0_result_params[val] = result.params[val].value\n",
    "\n",
    "    \n",
    "    # return result, country_name\n",
    "    return result, country_name, N, D, max_days, CFR_OPT, CFR_scaling_factor, R_0_function, R_0_result_params\n",
    "\n",
    "def fitted_plot_extended(result, country_name, region_name=None):\n",
    "    y_data = train[(train[\"Country_Region\"] == country_name)].Fatalities.values\n",
    "    max_days = len(train.groupby(\"Date\").sum().index) # constant for all countries\n",
    "    x_data = np.linspace(0, max_days - 1, max_days, dtype=int)\n",
    "    x_ticks = train[train[\"Country_Region\"] == \"Germany\"].Date.values  # same for all countries\n",
    "    \n",
    "    plt.figure(figsize=(10,5))\n",
    "    \n",
    "    real_data, = plt.plot(x_data, y_data, 'bo', label=\"real data\")\n",
    "    SIR_fit = plt.plot(x_data, result.best_fit, 'r-', label=\"SIR model\")\n",
    "    \n",
    "    plt.xlabel(\"Day\")\n",
    "    plt.xticks(x_data[::10], x_ticks[::10])\n",
    "    plt.ylabel(\"Fatalities\")\n",
    "    plt.title(\"Real Data vs SIR-Model in \" + country_name)\n",
    "    plt.legend(numpoints=1, loc=2, frameon=None)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_R0(t, a, b, c):\n",
    "    return a / (1 + (t/c)**b)\n",
    "\n",
    "result, country_name, N, D, max_days, CFR_OPT, CFR_scaling_factor, R_0_function, R_0_result_params = fit_extended_SIR(\"Italy\", new_R0, region_name=None, fit_method=\"least_squares\", a=3.0, b=1.5, c=50)\n",
    "print(result.fit_report())\n",
    "fitted_plot(result, \"Italy\");\n",
    "plot_extended_SIR(*extended_SIR(N, D, max_days, CFR_OPT, CFR_scaling_factor, R_0_function, **R_0_result_params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_R0(t, a, b, c):\n",
    "    return a / (1 + (t/c)**b)\n",
    "\n",
    "result, country_name, N, D, max_days, CFR_OPT, CFR_scaling_factor, R_0_function, R_0_result_params = fit_extended_SIR(\"Spain\", new_R0, region_name=None, fit_method=\"least_squares\", a=3.0, b=1.5, c=50)\n",
    "print(result.fit_report())\n",
    "fitted_plot(result, \"Spain\");\n",
    "plot_extended_SIR(*extended_SIR(N, D, max_days, CFR_OPT, CFR_scaling_factor, R_0_function, **R_0_result_params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_R0(t, a, b, c):\n",
    "    return a / (1 + (t/c)**b)\n",
    "\n",
    "result, country_name, N, D, max_days, CFR_OPT, CFR_scaling_factor, R_0_function, R_0_result_params = fit_extended_SIR(\"US\", new_R0, region_name=None, fit_method=\"least_squares\", a=3.0, b=1.5, c=50)\n",
    "print(result.fit_report())\n",
    "fitted_plot(result, \"US\");\n",
    "plot_extended_SIR(*extended_SIR(N, D, max_days, CFR_OPT, CFR_scaling_factor, R_0_function, **R_0_result_params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_R0(t, a, b, c):\n",
    "    return a / (1 + (t/c)**b)\n",
    "\n",
    "result, country_name, N, D, max_days, CFR_OPT, CFR_scaling_factor, R_0_function, R_0_result_params = fit_extended_SIR(\"Germany\", new_R0, region_name=None, fit_method=\"least_squares\", a=3.0, b=1.5, c=50)\n",
    "print(result.fit_report())\n",
    "fitted_plot(result, \"Germany\");\n",
    "plot_extended_SIR(*extended_SIR(N, D, max_days, CFR_OPT, CFR_scaling_factor, R_0_function, **R_0_result_params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_R0(t, a, b, c):\n",
    "    return a / (1 + (t/c)**b)\n",
    "\n",
    "result, country_name, N, D, max_days, CFR_OPT, CFR_scaling_factor, R_0_function, R_0_result_params = fit_extended_SIR(\"United Kingdom\", new_R0, region_name=None, fit_method=\"least_squares\", a=3.0, b=1.5, c=50)\n",
    "print(result.fit_report())\n",
    "fitted_plot(result, \"United Kingdom\");\n",
    "plot_extended_SIR(*extended_SIR(N, D, max_days, CFR_OPT, CFR_scaling_factor, R_0_function, **R_0_result_params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_R0(t, a, b, c):\n",
    "    return a / (1 + (t/c)**b)\n",
    "\n",
    "result, country_name, N, D, max_days, CFR_OPT, CFR_scaling_factor, R_0_function, R_0_result_params = fit_extended_SIR(\"China\", new_R0, region_name=None, fit_method=\"least_squares\", a=3.0, b=1.5, c=50)\n",
    "print(result.fit_report())\n",
    "fitted_plot(result, \"China\");\n",
    "plot_extended_SIR(*extended_SIR(N, D, max_days, CFR_OPT, CFR_scaling_factor, R_0_function, **R_0_result_params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_R0(t, a, b, c):\n",
    "    return a / (1 + (t/c)**b)\n",
    "\n",
    "result, country_name, N, D, max_days, CFR_OPT, CFR_scaling_factor, R_0_function, R_0_result_params = fit_extended_SIR(\"Iran\", new_R0, region_name=None, fit_method=\"least_squares\", a=3.0, b=1.5, c=50)\n",
    "print(result.fit_report())\n",
    "fitted_plot(result, \"Iran\");\n",
    "plot_extended_SIR(*extended_SIR(N, D, max_days, CFR_OPT, CFR_scaling_factor, R_0_function, **R_0_result_params))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **3. Prediction** <a id=\"section3\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **3.1 Logistic model** <a id=\"section31\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "import scipy.optimize as opt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_example = pd.read_csv(\"../input/covid19-global-forecasting-week-4/submission.csv\")\n",
    "test = pd.read_csv(\"../input/covid19-global-forecasting-week-4/test.csv\")\n",
    "train = pd.read_csv(\"../input/covid19-global-forecasting-week-4/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ = train[train[\"ConfirmedCases\"] >= 0]\n",
    "train_.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replace all na (Province_State) with country:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMPTY_VAL = \"EMPTY_VAL\"\n",
    "\n",
    "def fillState(state, country):\n",
    "    if state == EMPTY_VAL: return country\n",
    "    return state\n",
    "\n",
    "train_['Province_State'].fillna(EMPTY_VAL, inplace=True)\n",
    "train_['Province_State'] = train_.loc[:, ['Province_State', 'Country_Region']].apply(lambda x : fillState(x['Province_State'], x['Country_Region']), axis=1)\n",
    "test['Province_State'].fillna(EMPTY_VAL, inplace=True)\n",
    "test['Province_State'] = test.loc[:, ['Province_State', 'Country_Region']].apply(lambda x : fillState(x['Province_State'], x['Country_Region']), axis=1)\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_['row_number'] = train_.groupby(['Country_Region', 'Province_State']).cumcount()\n",
    "x = train_[train_[\"Country_Region\"] == 'US'][train_[\"Province_State\"] == 'New York']['row_number']\n",
    "y = train_[train_[\"Country_Region\"] == 'US'][train_[\"Province_State\"] == 'New York']['ConfirmedCases']\n",
    "y_ = train_[train_[\"Country_Region\"] == 'US'][train_[\"Province_State\"] == 'New York']['Fatalities']\n",
    "\n",
    "def f(x, L, b, k, x_0):\n",
    "    return L / (1. + np.exp(-k * (x - x_0))) + b\n",
    "\n",
    "\n",
    "def logistic(xs, L, k, x_0):\n",
    "    result = []\n",
    "    for x in xs:\n",
    "        xp = k*(x-x_0)\n",
    "        if xp >= 0:\n",
    "            result.append(L / ( 1. + np.exp(-xp) ) )\n",
    "        else:\n",
    "            result.append(L * np.exp(xp) / ( 1. + np.exp(xp) ) )\n",
    "    return result\n",
    "\n",
    "p0 = [max(y), 0.0,max(x)]\n",
    "p0_ = [max(y_), 0.0,max(x)]\n",
    "x_ = np.arange(0, 100, 1).tolist()\n",
    "try:\n",
    "    popt, pcov = opt.curve_fit(logistic, x, y,p0)\n",
    "    yfit = logistic(x_, *popt)\n",
    "    popt_, pcov_ = opt.curve_fit(logistic, x, y_,p0_)\n",
    "    yfit_ = logistic(x_, *popt_)\n",
    "except:\n",
    "    popt, pcov = opt.curve_fit(f, x, y, method=\"lm\", maxfev=5000)\n",
    "    yfit = f(x_, *popt)\n",
    "    popt_, pcov_ = opt.curve_fit(f, x, y_, method=\"lm\", maxfev=5000)\n",
    "    yfit_ = f(x_, *popt_)\n",
    "    #print(\"problem\")\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 8))\n",
    "ax.plot(x, y, 'o', label ='Actual Cases')\n",
    "ax.plot(x_, yfit, '-', label ='Fitted Cases')\n",
    "\n",
    "ax.plot(x, y_, 'o', label ='Actual Fatalities')\n",
    "ax.plot(x_, yfit_, '-', label ='Fitted fatalities')\n",
    "ax.title.set_text('US - New York')\n",
    "plt.legend(loc=\"center right\")\n",
    "plt.show()\n",
    "\n",
    "correlation_matrix = np.corrcoef(y[1:73], yfit[1:73])\n",
    "correlation_xy = correlation_matrix[0,1]\n",
    "r_squared = correlation_xy**2\n",
    "r_squared\n",
    "\n",
    "correlation_matrix = np.corrcoef(y_[1:73], yfit_[1:73])\n",
    "correlation_xy = correlation_matrix[0,1]\n",
    "r_squared1 = correlation_xy**2\n",
    "r_squared1\n",
    "\n",
    "print(\"The R^2 for the Actual Cases is:\", r_squared,\"\\n\\n The R^2 for the Fatalities is:\",r_squared1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_['row_number'] = train_.groupby(['Country_Region', 'Province_State']).cumcount()\n",
    "x = train_[train_[\"Country_Region\"] == 'Italy'][train_[\"Province_State\"] == 'Italy']['row_number']\n",
    "y = train_[train_[\"Country_Region\"] == 'Italy'][train_[\"Province_State\"] == 'Italy']['ConfirmedCases']\n",
    "y_ = train_[train_[\"Country_Region\"] == 'Italy'][train_[\"Province_State\"] == 'Italy']['Fatalities']\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 8))\n",
    "ax.plot(x, y, 'o', label ='Actual Cases')\n",
    "ax.plot(x_, yfit, '-', label ='Fitted Cases')\n",
    "\n",
    "ax.plot(x, y_, 'o', label ='Actual Fatalities')\n",
    "ax.plot(x_, yfit_, '-', label ='Fitted fatalities')\n",
    "ax.title.set_text('Italy')\n",
    "plt.legend(loc=\"center right\")\n",
    "plt.show()\n",
    "\n",
    "correlation_matrix = np.corrcoef(y[1:73], yfit[1:73])\n",
    "correlation_xy = correlation_matrix[0,1]\n",
    "r_squared = correlation_xy**2\n",
    "r_squared\n",
    "\n",
    "correlation_matrix = np.corrcoef(y_[1:73], yfit_[1:73])\n",
    "correlation_xy = correlation_matrix[0,1]\n",
    "r_squared1 = correlation_xy**2\n",
    "r_squared1\n",
    "\n",
    "print(\"The R^2 for the Actual Cases is:\", r_squared,\"\\n\\n The R^2 for the Fatalities is:\",r_squared1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_['row_number'] = train_.groupby(['Country_Region', 'Province_State']).cumcount()\n",
    "x = train_[train_[\"Country_Region\"] == 'Spain'][train_[\"Province_State\"] == 'Spain']['row_number']\n",
    "y = train_[train_[\"Country_Region\"] == 'Spain'][train_[\"Province_State\"] == 'Spain']['ConfirmedCases']\n",
    "y_ = train_[train_[\"Country_Region\"] == 'Spain'][train_[\"Province_State\"] == 'Spain']['Fatalities']\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 8))\n",
    "ax.plot(x, y, 'o', label ='Actual Cases')\n",
    "ax.plot(x_, yfit, '-', label ='Fitted Cases')\n",
    "\n",
    "ax.plot(x, y_, 'o', label ='Actual Fatalities')\n",
    "ax.plot(x_, yfit_, '-', label ='Fitted fatalities')\n",
    "ax.title.set_text('Spain')\n",
    "plt.legend(loc=\"center right\")\n",
    "plt.show()\n",
    "\n",
    "correlation_matrix = np.corrcoef(y[1:73], yfit[1:73])\n",
    "correlation_xy = correlation_matrix[0,1]\n",
    "r_squared = correlation_xy**2\n",
    "r_squared\n",
    "\n",
    "correlation_matrix = np.corrcoef(y_[1:73], yfit_[1:73])\n",
    "correlation_xy = correlation_matrix[0,1]\n",
    "r_squared1 = correlation_xy**2\n",
    "r_squared1\n",
    "\n",
    "print(\"The R^2 for the Actual Cases is:\", r_squared,\"\\n\\n The R^2 for the Fatalities is:\",r_squared1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_['row_number'] = train_.groupby(['Country_Region', 'Province_State']).cumcount()\n",
    "x = train_[train_[\"Country_Region\"] == 'Germany'][train_[\"Province_State\"] == 'Germany']['row_number']\n",
    "y = train_[train_[\"Country_Region\"] == 'Germany'][train_[\"Province_State\"] == 'Germany']['ConfirmedCases']\n",
    "y_ = train_[train_[\"Country_Region\"] == 'Germany'][train_[\"Province_State\"] == 'Germany']['Fatalities']\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 8))\n",
    "ax.plot(x, y, 'o', label ='Actual Cases')\n",
    "ax.plot(x_, yfit, '-', label ='Fitted Cases')\n",
    "\n",
    "ax.plot(x, y_, 'o', label ='Actual Fatalities')\n",
    "ax.plot(x_, yfit_, '-', label ='Fitted fatalities')\n",
    "ax.title.set_text('Germany')\n",
    "plt.legend(loc=\"center right\")\n",
    "plt.show()\n",
    "\n",
    "correlation_matrix = np.corrcoef(y[1:73], yfit[1:73])\n",
    "correlation_xy = correlation_matrix[0,1]\n",
    "r_squared = correlation_xy**2\n",
    "r_squared\n",
    "\n",
    "correlation_matrix = np.corrcoef(y_[1:73], yfit_[1:73])\n",
    "correlation_xy = correlation_matrix[0,1]\n",
    "r_squared1 = correlation_xy**2\n",
    "r_squared1\n",
    "\n",
    "print(\"The R^2 for the Actual Cases is:\", r_squared,\"\\n\\n The R^2 for the Fatalities is:\",r_squared1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_['row_number'] = train_.groupby(['Country_Region', 'Province_State']).cumcount()\n",
    "x = train_[train_[\"Country_Region\"] == 'United Kingdom'][train_[\"Province_State\"] == 'United Kingdom']['row_number']\n",
    "y = train_[train_[\"Country_Region\"] == 'United Kingdom'][train_[\"Province_State\"] == 'United Kingdom']['ConfirmedCases']\n",
    "y_ = train_[train_[\"Country_Region\"] == 'United Kingdom'][train_[\"Province_State\"] == 'United Kingdom']['Fatalities']\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 8))\n",
    "ax.plot(x, y, 'o', label ='Actual Cases')\n",
    "ax.plot(x_, yfit, '-', label ='Fitted Cases')\n",
    "\n",
    "ax.plot(x, y_, 'o', label ='Actual Fatalities')\n",
    "ax.plot(x_, yfit_, '-', label ='Fitted fatalities')\n",
    "ax.title.set_text('United Kingdom')\n",
    "plt.legend(loc=\"center right\")\n",
    "plt.show()\n",
    "\n",
    "correlation_matrix = np.corrcoef(y[1:73], yfit[1:73])\n",
    "correlation_xy = correlation_matrix[0,1]\n",
    "r_squared = correlation_xy**2\n",
    "r_squared\n",
    "\n",
    "correlation_matrix = np.corrcoef(y_[1:73], yfit_[1:73])\n",
    "correlation_xy = correlation_matrix[0,1]\n",
    "r_squared1 = correlation_xy**2\n",
    "r_squared1\n",
    "\n",
    "print(\"The R^2 for the Actual Cases is:\", r_squared,\"\\n\\n The R^2 for the Fatalities is:\",r_squared1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_['row_number'] = train_.groupby(['Country_Region', 'Province_State']).cumcount()\n",
    "x = train_[train_[\"Country_Region\"] == 'Iran'][train_[\"Province_State\"] == 'Iran']['row_number']\n",
    "y = train_[train_[\"Country_Region\"] == 'Iran'][train_[\"Province_State\"] == 'Iran']['ConfirmedCases']\n",
    "y_ = train_[train_[\"Country_Region\"] == 'Iran'][train_[\"Province_State\"] == 'Iran']['Fatalities']\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 8))\n",
    "ax.plot(x, y, 'o', label ='Actual Cases')\n",
    "ax.plot(x_, yfit, '-', label ='Fitted Cases')\n",
    "\n",
    "ax.plot(x, y_, 'o', label ='Actual Fatalities')\n",
    "ax.plot(x_, yfit_, '-', label ='Fitted fatalities')\n",
    "ax.title.set_text('Iran')\n",
    "plt.legend(loc=\"center right\")\n",
    "plt.show()\n",
    "\n",
    "correlation_matrix = np.corrcoef(y[1:73], yfit[1:73])\n",
    "correlation_xy = correlation_matrix[0,1]\n",
    "r_squared = correlation_xy**2\n",
    "r_squared\n",
    "\n",
    "correlation_matrix = np.corrcoef(y_[1:73], yfit_[1:73])\n",
    "correlation_xy = correlation_matrix[0,1]\n",
    "r_squared1 = correlation_xy**2\n",
    "r_squared1\n",
    "\n",
    "print(\"The R^2 for the Actual Cases is:\", r_squared,\"\\n\\n The R^2 for the Fatalities is:\",r_squared1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **3.2. Gompertz model** <a id=\"section32\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import cycle, islice\n",
    "import seaborn as sb\n",
    "import matplotlib.dates as dates\n",
    "import datetime as dt\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import cycle, islice\n",
    "\n",
    "import plotly.offline as py\n",
    "py.init_notebook_mode(connected=True)\n",
    "from plotly import tools, subplots\n",
    "import plotly.figure_factory as ff\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.preprocessing import PolynomialFeatures \n",
    "from sklearn.pipeline import make_pipeline\n",
    "from tqdm import tqdm\n",
    "\n",
    "from scipy.optimize.minpack import curve_fit\n",
    "from sklearn.metrics import r2_score\n",
    "from scipy.special import expit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv(\"../input/covid19-global-forecasting-week-4/test.csv\")\n",
    "train_data = pd.read_csv(\"../input/covid19-global-forecasting-week-4/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['NewConfirmedCases'] = train_data['ConfirmedCases'] - train_data['ConfirmedCases'].shift(1)\n",
    "train_data['NewConfirmedCases'] = train_data['NewConfirmedCases'].fillna(0.0)\n",
    "train_data['NewFatalities']     = train_data['Fatalities'] - train_data['Fatalities'].shift(1)\n",
    "train_data['NewFatalities']     = train_data['NewFatalities'].fillna(0.0)#.astype(int)\n",
    "\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getColumnInfo(df):\n",
    "    n_province =  df['Province_State'].nunique()\n",
    "    n_country  =  df['Country_Region'].nunique()\n",
    "    n_days     =  df['Date'].nunique()\n",
    "    start_date =  df['Date'].unique()[0]\n",
    "    end_date   =  df['Date'].unique()[-1]\n",
    "    return n_province, n_country, n_days, start_date, end_date\n",
    "\n",
    "n_train = train_data.shape[0]\n",
    "n_test = test_data.shape[0]\n",
    "\n",
    "n_prov_train, n_count_train, n_train_days, start_date_train, end_date_train = getColumnInfo(train_data)\n",
    "n_prov_test,  n_count_test,  n_test_days,  start_date_test,  end_date_test  = getColumnInfo(test_data)\n",
    "df_test = test_data.loc[test_data.Date > '2020-04-03']\n",
    "overlap_days = n_test_days - df_test.Date.nunique()\n",
    "\n",
    "prob_confirm_check_train = train_data.ConfirmedCases.value_counts(normalize=True)\n",
    "prob_fatal_check_train = train_data.Fatalities.value_counts(normalize=True)\n",
    "\n",
    "n_confirm_train = train_data.ConfirmedCases.value_counts()[1:].sum()\n",
    "n_fatal_train = train_data.Fatalities.value_counts()[1:].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_data_by_country = train_data.groupby(['Country_Region'],as_index=True).agg({'ConfirmedCases': 'max', 'Fatalities': 'max'})\n",
    "#train_data_by_country_confirm = train_data_by_country.sort_values(by=[\"ConfirmedCases\"], ascending=False)\n",
    "train_data_by_country = train_data.groupby(['Date','Country_Region'],as_index=False).agg({'ConfirmedCases': 'sum', 'Fatalities': 'sum'\n",
    "                                                                                         })\n",
    "                                                       #'GrowthRate':'mean'\n",
    "max_train_date = train_data['Date'].max()\n",
    "train_data_by_country_confirm = train_data_by_country.query('(Date == @max_train_date) & (ConfirmedCases > 100)').sort_values('ConfirmedCases', ascending=False)\n",
    "train_data_by_country_confirm.set_index('Country_Region', inplace=True)\n",
    "display(train_data_by_country_confirm.head())\n",
    "\n",
    "from itertools import cycle, islice\n",
    "discrete_col = list(islice(cycle(['orange', 'r', 'g', 'k', 'b', 'c', 'm']), None, len(train_data_by_country_confirm.head(30))))\n",
    "plt.rcParams.update({'font.size': 22})\n",
    "train_data_by_country_confirm.head(20).plot(figsize=(20,15), kind='barh', color=discrete_col)\n",
    "plt.legend([\"Confirmed Cases\", \"Fatalities\"]);\n",
    "plt.xlabel(\"Number of Covid-19 Affectees\")\n",
    "plt.title(\"First 20 Countries with Highest Confirmed Cases\")\n",
    "ylocs, ylabs = plt.yticks()\n",
    "for i, v in enumerate(train_data_by_country_confirm.head(20)[\"ConfirmedCases\"][:]):\n",
    "    plt.text(v+0.01, ylocs[i]-0.25, str(int(v)), fontsize=12)\n",
    "for i, v in enumerate(train_data_by_country_confirm.head(20)[\"Fatalities\"][:]):\n",
    "    if v > 0: #disply for only >300 fatalities\n",
    "        plt.text(v+0.01,ylocs[i]+0.1,str(int(v)),fontsize=12)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''''#train_data_by_country = train_data.groupby(['Country_Region'],as_index=True).agg({'ConfirmedCases': 'max', 'Fatalities': 'max'})\n",
    "#train_data_by_country_confirm = train_data_by_country.sort_values(by=[\"ConfirmedCases\"], ascending=False)\n",
    "\n",
    "train_data['Date'] = pd.to_datetime(train_data['Date'])\n",
    "train_data_by_date = train_data.groupby(['Date'],as_index=True).agg({'ConfirmedCases': 'max','Fatalities': 'max', \n",
    "                                                                     'NewConfirmedCases':'max', 'NewFatalities':'max'})\n",
    "\n",
    "## ======= Sort by countries with fatalities > 200 ========\n",
    "train_data_by_country_fatal = train_data_by_country[train_data_by_country['Fatalities']>200]\n",
    "train_data_by_country_fatal = train_data_by_country_fatal.sort_values(by=['Fatalities'],ascending=False).reset_index()\n",
    "#display(train_data_by_country_fatal.head(20))\n",
    "\n",
    "df_merge_by_country = pd.merge(train_data,train_data_by_country_fatal['Country_Region'],on=['Country_Region'],how='inner')\n",
    "df_max_fatality_country = df_merge_by_country.groupby(['Date','Country_Region'],as_index=False).agg({'ConfirmedCases': 'sum',\n",
    "                                                                                                     'Fatalities': 'sum',\n",
    "                                                                                                     'NewConfirmedCases':'sum',\n",
    "                                                                                                     'NewFatalities':'sum'})\n",
    "\n",
    "\n",
    "# convert -ve numbers to zeros, and set Date as new index\n",
    "num = df_max_fatality_country._get_numeric_data() \n",
    "num[num < 0.0] = 0.0\n",
    "df_max_fatality_country.set_index('Date',inplace=True)\n",
    "#display(df_max_fatality_country.head(20))\n",
    "\n",
    "countries = train_data_by_country_fatal['Country_Region'].unique()''''''\n",
    "\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reformat_time(reformat, ax):\n",
    "    ax.xaxis.set_major_locator(dates.WeekdayLocator())\n",
    "    ax.xaxis.set_major_formatter(dates.DateFormatter('%b %d'))    \n",
    "    if reformat: #reformat again if you wish\n",
    "        date_list = train_data_by_date.reset_index()[\"Date\"].tolist()\n",
    "        x_ticks = [dt.datetime.strftime(t,'%Y-%m-%d') for t in date_list]\n",
    "        x_ticks = [tick for i,tick in enumerate(x_ticks) if i%8==0 ]# split labels into same number of ticks as by pandas\n",
    "        ax.set_xticklabels(x_ticks, rotation=90)\n",
    "    # cosmetics\n",
    "    ax.yaxis.grid(linestyle='dotted')\n",
    "    ax.spines['right'].set_color('none')\n",
    "    ax.spines['top'].set_color('none')\n",
    "    ax.spines['left'].set_color('none')\n",
    "    ax.spines['bottom'].set_color('none')\n",
    "\n",
    "train_data['Date'] = pd.to_datetime(train_data['Date'])\n",
    "train_data_by_date = train_data.groupby(['Date'],as_index=True).agg({'ConfirmedCases': 'sum','Fatalities': 'sum', \n",
    "                                                                     'NewConfirmedCases':'sum', 'NewFatalities':'sum'})\n",
    "#                                             MortalityRate':'mean'\n",
    "num0 = train_data_by_date._get_numeric_data() \n",
    "num0[num0 < 0.0] = 0.0\n",
    "#display(train_data_by_date.head())\n",
    "\n",
    "## ======= Sort by countries with fatalities > 500 ========\n",
    "\n",
    "train_data_by_country_max = train_data.groupby(['Country_Region'],as_index=True).agg({'ConfirmedCases': 'max', 'Fatalities': 'max'})\n",
    "train_data_by_country_fatal = train_data_by_country_max[train_data_by_country_max['Fatalities']>500]\n",
    "train_data_by_country_fatal = train_data_by_country_fatal.sort_values(by=['Fatalities'],ascending=False).reset_index()\n",
    "display(train_data_by_country_fatal.head(20))\n",
    "\n",
    "df_merge_by_country = pd.merge(train_data,train_data_by_country_fatal['Country_Region'],on=['Country_Region'],how='inner')\n",
    "df_max_fatality_country = df_merge_by_country.groupby(['Date','Country_Region'],as_index=False).agg({'ConfirmedCases': 'sum',\n",
    "                                                                                                     'Fatalities': 'sum',\n",
    "                                                                                                     'NewConfirmedCases':'sum',\n",
    "                                                                                                     'NewFatalities':'sum'\n",
    "                                                                                                     })\n",
    "#                                               MortalityRate':'mean'\n",
    "\n",
    "num1 = df_max_fatality_country._get_numeric_data() \n",
    "num1[num1 < 0.0] = 0.0\n",
    "df_max_fatality_country.set_index('Date',inplace=True)\n",
    "#display(df_max_fatality_country.head(20))\n",
    "\n",
    "countries = train_data_by_country_fatal['Country_Region'].unique()\n",
    "\n",
    "plt.rcParams.update({'font.size': 16})\n",
    "\n",
    "fig,(ax0,ax1) = plt.subplots(1,2,figsize=(15, 8))\n",
    "fig,(ax2,ax3) = plt.subplots(1,2,figsize=(15, 8))#,sharey=True)\n",
    "\n",
    "train_data_by_date.ConfirmedCases.plot(ax=ax0, x_compat=True, title='Confirmed Cases Globally', legend='Confirmed Cases',\n",
    "                                       color=discrete_col)#, logy=True)\n",
    "reformat_time(0,ax0)\n",
    "train_data_by_date.NewConfirmedCases.plot(ax=ax0, x_compat=True, linestyle='dotted', legend='New Confirmed Cases',\n",
    "                                          color=discrete_col)#, logy=True)\n",
    "reformat_time(0,ax0)\n",
    "\n",
    "train_data_by_date.Fatalities.plot(ax=ax2, x_compat=True, title='Fatalities Globally', legend='Fatalities', color='r')\n",
    "reformat_time(0,ax2)\n",
    "train_data_by_date.NewFatalities.plot(ax=ax2, x_compat=True, linestyle='dotted', legend='Daily Deaths',color='r')#tell pandas not to use its own datetime format\n",
    "reformat_time(0,ax2)\n",
    "\n",
    "for country in countries:\n",
    "    match = df_max_fatality_country.Country_Region==country\n",
    "    df_fatality_by_country = df_max_fatality_country[match] \n",
    "    df_fatality_by_country.ConfirmedCases.plot(ax=ax1, x_compat=True, title='Cumulative Confirmed Cases Nationally')\n",
    "    reformat_time(0,ax1)\n",
    "    df_fatality_by_country.Fatalities.plot(ax=ax3, x_compat=True, title='Cumulative Fatalities Nationally')\n",
    "    reformat_time(0,ax3)\n",
    "    \n",
    "ax1.legend(countries)\n",
    "ax3.legend(countries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures \n",
    "from sklearn.pipeline import make_pipeline\n",
    "from tqdm import tqdm\n",
    "\n",
    "plt.rcParams.update({'font.size': 12})\n",
    "fig,(ax0,ax1) = plt.subplots(2,1,figsize=(20, 20))\n",
    "countries_europe = ['Italy', 'France', 'Spain', 'Germany', 'United Kingdom']\n",
    "\n",
    "# Take the 1st day as 2020-02-23\n",
    "df = train_data.loc[train_data.Date >= '2020-02-23']\n",
    "n_days_europe = df.Date.nunique()\n",
    "\n",
    "for country in tqdm(countries): \n",
    "    df_country_train = df_max_fatality_country[df_max_fatality_country['Country_Region']==country] \n",
    "    df_country_test = test_data[test_data['Country_Region']==country]  \n",
    "    df_country_train = df_country_train.reset_index()[df_country_train.reset_index().Date > '2020-02-22']\n",
    "    \n",
    "    x_train = np.arange(1, n_days_europe+1).reshape((-1,1))\n",
    "    x_test  = (np.arange(1,n_test_days+1+overlap_days)).reshape((-1,1)) \n",
    "    #print (range(n_days_europe))\n",
    "    \n",
    "    y_train_f = df_country_train['Fatalities']\n",
    "    #print(y_train_f)\n",
    "    model_f = make_pipeline(PolynomialFeatures(degree=3), Ridge(fit_intercept=False)) \n",
    "    model_f = model_f.fit(x_train, y_train_f)\n",
    "    y_predict_f = model_f.predict(x_test) \n",
    "    \n",
    "    y_train_c = df_country_train['ConfirmedCases'] \n",
    "    model_c = make_pipeline(PolynomialFeatures(degree=3), Ridge(fit_intercept=False)) \n",
    "    model_c = model_c.fit(x_train, y_train_c)\n",
    "    y_predict_c = model_c.predict(x_test)\n",
    "    \n",
    "    ax0.plot(x_test, y_predict_c,linewidth=2, label='predict_'+country)\n",
    "    ax0.plot(x_train, y_train_c, linewidth=2, color='r', linestyle='dotted', label='train_'+country)\n",
    "    ax0.set_title(\"Prediction vs Training for Confirmed Cases\")\n",
    "    ax0.set_xlabel(\"Number of days\")\n",
    "    ax0.set_ylabel(\"Confirmed Cases\")\n",
    "    ax0.legend(loc='center left',bbox_to_anchor=(1.0, 0.5))\n",
    "    \n",
    "    ax1.plot(x_test, y_predict_f,linewidth=2, label='predict_'+country)\n",
    "    ax1.plot(x_train, y_train_f, linewidth=2, color='r', linestyle='dotted', label='train_'+country)\n",
    "    ax1.set_title(\"Prediction vs Training for Fatalities\")\n",
    "    ax1.set_xlabel(\"Number of days\")\n",
    "    ax1.set_ylabel(\"Fatalities\")\n",
    "    ax1.legend(loc='center left',bbox_to_anchor=(1.0, 0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#only selected countries\n",
    "#countries= countries[0:9]\n",
    "from tqdm import tqdm\n",
    "from scipy.optimize.minpack import curve_fit\n",
    "from sklearn.metrics import r2_score\n",
    "from scipy.special import expit\n",
    "\n",
    "def Gompertz(a, c, t, t0):    \n",
    "    Q = a * np.exp(-np.exp(-c*(t-t0)))\n",
    "    return Q\n",
    "def Boltzman(a, c, t, t0):\n",
    "    Q = a / (1 + np.exp(-c*(t-t0)))\n",
    "    return Q\n",
    "\n",
    "plt.rcParams.update({'font.size': 12})\n",
    "fig,(ax0,ax1) = plt.subplots(2,1,figsize=(20, 20))\n",
    "#countries_europe=['US', 'China', 'Iran', 'France', 'Italy', 'Spain', 'Germany', 'Belgium', 'Turkey', 'Netherlands', 'Switzerland', 'United Kingdom']\n",
    "#countries_europe=['France']\n",
    "for country in tqdm(countries): \n",
    "    #print('\\n\\n\\n\\n country ==>', country)\n",
    "    df_country_train = df_max_fatality_country[df_max_fatality_country['Country_Region']==country] \n",
    "    df_country_test = test_data[test_data['Country_Region']==country]  \n",
    "    if country != 'China':\n",
    "        df_country_train = df_country_train.reset_index().loc[df_country_train.reset_index().Date>'2020-02-22'] #17\n",
    "        n_days_sans_China =train_data.Date.nunique() - df_country_train.Date.nunique()        \n",
    "    else:\n",
    "        df_country_train = df_country_train.reset_index()\n",
    "        n_days_sans_China = 0\n",
    "        \n",
    "    n_train_days =df_country_train.Date.nunique()    \n",
    "    x_train = range(n_train_days)\n",
    "    x_test  = range(n_train_days+n_test_days-overlap_days)#n_test_days+overlap_days)\n",
    "    y_train_f = df_country_train['Fatalities']\n",
    "    y_train_c = df_country_train['ConfirmedCases']    \n",
    "    \n",
    "    if country == 'China':\n",
    "        lower = [100, 0.02, 0]\n",
    "        upper = [2.0*max(y_train_f),0.2, 40]\n",
    "    elif country == 'Iran':\n",
    "        lower = [200, 0.00, 0]\n",
    "        upper = [3.0*max(y_train_f),0.14, 65]\n",
    "    elif country == 'Italy':\n",
    "        lower = [100, 0.00, 0]\n",
    "        upper = [3.5*max(y_train_f),0.15, 72]\n",
    "    elif country == 'US':\n",
    "        lower = [0, 0.02, 0]\n",
    "        upper = [4.0*max(y_train_f),0.22, 83] \n",
    "    elif country == 'France':\n",
    "        lower = [0, 0.02, 0]\n",
    "        upper = [4.0*max(y_train_f),0.18, 82]    \n",
    "    elif country == 'Spain':\n",
    "        lower = [0, 0.02, 0]\n",
    "        upper = [3.5*max(y_train_f),0.18, 75]\n",
    "    elif country == 'Germany':\n",
    "        lower = [0.0, 0.02, 0]\n",
    "        upper = [3.5*max(y_train_f),0.25, 80] \n",
    "    elif country == 'Belgium':\n",
    "        lower = [0.0, 0.02, 0]\n",
    "        upper = [3.5*max(y_train_f),0.25, 80] \n",
    "    elif country == 'Turkey':\n",
    "        lower = [0.0, 0.02, 0]\n",
    "        upper = [4.0*max(y_train_f),0.25, 83]\n",
    "    elif country == 'Netherlands':\n",
    "        lower = [0.0, 0.02, 0]\n",
    "        upper = [4.0*max(y_train_f),0.18, 80] \n",
    "    elif country == 'Switzerland':\n",
    "        lower = [0.0, 0.02, 0]\n",
    "        upper = [4.0*max(y_train_f),0.18, 80] \n",
    "    elif country == 'United Kingdom':\n",
    "        lower = [0.0, 0.02, 0]\n",
    "        upper = [4.5*max(y_train_f),0.25, 85]     \n",
    "    else:\n",
    "        lower = [0.0, 0.02, 0]\n",
    "        upper = [4.5*max(y_train_f),0.25, 80]    \n",
    "    \n",
    "    popt_f, pcov_f = curve_fit(Gompertz, x_train, y_train_f, method='trf', bounds=(lower,upper))\n",
    "    a_max, estimated_c, estimated_t0 = popt_f\n",
    "    y_predict_f = Gompertz(a_max, estimated_c, x_test, estimated_t0)\n",
    "    y_predict_f_at_t0 =  Gompertz(a_max, estimated_c, estimated_t0, estimated_t0)\n",
    "    print(\"\\n\\n\\n\\n\",country,'\\nfatalities ==>, max: ',a_max, ', slope: %.2f'% estimated_c, ', inflection point: ', \n",
    "          estimated_t0, ', r2 score: %.2f'% r2_score(y_train_f[:], y_predict_f[0:n_train_days]))\n",
    "   \n",
    "    ###### Confirmed cases:    \n",
    "        \n",
    "    if country == 'China':\n",
    "        lower_c = [100, 0.02, 0]\n",
    "        upper_c = [2.0*max(y_train_c),0.25,30]\n",
    "    elif country == 'Iran':\n",
    "        lower_c = [100, 0.00, 0]\n",
    "        upper_c = [3.0*max(y_train_c),0.15,65]\n",
    "    elif country == 'Italy':\n",
    "        lower_c = [1000, 0.00, 0]\n",
    "        upper_c = [3.0*max(y_train_c),0.15, 64]\n",
    "    elif country == 'US':\n",
    "        lower_c = [0, 0.02, 0]\n",
    "        upper_c = [3.5*max(y_train_c),0.23, 78] \n",
    "    elif country == 'France':\n",
    "        lower_c = [10, 0.02, 0]\n",
    "        upper_c = [4.5*max(y_train_c),0.15, 85]\n",
    "    elif country == 'Spain':\n",
    "        lower_c = [10, 0.02, 0]\n",
    "        upper_c = [3.5*max(y_train_c),0.15, 74] \n",
    "    elif country == 'Germany':\n",
    "        lower_c = [10, 0.02, 0]\n",
    "        upper_c = [3.5*max(y_train_c),0.15, 75] \n",
    "    elif country == 'Belgium':\n",
    "        lower_c = [100, 0.02, 0]\n",
    "        upper_c = [4.0*max(y_train_c),0.15, 80]\n",
    "    elif country == 'Turkey':\n",
    "        lower_c = [100, 0.02, 0]\n",
    "        upper_c = [4.0*max(y_train_c),0.25, 83] \n",
    "    elif country == 'Netherlands':\n",
    "        lower_c = [100, 0.02, 0]\n",
    "        upper_c = [4.0*max(y_train_c),0.14, 78] \n",
    "    elif country == 'Switzerland':\n",
    "        lower_c = [100, 0.02, 0]\n",
    "        upper_c = [3.5*max(y_train_c),0.14, 70]  \n",
    "    elif country == 'United Kingdom':\n",
    "        lower_c = [100, 0.02, 0]\n",
    "        upper_c = [4.5*max(y_train_c),0.15, 85]    \n",
    "    else:\n",
    "        lower_c = [100, 0.02, 0]\n",
    "        upper_c = [4.5*max(y_train_c),0.15, 80]\n",
    "        \n",
    "    \n",
    "    popt_c, pcov_c = curve_fit(Gompertz, x_train, y_train_c, method='trf', bounds=(lower_c,upper_c))\n",
    "    a_max_c, estimated_c_c, estimated_t0_c = popt_c\n",
    "    y_predict_c = Gompertz(a_max_c, estimated_c_c, x_test, estimated_t0_c)\n",
    "    y_predict_c_at_t0 =  Gompertz(a_max_c, estimated_c_c, estimated_t0_c, estimated_t0_c)\n",
    "    print('confirmed ==> max: ',a_max_c, ', slope: %.2f'% estimated_c_c, ', inflection point: ', \n",
    "          estimated_t0_c, ', r2 score: %.2f'% r2_score(y_train_c[:], y_predict_c[0:n_train_days]))\n",
    "    \n",
    "    ## ===== Move the x-axis of trained and test datasets to allign with dates in China ======\n",
    "    extend_days_test = [i+len(x_test) for i in range(n_days_sans_China)]\n",
    "    x_test      = np.append(x_test, extend_days_test) \n",
    "    y_predict_c = np.pad(y_predict_c, (n_days_sans_China, 0), 'constant')\n",
    "    y_predict_f = np.pad(y_predict_f, (n_days_sans_China, 0), 'constant')\n",
    "    inflection_c = estimated_t0_c+n_days_sans_China\n",
    "\n",
    "    extend_days_train = [i+len(x_train) for i in range(n_days_sans_China)]\n",
    "    x_train     = np.append(x_train, extend_days_train)\n",
    "    y_train_c   = np.pad(y_train_c, (n_days_sans_China, 0), 'constant')\n",
    "    y_train_f   = np.pad(y_train_f, (n_days_sans_China, 0), 'constant')\n",
    "    inflection_f = estimated_t0+n_days_sans_China\n",
    "    \n",
    "    ## ===== Plot =======\n",
    "    ax0.plot(x_test, y_predict_c, linewidth=2, label='predict_'+country) \n",
    "    ax0.plot(inflection_c, y_predict_c_at_t0, marker='o', markersize=6, color='green')#, label='inflection')\n",
    "    ax0.plot(x_train, y_train_c, linewidth=2, color='r', linestyle='dotted', label='train_'+country)   \n",
    "    ax0.set_title(\"Prediction vs Training for Confirmed Cases\")\n",
    "    ax0.set_xlabel(\"Number of days\")\n",
    "    ax0.set_ylabel(\"Confirmed Cases\")\n",
    "    ax0.legend(loc='center left',bbox_to_anchor=(1.0, 0.5))\n",
    "    \n",
    "    \n",
    "    ax1.plot(x_test, y_predict_f, linewidth=2, label='predict_'+country) \n",
    "    ax1.plot(inflection_f, y_predict_f_at_t0, marker='o', markersize=6, color='green')\n",
    "    ax1.plot(x_train, y_train_f, linewidth=2, color='r', linestyle='dotted', label='train_'+country)    \n",
    "    ax1.set_title(\"Prediction vs Training for Fatalities\")\n",
    "    ax1.set_xlabel(\"Number of days\")\n",
    "    ax1.set_ylabel(\"Fatalities\")\n",
    "    ax1.legend(loc='center left',bbox_to_anchor=(1.0, 0.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **3.3. Final submission using Gompertz model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-output": true
   },
   "outputs": [],
   "source": [
    "nCountries= train_data['Country_Region'].unique() \n",
    "isState = bool\n",
    "\n",
    "def get_bounds_fatal (country, isState, y_train):\n",
    "    maximum = max(y_train)\n",
    "    if maximum == 0.0: maximum = 1.0 \n",
    "\n",
    "    if country == 'China':\n",
    "        lower = [0.0, 0.02, 0]\n",
    "        upper = [2.0*maximum,0.2, 40]\n",
    "    elif country == 'Iran':\n",
    "        lower = [200, 0.00, 0]\n",
    "        upper = [3.0*maximum,0.14, 65]\n",
    "    elif country == 'Italy':\n",
    "        lower = [100, 0.00, 0]\n",
    "        upper = [3.5*maximum,0.15, 70]\n",
    "    elif country == 'US':\n",
    "        lower = [0, 0.02, 0]\n",
    "        if maximum <=10:upper = [4.0*maximum, 0.30, 85] \n",
    "        else:           upper = [4.0*maximum,0.23, 85] \n",
    "    elif country == 'France':\n",
    "        lower = [0, 0.02, 0]\n",
    "        if maximum <=10:upper = [4.0*maximum,0.18, 80]\n",
    "        else:           upper = [4.0*maximum,0.18, 80] \n",
    "    elif country == 'Spain':\n",
    "        lower = [0, 0.02, 0]\n",
    "        upper = [3.5*maximum,0.18, 75]\n",
    "    elif country == 'Germany':\n",
    "        lower = [0.0, 0.02, 0]\n",
    "        upper = [3.5*maximum,0.25, 80] \n",
    "    elif country == 'Belgium':\n",
    "        lower = [0.0, 0.02, 0]\n",
    "        upper = [3.5*maximum,0.25, 80] \n",
    "    elif country == 'Turkey':\n",
    "        lower = [0.0, 0.02, 0]\n",
    "        upper = [4.0*maximum,0.25, 83]\n",
    "    elif country == 'Netherlands':\n",
    "        lower = [0.0, 0.02, 0]\n",
    "        upper = [4.0*maximum,0.18, 80] \n",
    "    elif country == 'Switzerland':\n",
    "        lower = [0.0, 0.02, 0]\n",
    "        upper = [4.0*maximum,0.18, 80] \n",
    "    elif country == 'United Kingdom':\n",
    "        lower = [0.0, 0.02, 0]\n",
    "        upper = [4.5*maximum,0.25, 85] \n",
    "    elif country == 'Denmark':\n",
    "        lower = [0, 0.02, 0]\n",
    "        if maximum <=10:upper = [4.0*maximum, 0.30, 80] \n",
    "        else:           upper = [4.0*maximum,0.23, 80]  \n",
    "    elif country == 'Australia':\n",
    "        lower = [0, 0.02, 0]\n",
    "        if maximum <=10: upper = [2.0*maximum, 0.20, 45] \n",
    "        else:            upper = [2.5*maximum,0.20, 65]  \n",
    "    elif country == 'Canada':\n",
    "        lower = [0, 0.02, 0]\n",
    "        if maximum <=10: upper = [2.0*maximum, 0.20, 65] \n",
    "        else:            upper = [3.5*maximum, 0.30, 80] \n",
    "    elif country == 'Pakistan':\n",
    "        lower = [0.0, 0.02, 0] \n",
    "        upper = [4.5*maximum,0.20,85]   \n",
    "    elif country == 'India':\n",
    "        lower = [0.0, 0.02, 0] \n",
    "        upper = [4.5*maximum,0.25,85]       \n",
    "    else:\n",
    "        lower = [0.0, 0.02, 0] \n",
    "        if isState:\n",
    "            if maximum <=10:upper = [4.0*maximum,0.30,80] \n",
    "            else:           upper = [4.5*maximum,0.15,80]\n",
    "        else: \n",
    "            if maximum <=10:upper = [4.0*maximum,0.60,85] \n",
    "            else:           upper = [4.5*maximum,0.25,85]    \n",
    "    return lower, upper \n",
    "\n",
    "def get_bounds_confirm (country, isState, y_train):\n",
    "    maximum = max(y_train)\n",
    "    if maximum == 0.0: maximum = 1.0\n",
    "\n",
    "    if country == 'China':\n",
    "        lower_c = [0, 0.02, 0]\n",
    "        upper_c = [2.0*maximum,0.25,30]\n",
    "    elif country == 'Iran':\n",
    "        lower_c = [100, 0.00, 0]\n",
    "        upper_c = [3.0*maximum,0.15,65]\n",
    "    elif country == 'Italy':\n",
    "        lower_c = [1000, 0.00, 0]\n",
    "        upper_c = [3.0*maximum,0.15, 64]\n",
    "    elif country == 'US':\n",
    "        lower_c = [0, 0.02, 0]\n",
    "        if maximum <=10:upper_c = [4.0*maximum, 0.30, 80] \n",
    "        else:           upper_c = [3.5*maximum, 0.23, 78] \n",
    "    elif country == 'France':\n",
    "        lower_c = [10, 0.02, 0]\n",
    "        if maximum <=10:upper_c = [4.0*maximum, 0.15, 80] \n",
    "        else:           upper_c = [4.5*maximum, 0.15, 80] \n",
    "    elif country == 'Spain':\n",
    "        lower_c = [10, 0.02, 0]\n",
    "        upper_c = [3.5*maximum,0.15, 74] \n",
    "    elif country == 'Germany':\n",
    "        lower_c = [10, 0.02, 0]\n",
    "        upper_c = [3.5*maximum,0.15, 75] \n",
    "    elif country == 'Belgium':\n",
    "        lower_c = [100, 0.02, 0]\n",
    "        upper_c = [4.0*maximum,0.15, 80]\n",
    "    elif country == 'Turkey':\n",
    "        lower_c = [100, 0.02, 0]\n",
    "        upper_c = [4.0*maximum,0.25, 83] \n",
    "    elif country == 'Netherlands':\n",
    "        lower_c = [0.0, 0.02, 0]\n",
    "        upper_c = [4.0*maximum,0.14, 78] \n",
    "    elif country == 'Switzerland':\n",
    "        lower_c = [100, 0.02, 0]\n",
    "        upper_c = [3.5*maximum,0.14, 70] \n",
    "    elif country == 'United Kingdom':\n",
    "        lower_c = [0.0, 0.02, 0]\n",
    "        upper_c = [4.5*maximum,0.15, 85] \n",
    "    elif country == 'Denmark':\n",
    "        lower_c = [0, 0.02, 0]\n",
    "        if maximum <=10: upper_c = [2.0*maximum, 0.30, 40] \n",
    "        else:            upper_c = [2.5*maximum,0.30, 55]   \n",
    "    elif country == 'Australia':\n",
    "        lower_c = [0, 0.02, 0]\n",
    "        if maximum <=10: upper_c = [2.0*maximum, 0.25, 45] \n",
    "        else:            upper_c = [2.5*maximum,0.25, 65]  \n",
    "    elif country == 'Canada':\n",
    "        lower_c = [0, 0.02, 0]\n",
    "        if maximum <=10: upper_c = [3.0*maximum, 0.28, 75] \n",
    "        else:            upper_c = [3.5*maximum,0.28, 80]\n",
    "    elif country == 'Pakistan':\n",
    "        lower_c = [0.0, 0.02, 0] \n",
    "        upper_c = [4.5*maximum,0.15,85] \n",
    "    elif country == 'India':\n",
    "        lower_c = [0.0, 0.02, 0] \n",
    "        upper_c = [4.5*maximum,0.20,85]     \n",
    "    else:\n",
    "        lower_c = [0.0, 0.02, 0] \n",
    "        if isState:\n",
    "            if maximum <= 200: upper_c = [2.0*maximum,0.20,80] \n",
    "            else:              upper_c = [4.5*maximum,0.20,80]\n",
    "        else:  \n",
    "            if maximum <= 200: upper_c = [3.0*maximum,0.20,85]  \n",
    "            else:              upper_c = [4.5*maximum,0.15,80]    \n",
    "    return lower_c, upper_c \n",
    "\n",
    "#nCountries = ['United Kingdom']  \n",
    "x_train = range(n_train_days)\n",
    "x_test  = range(n_train_days+n_test_days-overlap_days)\n",
    "\n",
    "for country in tqdm(nCountries): \n",
    "    fig,(ax0,ax1) = plt.subplots(2,1,figsize=(20, 20))\n",
    "    #print('\\n\\n\\n\\n country ==>', country) \n",
    "    \n",
    "    df_country_train = train_data[train_data['Country_Region']==country] \n",
    "    df_country_test = test_data[test_data['Country_Region']==country]  \n",
    "    \n",
    "    if country != 'China':\n",
    "        df_country_train = df_country_train.reset_index().loc[df_country_train.reset_index().Date>'2020-02-22'] #17\n",
    "        n_days_sans_China =train_data.Date.nunique() - df_country_train.Date.nunique()        \n",
    "    else:\n",
    "        df_country_train = df_country_train.reset_index()\n",
    "        n_days_sans_China = 0\n",
    "        \n",
    "    n_train_days =df_country_train.Date.nunique()    \n",
    "    x_train = range(n_train_days)\n",
    "    x_test  = range(n_train_days+n_test_days-overlap_days)   \n",
    "    nvalues = df_country_train['Province_State'].isna().nunique() #fix for problem with Denmark data\n",
    "    \n",
    "    if (df_country_train['Province_State'].isna().unique()==True).any() and nvalues<2: \n",
    "        isState = False        \n",
    "        y_train_f = df_country_train['Fatalities']\n",
    "        y_train_c = df_country_train['ConfirmedCases']  \n",
    "        \n",
    "        if y_train_f.empty == False:\n",
    "            lower, upper = get_bounds_fatal (country, isState, y_train_f)\n",
    "            popt_f, pcov_f = curve_fit(Gompertz, x_train, y_train_f, method='trf', bounds=(lower,upper))\n",
    "            a_max, estimated_c, estimated_t0 = popt_f\n",
    "            y_predict_f = Gompertz(a_max, estimated_c, x_test, estimated_t0)            \n",
    "            #print('\\nfatalities ==>, max: ',a_max, ', slope: %.2f'% estimated_c, ', inflection point: ', \n",
    "             #     estimated_t0, ', r2 score: %.2f'% r2_score(y_train_f[:], y_predict_f[0:n_train_days]))\n",
    "            \n",
    "            \n",
    "        if y_train_c.empty == False:  \n",
    "            lower_c, upper_c = get_bounds_confirm (country, isState, y_train_c)\n",
    "            popt_c, pcov_c = curve_fit(Gompertz, x_train, y_train_c, method='trf', bounds=(lower_c,upper_c))\n",
    "            a_max_c, estimated_c_c, estimated_t0_c = popt_c\n",
    "            y_predict_c = Gompertz(a_max_c, estimated_c_c, x_test, estimated_t0_c)\n",
    "            #print('\\nconfirmed ==> max: ',a_max_c, ', slope: %.2f'% estimated_c_c, ', inflection point: ', \n",
    "             #     estimated_t0_c, ', r2 score: %.2f'% r2_score(y_train_c[:], y_predict_c[0:n_train_days]))\n",
    "            \n",
    "            \n",
    "        ## ===== Move the x-axis of trained and test datasets to allign with dates in China ======\n",
    "        extend_days_test = [i+len(x_test) for i in range(n_days_sans_China)]\n",
    "        x_test      = np.append(x_test, extend_days_test)                         \n",
    "        y_predict_c = np.pad(y_predict_c, (n_days_sans_China, 0), 'constant') \n",
    "        y_predict_f = np.pad(y_predict_f, (n_days_sans_China, 0), 'constant')\n",
    "        inflection_f = estimated_t0+n_days_sans_China\n",
    "            \n",
    "        extend_days_train = [i+len(x_train) for i in range(n_days_sans_China)]\n",
    "        x_train     = np.append(x_train, extend_days_train)           \n",
    "        y_train_c   = np.pad(y_train_c, (n_days_sans_China, 0), 'constant')\n",
    "        y_train_f   = np.pad(y_train_f, (n_days_sans_China, 0), 'constant')\n",
    "        inflection_c = estimated_t0_c+n_days_sans_China           \n",
    "        \n",
    "        ax0.plot(x_test, y_predict_c, linewidth=2, label='predict_'+country) \n",
    "        ax0.plot(x_train, y_train_c, linewidth=2, color='r', linestyle='dotted', label='train_'+country)\n",
    "        ax0.set_title(\"Prediction vs Training for Confirmed Cases\")\n",
    "        ax0.set_xlabel(\"Number of days\")\n",
    "        ax0.set_ylabel(\"Confirmed Cases\")\n",
    "        ax0.legend()\n",
    "        test_data.loc[test_data['Country_Region']==country,'ConfirmedCases'] = y_predict_c[-n_test_days:]\n",
    "        \n",
    "        ax1.plot(x_test, y_predict_f, linewidth=2, label='predict_'+country) \n",
    "        ax1.plot(x_train, y_train_f, linewidth=2, color='r', linestyle='dotted', label='train_'+country)    \n",
    "        ax1.set_title(\"Prediction vs Training for Fatalities\")\n",
    "        ax1.set_xlabel(\"Number of days\")\n",
    "        ax1.set_ylabel(\"Fatalities\")\n",
    "        ax1.legend()\n",
    "        test_data.loc[test_data['Country_Region']==country,'Fatalities'] = y_predict_f[-n_test_days:]             \n",
    "    else: # use Province/State data when available\n",
    "        isState = True\n",
    "        state_list = []\n",
    "        y_predict_c_dict = {}; y_train_c_dict = {}\n",
    "        y_predict_f_dict = {}; y_train_f_dict = {}\n",
    "        for state in df_country_train['Province_State'].unique():\n",
    "            df_state_train = df_country_train[df_country_train['Province_State']==state] \n",
    "            df_state_test = df_country_test[df_country_test['Province_State']==state]   \n",
    "            state_list.append(state)\n",
    "            y_train_f = df_state_train['Fatalities']\n",
    "            y_train_c = df_state_train['ConfirmedCases']   \n",
    "            \n",
    "            if y_train_f.empty== False:                 \n",
    "                lower, upper = get_bounds_fatal (country, isState, y_train_f)\n",
    "                popt_f, pcov_f = curve_fit(Gompertz, x_train, y_train_f, method='trf', bounds=(lower,upper))\n",
    "                a_max, estimated_c, estimated_t0 = popt_f\n",
    "                y_predict_f = Gompertz(a_max, estimated_c, x_test, estimated_t0) \n",
    "                y_predict_f_dict[state] =  y_predict_f\n",
    "                y_train_f_dict[state]   =  y_train_f                \n",
    "                #print('\\nfatalities state ==>, max: ',a_max, ', slope: %.2f'% estimated_c, ', inflection point: ', \n",
    "                #    estimated_t0, ', r2 score: %.2f'% r2_score(y_train_f[:], y_predict_f[0:70]))                     \n",
    "                                \n",
    "            if y_train_c.empty == False:  \n",
    "                lower_c, upper_c = get_bounds_confirm (country, isState, y_train_c)\n",
    "                popt_c, pcov_c = curve_fit(Gompertz, x_train, y_train_c, method='trf', bounds=(lower_c,upper_c))\n",
    "                a_max_c, estimated_c_c, estimated_t0_c = popt_c\n",
    "                y_predict_c = Gompertz(a_max_c, estimated_c_c, x_test, estimated_t0_c)\n",
    "                y_predict_c_dict[state] =  y_predict_c\n",
    "                y_train_c_dict[state]   =  y_train_c\n",
    "                #print('\\nconfirmed state ==> max: ',a_max_c, ', slope: %.2f'% estimated_c_c, ', inflection point: ', \n",
    "                #  estimated_t0_c, ', r2 score: %.2f'% r2_score(y_train_c[:], y_predict_c[0:70]))\n",
    "                            \n",
    "        ## ====== Plot and Store the Results: ======\n",
    "        ## ====== Move the x-axis of trained and test datasets to allign with dates in China ======       \n",
    "        extend_days_test = [i+len(x_test) for i in range(n_days_sans_China)]\n",
    "        x_test      = np.append(x_test, extend_days_test) \n",
    "        extend_days_train = [i+len(x_train) for i in range(n_days_sans_China)]\n",
    "        x_train     = np.append(x_train, extend_days_train)           \n",
    "            \n",
    "        for state, y_predict in y_predict_f_dict.items():\n",
    "            y_predict = np.pad(y_predict, (n_days_sans_China, 0), 'constant') \n",
    "            ax1.plot(x_test, y_predict, linewidth=2, label=state) \n",
    "            #ax1.legend(loc='center left',bbox_to_anchor=(1.0, 0.5)) \n",
    "            test_data.loc[(test_data['Country_Region']==country)&(test_data['Province_State']==state),'Fatalities'] = y_predict[-n_test_days:]\n",
    "        for state, y_train in y_train_f_dict.items():\n",
    "            y_train   = np.pad(y_train, (n_days_sans_China, 0), 'constant')\n",
    "            ax1.plot(x_train, y_train, linewidth=2, color='r', linestyle='dotted', label='train_'+state)             \n",
    "        ax1.set_title(\"Prediction vs Training for Fatalities\")\n",
    "        ax1.set_xlabel(\"Number of days\")\n",
    "        ax1.set_ylabel(\"Fatalities\")   \n",
    "        \n",
    "        \n",
    "        for state, y_predict in y_predict_c_dict.items():\n",
    "            y_predict = np.pad(y_predict, (n_days_sans_China, 0), 'constant') \n",
    "            ax0.plot(x_test, y_predict, linewidth=2, label=state) \n",
    "            ax0.legend(loc='center left',bbox_to_anchor=(1.0, 0.5)) \n",
    "            test_data.loc[(test_data['Country_Region']==country)&(test_data['Province_State']==state),'ConfirmedCases'] = y_predict[-n_test_days:]\n",
    "        for state, y_train in y_train_c_dict.items():\n",
    "            y_train   = np.pad(y_train, (n_days_sans_China, 0), 'constant')\n",
    "            ax0.plot(x_train, y_train, linewidth=2, color='r', linestyle='dotted', label='train_'+country+'_'+state)             \n",
    "        ax0.set_title(\"Prediction vs Training for ConfirmedCases\")\n",
    "        ax0.set_xlabel(\"Number of days\")\n",
    "        ax0.set_ylabel(\"Confirmed Cases\")   \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit_data = pd.read_csv(\"../input/covid19-global-forecasting-week-4/submission.csv\")#, index_col=0)\n",
    "\n",
    "test_data['Fatalities'] = test_data['Fatalities'].fillna(0.0).astype(int)\n",
    "test_data['ConfirmedCases'] = test_data['ConfirmedCases'].fillna(0.0).astype(int)\n",
    "\n",
    "#submit_data['Country_Region'] = test_data['Country_Region']\n",
    "#submit_data['Date'] = test_data['Date']\n",
    "submit_data['Fatalities'] = test_data['Fatalities'].astype('int')\n",
    "submit_data['ConfirmedCases'] = test_data['ConfirmedCases'].astype('int')\n",
    "\n",
    "submit_data.to_csv('submission.csv', index=False)\n",
    "\n",
    "#submit_data = submit_data[['Date','Country_Region','ConfirmedCases', 'Fatalities']]\n",
    "submit_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit_data_1 = submit_data.groupby('Country_Region')[['ConfirmedCases', 'Fatalities']].sum().reset_index()\n",
    "submit_data.to_csv('prova.csv', index=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "select_countries [\"US\"] = submit_data_1[(submit_data_1['Country_Region'] == 'US')]\n",
    "select_countries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **4. NLTK Sentiment Analysis** <a id=\"section4\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython import display\n",
    "import math\n",
    "from pprint import pprint\n",
    "import nltk\n",
    "import seaborn as sns\n",
    "sns.set(style='darkgrid', context='talk', palette='Dark2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BN = pd.read_csv(\"../input/twitter-covid19/BreakingNews.csv\")\n",
    "CNN = pd.read_csv(\"../input/twitter-covid19/cnn.csv\")\n",
    "NYT = pd.read_csv(\"../input/twitter-covid19/NYT.csv\")\n",
    "\n",
    "frames = [BN,CNN,NYT]\n",
    "news = pd.concat(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "labels = news.username.unique()\n",
    "sizes = news.username.value_counts()\n",
    "explode = (0.1, 0, 0)\n",
    "fig, ax = plt.subplots()\n",
    "ax.pie(sizes, labels=labels, autopct='%.1f%%', shadow=True, startangle=90)\n",
    "ax.set_aspect('equal')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = news.text\n",
    "\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer as SIA\n",
    "\n",
    "sia = SIA()\n",
    "results = []\n",
    "\n",
    "for line in text:\n",
    "    pol_score = sia.polarity_scores(line)\n",
    "    pol_score['text'] = line\n",
    "    results.append(pol_score)\n",
    "\n",
    "pprint(results[:3], width=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_records(results)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['label'] = 0\n",
    "df.loc[df['compound'] > 0.2, 'label'] = 1\n",
    "df.loc[df['compound'] < -0.2, 'label'] = -1\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df[['text', 'label']]\n",
    "df.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Positive news:\\n\")\n",
    "pprint(list(df[df['label'] == 1].text)[:5], width=200)\n",
    "\n",
    "print(\"\\nNegative news:\\n\")\n",
    "pprint(list(df[df['label'] == -1].text)[:5], width=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.label.value_counts(normalize=True) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "\n",
    "counts = df.label.value_counts(normalize=True) * 100\n",
    "\n",
    "sns.barplot(x=counts.index, y=counts, ax=ax)\n",
    "\n",
    "ax.set_xticklabels(['Negative', 'Neutral', 'Positive'])\n",
    "ax.set_ylabel(\"Percentage\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize, RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "stop_words = stopwords.words('english')\n",
    "\n",
    "def process_text(headlines):\n",
    "    tokens = []\n",
    "    for line in headlines:\n",
    "        line = line.lower()\n",
    "        toks = tokenizer.tokenize(line)\n",
    "        toks = [t for t in toks if t not in stop_words]\n",
    "        tokens.extend(toks)\n",
    "    \n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_lines = list(df[df.label == 1].text)\n",
    "\n",
    "pos_tokens = process_text(pos_lines)\n",
    "pos_freq = nltk.FreqDist(pos_tokens)\n",
    "\n",
    "pos_freq.most_common(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud,STOPWORDS\n",
    "df_pos = df[df.label == 1].text\n",
    "df_neg = df[df.label == -1].text\n",
    "\n",
    "def wordcloud_draw(data, color = 'black'):\n",
    "    words = ' '.join(data)\n",
    "    cleaned_word = \" \".join([word for word in words.split()\n",
    "                            if 'http' not in word\n",
    "                                and not word.startswith('@')\n",
    "                                and not word.startswith('#')\n",
    "                                and word != 'RT'\n",
    "                            ])\n",
    "    wordcloud = WordCloud(stopwords=STOPWORDS,\n",
    "                      background_color=color,\n",
    "                      width=2500,\n",
    "                      height=2000\n",
    "                     ).generate(cleaned_word)\n",
    "    plt.figure(1,figsize=(13, 13))\n",
    "    plt.imshow(wordcloud)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    \n",
    "print(\"Positive words\")\n",
    "wordcloud_draw(df_pos,'white')\n",
    "print(\"Negative words\")\n",
    "wordcloud_draw(df_neg)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
