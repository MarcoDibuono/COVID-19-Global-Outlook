{"cells":[{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"from IPython.display import Image\nfrom IPython.core.display import HTML \nImage(url= \"https://cdn.downtoearth.org.in/library/large/2020-03-01/0.01792700_1583044755_coronavirus-illustration-carousel.jpg\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# COVID-19 Global Outlook: modelling, prediction and sentiment analysis \n\nIn the context of the global COVID-19 pandemic, we follow the suggestions from Kaggle's competitions in order to provide useful insights about the virus' spread. Starting from a global exploratory analysis, then we focus on virus' modelling and prediction for the countries with the largest number of confirmed cases. For modelling, we implement SIR Model with some extensions and, for prediction, logistic and Gompertz model. At the end, we choose the best model based on R2 score, check the predictions' numbers about confirmed and fatalities for the next time interval and display some results from NLTK Sentiment analysis. \n\nData: [COVID19 Global Forecasting](https://www.kaggle.com/c/covid19-global-forecasting-week-4)\nConsulted kernels: \n\n**TABLE OF CONTENTS**\n\n1. [Exploratory data analysis (EDA)](#section1)\n\n    1.1. [Worldwide Trend](#section11)\n    \n    1.2. [Country-Wise growth](#section12)\n    \n    1.3. [Zoom up to](#section13)\n    \n      1.3.1. [US](#section131)\n      \n      1.3.2. [Europe](#section132)\n      \n      1.3.3. [Asia](#section133)\n      \n    \n2. [Modelling](#section2)\n\n    2.1. [SIR model](#section21)\n    \n    2.2. [SIR-Model with Lockdown](#section22)\n    \n      2.2.1. [Fitting SIR with Lockdown to data](#section131)\n      \n    2.3. [SIR with time-dependent R_0 and CFR](#section21)\n    \n      2.3.1. [Fitting extended SIR to data](#section131)\n    \n    \n3. [Prediction](#section3)\n\n    3.1. [Logistic model](#section31)\n    \n    3.2. [Gompertz model](#section32)\n    \n    \n4. [NLTK Sentiment Analysis](#section4)\n\n    4.1. [Sentiment polarity](#section41)\n  \n    \n5. [Conclusions](#section5)\n"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"import os\nimport numpy as np\nimport pandas as pd\nimport scipy as sp\n\n# --- plotly ---\nfrom plotly import tools, subplots\nimport plotly.offline as py\npy.init_notebook_mode(connected=True)\nimport plotly.graph_objs as go\nimport plotly.express as px\nimport plotly.figure_factory as ff\nimport plotly.io as pio\npio.templates.default = \"plotly_white\"\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"submission_example = pd.read_csv(\"../input/covid19-global-forecasting-week-4/submission.csv\")\ntest = pd.read_csv(\"../input/covid19-global-forecasting-week-4/test.csv\")\ntrain = pd.read_csv(\"../input/covid19-global-forecasting-week-4/train.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"train.rename({'Country_Region': 'country', 'Province_State': 'province', 'Id': 'id', 'Date': 'date', 'ConfirmedCases': 'confirmed', 'Fatalities': 'fatalities'}, axis=1, inplace=True)\ntest.rename({'Country_Region': 'country', 'Province_State': 'province', 'Id': 'id', 'Date': 'date', 'ConfirmedCases': 'confirmed', 'Fatalities': 'fatalities'}, axis=1, inplace=True)\ntrain['country_province'] = train['country'].fillna('') + '/' + train['province'].fillna('')\ntest['country_province'] = test['country'].fillna('') + '/' + test['province'].fillna('')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **1. Exploratory data analysis (EDA)** <a id=\"section1\"></a>"},{"metadata":{},"cell_type":"markdown","source":"### **1.1. Worldwide Trend** <a id=\"section11\"></a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"ww_df = train.groupby('date')[['confirmed', 'fatalities']].sum().reset_index()\nww_df['new_case'] = ww_df['confirmed'] - ww_df['confirmed'].shift(1)\nww_df.tail()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ww_melt_df = pd.melt(ww_df, id_vars=['date'], value_vars=['confirmed', 'fatalities', 'new_case'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = px.line(ww_melt_df, x=\"date\", y=\"value\", color='variable', \n              title=\"Worldwide Confirmed/Death Cases Over Time\")\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = px.line(ww_melt_df, x=\"date\", y=\"value\", color='variable',\n              title=\"Worldwide Confirmed/Death Cases Over Time (Log scale)\",\n             log_y=True)\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ww_df['mortality'] = ww_df['fatalities'] / ww_df['confirmed']\n\nfig = px.line(ww_df, x=\"date\", y=\"mortality\", \n              title=\"Worldwide Mortality Rate Over Time\")\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### **1.2. Country-Wise growth** <a id=\"section12\"></a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"country_df = train.groupby(['date', 'country'])[['confirmed', 'fatalities']].sum().reset_index()\ntarget_date = country_df['date'].max()\n\nprint('Date: ', target_date)\nfor i in [1, 10, 100, 1000, 10000]:\n    n_countries = len(country_df.query('(date == @target_date) & confirmed > @i'))\n    print(f'{n_countries} countries have more than {i} confirmed cases')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"top_country_df = country_df.query('(date == @target_date) & (confirmed > 1000)').sort_values('confirmed', ascending=False)\ntop_country_df = top_country_df.iloc[0:7]\ntop_country_melt_df = pd.melt(top_country_df, id_vars='country', value_vars=['confirmed', 'fatalities'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = px.bar(top_country_melt_df.iloc[::-1],\n             x='value', y='country', color='variable', barmode='group',\n             title=f'Confirmed Cases/Deaths on {target_date}', text='value', height=1500, orientation='h')\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"top10_countries = top_country_df.sort_values('confirmed', ascending=False).iloc[:10]['country'].unique()\ntop10_countries_df = country_df[country_df['country'].isin(top10_countries)]\nfig = px.line(top10_countries_df,\n              x='date', y='confirmed', color='country',\n              title=f'Confirmed Cases for top 10 country as of {target_date}')\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"top10_countries = top_country_df.sort_values('fatalities', ascending=False).iloc[:10]['country'].unique()\ntop10_countries_df = country_df[country_df['country'].isin(top10_countries)]\nfig = px.line(top10_countries_df,\n              x='date', y='fatalities', color='country',\n              title=f'Fatalities for top 10 country as of {target_date}')\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"top_country_df = country_df.query('(date == @target_date) & (confirmed > 100)')\ntop_country_df['mortality_rate'] = top_country_df['fatalities'] / top_country_df['confirmed']\ntop_country_df = top_country_df.sort_values('mortality_rate', ascending=False)\n\nfig = px.bar(top_country_df[:15].iloc[::-1],\n             x='mortality_rate', y='country',\n             title=f'Mortality rate HIGH: top 15 countries on {target_date}', text='mortality_rate', height=800, orientation='h')\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = px.bar(top_country_df[-15:],\n             x='mortality_rate', y='country',\n             title=f'Mortality rate LOW: top 15 countries on {target_date}', text='mortality_rate', height=800, orientation='h')\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = px.scatter_geo(country_df, locations=\"country\", locationmode='country names', \n                     color=\"confirmed\", size='confirmed', hover_name=\"country\", \n                     hover_data=['confirmed', 'fatalities'],\n                     range_color= [0, country_df['confirmed'].max()], \n                     projection=\"natural earth\", animation_frame=\"date\", \n                     title='COVID-19: Confirmed cases spread Over Time', color_continuous_scale=\"portland\")\n# fig.update(layout_coloraxis_showscale=False)\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = px.scatter_geo(country_df, locations=\"country\", locationmode='country names', \n                     color=\"fatalities\", size='fatalities', hover_name=\"country\", \n                     hover_data=['confirmed', 'fatalities'],\n                     range_color= [0, country_df['confirmed'].max()], \n                     projection=\"natural earth\", animation_frame=\"date\", \n                     title='COVID-19: Fatalities growth Over Time', color_continuous_scale=\"portland\")\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## **1.3. Zoom up to** <a id=\"section13\"></a>"},{"metadata":{},"cell_type":"markdown","source":"### **1.3.1. US** <a id=\"section131\"></a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"usa_state_code_df = pd.read_csv(\"../input/usa-state-code/usa_states2.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Prepare data frame only for US. \n\ntrain_us = train.query('country == \"US\"')\ntrain_us['mortality_rate'] = train_us['fatalities'] / train_us['confirmed']\n\n# Convert province column to its 2-char code name,\nstate_name_to_code = dict(zip(usa_state_code_df['state_name'], usa_state_code_df['state_code']))\ntrain_us['province_code'] = train_us['province'].map(state_name_to_code)\n\n# Only show latest days.\ntrain_us_latest = train_us.query('date == @target_date')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = px.choropleth(train_us_latest, locations='province_code', locationmode=\"USA-states\",\n                    color='confirmed', scope=\"usa\", hover_data=['province', 'fatalities', 'mortality_rate'],\n                    title=f'Confirmed cases in US on {target_date}')\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = px.choropleth(train_us_latest, locations='province_code', locationmode=\"USA-states\",\n                    color='mortality_rate', scope=\"usa\", hover_data=['province', 'fatalities', 'mortality_rate'],\n                    title=f'Mortality rate in US on {target_date}')\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### **1.3.2. Europe** <a id=\"section132\"></a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"europe_country_list =list([\n    'Austria','Belgium','Bulgaria','Croatia','Cyprus','Czechia','Denmark','Estonia','Finland','France','Germany','Greece','Hungary','Ireland',\n    'Italy', 'Latvia','Luxembourg','Lithuania','Malta','Norway','Netherlands','Poland','Portugal','Romania','Slovakia','Slovenia',\n    'Spain', 'Sweden', 'United Kingdom', 'Iceland', 'Russia', 'Switzerland', 'Serbia', 'Ukraine', 'Belarus',\n    'Albania', 'Bosnia and Herzegovina', 'Kosovo', 'Moldova', 'Montenegro', 'North Macedonia'])\n\ncountry_df['date'] = pd.to_datetime(country_df['date'])\ntrain_europe = country_df[country_df['country'].isin(europe_country_list)]\n#train_europe['date_str'] = pd.to_datetime(train_europe['date'])\ntrain_europe_latest = train_europe.query('date == @target_date')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = px.choropleth(train_europe_latest, locations=\"country\", \n                    locationmode='country names', color=\"confirmed\", \n                    hover_name=\"country\", range_color=[1, 100000], \n                    color_continuous_scale='portland', \n                    title=f'European Countries with Confirmed Cases as of {target_date}', scope='europe', height=500)\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"europe_country_list =list([\n    'France','Germany',\n    'Italy', \n    'Spain','United Kingdom','Belgium','Netherlands',\"Austria\",\"Portugal\",\"Norway\"])\n\ncountry_df['date'] = pd.to_datetime(country_df['date'])\ntrain_europe = country_df[country_df['country'].isin(europe_country_list)]\ntrain_europe_march = train_europe.query('date > \"2020-03-01\"')\nfig = px.line(train_europe_march,\n              x='date', y='confirmed', color='country',\n              title=f'Confirmed cases by country in Europe, as of {target_date}')\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = px.line(train_europe_march,\n              x='date', y='fatalities', color='country',\n              title=f'Fatalities by country in Europe, as of {target_date}')\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_europe_march['prev_confirmed'] = train_europe_march.groupby('country')['confirmed'].shift(1)\ntrain_europe_march['new_case'] = train_europe_march['confirmed'] - train_europe_march['prev_confirmed']\nfig = px.line(train_europe_march,\n              x='date', y='new_case', color='country',\n              title=f'DAILY NEW Confirmed cases by country in Europe')\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### **1.3.3. Asia** <a id=\"section133\"></a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"country_latest = country_df.query('date == @target_date')\n\nfig = px.choropleth(country_latest, locations=\"country\", \n                    locationmode='country names', color=\"confirmed\", \n                    hover_name=\"country\", range_color=[1, 50000], \n                    color_continuous_scale='portland', \n                    title=f'Asian Countries with Confirmed Cases as of {target_date}', scope='asia', height=800)\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"china_df = train.query('country == \"China\"')\nchina_df['prev_confirmed'] = china_df.groupby('country')['confirmed'].shift(1)\nchina_df['new_case'] = china_df['confirmed'] - china_df['prev_confirmed']\nchina_df.loc[china_df['new_case'] < 0, 'new_case'] = 0.\nfig = px.line(china_df,\n              x='date', y='new_case', color='province',\n              title=f'DAILY NEW Confirmed cases in China by province')\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **2. Modelling** <a id=\"section2\"></a>"},{"metadata":{},"cell_type":"markdown","source":"## **2.1. SIR Model** <a id=\"section21\"></a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n%matplotlib inline \nimport mpld3\nmpld3.enable_notebook()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We have seen some general behavior of the virus in agregated data, for the country where the coronavirus was originated and for four other interesting countries. There's a lot of information to be extracted from this data; for example, we haven't analyzed the effects of long/lat of countries. However, since our main purpose is to develop a predective model in order to understand the key factors that impact the COVID-19 transmission, I'll move on to one of the most famous epidemiologic models: SIR. \n\nSIR is a simple model that considers a population that belongs to one of the following states:\n1. **Susceptible (S)**. The individual hasn't contracted the disease, but she can be infected due to transmisison from infected people\n2. **Infected (I)**. This person has contracted the disease\n3. **Recovered/Deceased (R)**. The disease may lead to one of two destinies: either the person survives, hence developing inmunity to the disease, or the person is deceased. \n\n<img src=\"https://www.lewuathe.com/assets/img/posts/2020-03-11-covid-19-dynamics-with-sir-model/sir.png\" width=\"500px\">\nImage by Kai Sasaki from [lewuathe.com](https://www.lewuathe.com/covid-19-dynamics-with-sir-model.html)\n\nThere are many versions of this model, considering birth and death (SIRD with demography), with intermediate states, etc. However, since we are in the early stages of the COVID-19 expansion and our interest is focused in the short term, we will consider that people develops immunity (in the long term, immunity may be lost and the COVID-19 may come back within a certain seasonality like the common flu) and there is no transition from recovered to the remaining two states. With this, the differential equations that govern the system are:\n\n$$ {dS \\over dt} = - {\\beta S I \\over N} $$\n\n$$ {dI \\over dt} = {\\beta S I \\over N} - \\gamma I$$\n\n$$ {dR \\over dt} = \\gamma I$$\n\nWhere $\\beta$ is the contagion rate of the pathogen and $\\gamma$ is the recovery rate."},{"metadata":{"trusted":true},"cell_type":"code","source":"submission_example = pd.read_csv(\"../input/covid19-global-forecasting-week-4/submission.csv\")\ntest = pd.read_csv(\"../input/covid19-global-forecasting-week-4/test.csv\")\ntrain = pd.read_csv(\"../input/covid19-global-forecasting-week-4/train.csv\")\n\ntrain[\"Country_Region\"] = [country_name.replace(\"'\",\"\") for country_name in train[\"Country_Region\"]]\ntrain = train.groupby(['Country_Region', 'Date'], as_index=False)\ntrain = train.aggregate(np.sum)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from scipy.integrate import odeint\n\n# The SIR model differential equations.\ndef deriv(y, t, N, beta, gamma):\n    S, I, R = y\n    dSdt = -beta * S * I / N\n    dIdt = beta * S * I / N - gamma * I\n    dRdt = gamma * I\n    return dSdt, dIdt, dRdt","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We now want to add *cumulative* Deaths $X$ to the model: $X(t) = \\textit{number of deaths from day 0 to day t}$ for $t\\geq 14$, else $0$. \n\nRecursively, the number of cumulative deaths on day $t$ is equal to the number of cumulative deaths on day $t-1$ (that's $=X(t-1)$) plus the number of newly infected 13 days prior multiplied with the case fatality rate $\\alpha$ (alpha) (I chose 13 days as that is reported as the average time from infection until death in [this study](https://wwwnc.cdc.gov/eid/article/26/6/20-0320_article)).\n\nNow, the number of newly infected 13 days prior (that's the people who can die on day $t$) is equal to the number of infected 14 days prior multiplied with the expected amount of people an infected person infects per day (that's $\\beta$). So the number of newly infected 13 days prior is $\\beta \\cdot I(t-14)$.\n\nPutting it all together: $X(t) = X(t-1) + \\alpha \\cdot \\beta \\cdot I(t-14)$.\n\nThis is equal to the closed form formula $X(t) = \\alpha \\cdot \\beta \\cdot \\displaystyle \\sum_{i=0}^{t-14} I(i)$\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"def SIR_model(N, D, R_0, CaseFatalityRate, max_days):\n    '''\n    N: total population\n    D, R_0, CaseFatalityRate: see texts above\n    '''\n    I0, R0 = 1, 0  # Initial number of infected and recovered individuals (1 infected, 0 recovered) [this R0 has nothing to do with the basic reproduction number R0]\n    S0 = N - I0 - R0 # Initial number of susceptible (everyone else)\n\n    gamma = 1.0 / D  # see texts above\n    beta = R_0 * gamma  # see texts above\n    alpha = CaseFatalityRate\n\n    t = np.linspace(0, max_days, max_days) # Grid of time points (in days)\n\n    # Initial conditions vector\n    y0 = S0, I0, R0\n    # Integrate the SIR equations over the time grid, t.\n    ret = odeint(deriv, y0, t, args=(N, beta, gamma))\n    S, I, R = ret.T\n\n    # Adding deaths (see text above)\n    X = np.zeros(max_days)\n    for day in range(13, max_days):\n        X[day] = sum(I[:day-13])\n    X = alpha * beta * X\n\n\n    # Plot the data on three separate curves for S(t), I(t) and R(t)\n    f, ax = plt.subplots(1,1,figsize=(10,4))\n    ax.plot(t, S, 'b', alpha=0.7, linewidth=2, label='Susceptible')\n    ax.plot(t, I, 'y', alpha=0.7, linewidth=2, label='Infected')\n    ax.plot(t, X, 'r', alpha=0.7, linewidth=2, label='Dead')\n    ax.plot(t, R, 'g', alpha=0.7, linewidth=2, label='Recovered')\n\n    ax.set_xlabel('Time (days)')\n    ax.title.set_text('SIR-Model. Total Population: ' + str(N) + \", Days Infectious: \" + str(D) + \", R_0: \" + str(R_0) + \", CFR: \" + str(CaseFatalityRate*100) + \"%\")\n    # ax.set_ylabel('Number (1000s)')\n    # ax.set_ylim(0,1.2)\n    ax.yaxis.set_tick_params(length=0)\n    ax.xaxis.set_tick_params(length=0)\n    ax.grid(b=True, which='major', c='w', lw=2, ls='-')\n    legend = ax.legend()\n    legend.get_frame().set_alpha(0.5)\n    for spine in ('top', 'right', 'bottom', 'left'):\n        ax.spines[spine].set_visible(False)\n    plt.show();","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **2.2. SIR-Model with Lockdown** <a id=\"section22\"></a>"},{"metadata":{},"cell_type":"markdown","source":"We now want to find suitable parameters (Days infectious, R_0, CFR) for the SIR model\n\nAs I said before, the number of confirmed cases is likely far off from the real number (as not the whole population is getting tested) and thus is not very useful to fit our data to a SIR-Model.\n\nSo, we'll mainly use the number of deceased from the dataset to find parameters for the SIR model. What's important to note is that many countries implemented a *lockdown* that greatly reduces the basic reproduction number R_0; thus, we first tweak the model to allow for a second R_0_2 to come into effect on day L (for lockdown)."},{"metadata":{"trusted":true},"cell_type":"code","source":"def SIR_model_with_lockdown(N, D, R_0, CaseFatalityRate, max_days, L, R_0_2):\n    '''\n    N: total population\n    D, R_0, CaseFatalityRate, ...: see texts above\n    '''\n    # BEFORE LOCKDOWN (same code as first model)\n    I0, R0 = 1, 0  # Initial number of infected and recovered individuals (1 infected, 0 recovered) [this R0 has nothing to do with the basic reproduction number R0]\n    S0 = N - I0 - R0 # Initial number of susceptible (everyone else)\n\n    gamma = 1.0 / D  # see texts above\n    beta = R_0 * gamma  # see texts above\n    alpha = CaseFatalityRate\n\n    t = np.linspace(0, L, L)  # Grid of time points (in days)\n    \n    # Initial conditions vector\n    y0 = S0, I0, R0\n    # Integrate the SIR equations over the time grid, t.\n    ret = odeint(deriv, y0, t, args=(N, beta, gamma))\n    S, I, R = ret.T\n    \n    \n    # AFTER LOCKDOWN\n    I0_2, R0_2, S0_2 = I[-1], R[-1], S[-1]  # beginning of lockdown -> starting Infected/Susceptible/Recovered numbers are the numbers at the end of no-lockdown period\n\n    gamma = 1.0 / D  # same after lockdown\n    beta_2 = R_0_2 * gamma\n    alpha = CaseFatalityRate  # same after lockdown\n\n    t_2 = np.linspace(0, max_days - L + 1, max_days - L + 1)\n    \n    # Initial conditions vector\n    y0_2 = S0_2, I0_2, R0_2\n    # Integrate the SIR equations over the time grid, t.\n    ret_2 = odeint(deriv, y0_2, t_2, args=(N, beta_2, gamma))\n    S_2, I_2, R_2 = ret_2.T\n\n    \n    # COMBINING PERIODS\n    S_full = np.concatenate((S, S_2[1:]))\n    I_full = np.concatenate((I, I_2[1:]))\n    R_full = np.concatenate((R, R_2[1:]))\n    t_full = np.linspace(0, max_days, max_days)\n    \n    # Adding deaths\n    X = np.zeros(max_days)\n    for day in range(13, max_days):\n        for valid_day in range(day-13):\n            if valid_day < L:\n                X[day] += alpha * beta * I_full[valid_day]\n            else:\n                X[day] += alpha * beta_2 * I_full[valid_day]\n\n    \n\n    # Plot the data on three separate curves for S(t), I(t) and R(t)\n    f, ax = plt.subplots(1,1,figsize=(10,4))\n    ax.plot(t_full, S_full, 'b', alpha=0.7, linewidth=2, label='Susceptible')\n    ax.plot(t_full, I_full, 'y', alpha=0.7, linewidth=2, label='Infected')\n    ax.plot(t_full, X, 'r', alpha=0.7, linewidth=2, label='Dead')\n    ax.plot(t_full, R_full, 'g', alpha=0.7, linewidth=2, label='Recovered')\n\n    ax.set_xlabel('Time (days)')\n    ax.title.set_text('SIR-Model with Lockdown. Total Population: ' + str(N) + \n                      \", Days Infectious: \" + str(D) + \", R_0: \" + str(R_0) + \n                      \", CFR: \" + str(CaseFatalityRate*100) + \" R_0_2: \" + str(R_0_2) + \n                      \", L: \" + str(L) + \" days\")\n    # ax.set_ylabel('Number (1000s)')\n    # ax.set_ylim(0,1.2)\n    plt.text(L,N/20,'Lockdown')\n    plt.plot(L, 0, marker='o', markersize=6, color=\"red\")\n    ax.yaxis.set_tick_params(length=0)\n    ax.xaxis.set_tick_params(length=0)\n    ax.grid(b=True, which='major', c='w', lw=2, ls='-')\n    legend = ax.legend()\n    legend.get_frame().set_alpha(0.5)\n    for spine in ('top', 'right', 'bottom', 'left'):\n        ax.spines[spine].set_visible(False)\n    plt.show();","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **2.3 Fitting SIR with Lockdown to data** <a id=\"section23\"></a>"},{"metadata":{},"cell_type":"markdown","source":"We now try to fit the SIR-Model's Dead Curve to real data by tweaking the variables. Some of them are constant:\n* max_days is set to len(train.groupby(\"Date\").sum().index) so that we can compare against all available data\n* N is fixed for each country, that's just the total population\n* L is fixed for each country (the date it went into lockdown)\n* D is set to vary from 5 to 20 (according to this study, it takes on avg. 5 days to show symptoms, at most 14; according to this source (German), people are infectious up to 5 days after onset of symptoms).\n* CFR set to vary from  0.1%−10% \n* R_0 and R_0_2 are set to vary from 0.1 to 3.5"},{"metadata":{"trusted":true},"cell_type":"code","source":"def SIR_model_with_lockdown_deaths(x, N, D, R_0, CaseFatalityRate, max_days, L, R_0_2):\n    # BEFORE LOCKDOWN (same code as first model)\n    I0, R0 = 1, 0  # Initial number of infected and recovered individuals (1 infected, 0 recovered) [this R0 has nothing to do with the basic reproduction number R0]\n    S0 = N - I0 - R0 # Initial number of susceptible (everyone else)\n\n    gamma = 1.0 / D  # see texts above\n    beta = R_0 * gamma  # see texts above\n    alpha = CaseFatalityRate\n\n    t = np.linspace(0, L, L)  # Grid of time points (in days)\n    \n    # Initial conditions vector\n    y0 = S0, I0, R0\n    # Integrate the SIR equations over the time grid, t.\n    ret = odeint(deriv, y0, t, args=(N, beta, gamma))\n    S, I, R = ret.T\n    \n    \n    # AFTER LOCKDOWN\n    I0_2, R0_2, S0_2 = I[-1], R[-1], S[-1]  # beginning of lockdown -> starting Infected/Susceptible/Recovered numbers are the numbers at the end of no-lockdown period\n\n    gamma = 1.0 / D  # same after lockdown\n    beta_2 = R_0_2 * gamma\n    alpha = CaseFatalityRate  # same after lockdown\n\n    t_2 = np.linspace(0, max_days - L + 1, max_days - L + 1)\n    \n    # Initial conditions vector\n    y0_2 = S0_2, I0_2, R0_2\n    # Integrate the SIR equations over the time grid, t.\n    ret_2 = odeint(deriv, y0_2, t_2, args=(N, beta_2, gamma))\n    S_2, I_2, R_2 = ret_2.T\n\n    \n    # COMBINING PERIODS\n    S_full = np.concatenate((S, S_2[1:]))\n    I_full = np.concatenate((I, I_2[1:]))\n    R_full = np.concatenate((R, R_2[1:]))\n    t_full = np.linspace(0, max_days, max_days)\n    \n    # Adding deaths\n    X = np.zeros(max_days)\n    for day in range(13, max_days):\n        for valid_day in range(day-13):\n            if valid_day < L:\n                X[day] += alpha * beta * I_full[valid_day]\n            else:\n                X[day] += alpha * beta_2 * I_full[valid_day]\n    return X[x]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The (hidden as it's almost the same as before) code above defines a function with signature\nSIR_model_with_lockdown_deaths(x, N, D, R_0, CaseFatalityRate, max_days, L, R_0_2)\nthat takes as input the same variables as before and an x and returns the number of fatalities on day x. This function will be used to find suited parameters D, CFR, R_0 and R_0_2 for the model."},{"metadata":{"trusted":true},"cell_type":"code","source":"pip install lmfit","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from lmfit import Model\n\n# Load countries data file (from https://www.kaggle.com/saga21/covid-global-forecast-sir-model-ml-regressions)\nworld_population = pd.read_csv(\"../input/population-by-country-2020/population_by_country_2020.csv\")\n\n# Select desired columns and rename some of them\nworld_population = world_population[['Country (or dependency)', 'Population (2020)', 'Density (P/Km²)', 'Land Area (Km²)', 'Med. Age', 'Urban Pop %']]\nworld_population.columns = ['Country (or dependency)', 'Population (2020)', 'Density', 'Land Area', 'Med Age', 'Urban Pop']\n\n# Replace United States by US\nworld_population.loc[world_population['Country (or dependency)']=='United States', 'Country (or dependency)'] = 'US'\n\n# Remove the % character from Urban Pop values\nworld_population['Urban Pop'] = world_population['Urban Pop'].str.rstrip('%')\n\n# Replace Urban Pop and Med Age \"N.A\" by their respective modes, then transform to int\nworld_population.loc[world_population['Urban Pop']=='N.A.', 'Urban Pop'] = int(world_population.loc[world_population['Urban Pop']!='N.A.', 'Urban Pop'].mode()[0])\nworld_population['Urban Pop'] = world_population['Urban Pop'].astype('int16')\nworld_population.loc[world_population['Med Age']=='N.A.', 'Med Age'] = int(world_population.loc[world_population['Med Age']!='N.A.', 'Med Age'].mode()[0])\nworld_population['Med Age'] = world_population['Med Age'].astype('int16')\n\nworld_population.head(20)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We now define \n1. `fit_SIR`: this function takes a country name, lockdown data (and opt. region name) and first gathers the data (fatalities progression, population, etc.) and then fits the `SIR_model_with_lockdown_deaths`-function from above with fixed N (population), max_days (however many dates are supplied), L (lockdown date) and varying D, R_0, R_0_2, CFR. The function returns the lmfit-module's result object and the country name. The result object contains all we want to know about the curve fitting.\n2. `fitted_plot`: this function takes a lmfit-result-object and country name and plots the fitted SIR-model against the real curve."},{"metadata":{"trusted":true},"cell_type":"code","source":"lockdown_dates = {\"Italy\": \"2020-03-10\", \"Spain\": \"2020-03-15\", \"US\": \"2020-03-20\", \"Germany\": \"2020-03-23\", \"France\": \"2020-03-17\", \"United Kingdom\":\"2020-03-23\", \"China\":\"2020-01-23\", \"Iran\":\"2020-03-25\"}\n\ndef fit_SIR(country_name, lockdown_date=None):\n    \"\"\"\n    y_data: the fatalities data of one country/region (array)\n    population: total population of country\n    lockdown_date: format YYYY-MM-DD\n    \"\"\"\n    if lockdown_date is None:\n        lockdown_date = lockdown_dates[country_name]\n        \n    y_data = train[(train[\"Country_Region\"] == country_name)].Fatalities.values\n    max_days = len(train.groupby(\"Date\").sum().index) # constant for all countries\n\n    # country specific values\n    N = world_population.loc[world_population['Country (or dependency)'] == country_name][\"Population (2020)\"].values[0]\n    L = train.groupby(\"Date\").sum().index.tolist().index(lockdown_date)  # index of the lockdown date\n\n    # x_data is just [0, 1, ..., max_days] array\n    x_data = np.linspace(0, max_days - 1, max_days, dtype=int)\n    \n    # curve fitting from here\n    mod = Model(SIR_model_with_lockdown_deaths)\n\n    # initial values and bounds\n    mod.set_param_hint('N', value=N)\n    mod.set_param_hint('max_days', value=max_days)\n    mod.set_param_hint('L', value=L)\n    mod.set_param_hint('D', value=10, min=4, max=25)\n    mod.set_param_hint('CaseFatalityRate', value=0.01, min=0.0001, max=0.1)\n    mod.set_param_hint('R_0', value=2.0, min=0.1, max=5.0)\n    mod.set_param_hint('R_0_2', value=2.0, min=0.1, max=5.0)\n\n    params = mod.make_params()\n\n    # fixing constant parameters\n    params['N'].vary = False\n    params['max_days'].vary = False\n    params['L'].vary = False\n\n    result = mod.fit(y_data, params, x=x_data, method=\"least_squares\")\n    \n    return result, country_name\n\ndef fitted_plot(result, country_name, region_name=None):\n    y_data = train[(train[\"Country_Region\"] == country_name)].Fatalities.values\n    max_days = len(train.groupby(\"Date\").sum().index) # constant for all countries\n    x_data = np.linspace(0, max_days - 1, max_days, dtype=int)\n    x_ticks = train[train[\"Country_Region\"] == \"Germany\"].Date.values  # same for all countries\n    \n    plt.figure(figsize=(10,5))\n    \n    real_data, = plt.plot(x_data, y_data, 'bo', label=\"real data\")\n    SIR_fit = plt.plot(x_data, result.best_fit, 'r-', label=\"SIR model\")\n    \n    plt.xlabel(\"Day\")\n    plt.xticks(x_data[::10], x_ticks[::10])\n    plt.ylabel(\"Fatalities\")\n    plt.title(\"Real Data vs SIR-Model in \" + country_name)\n    plt.legend(numpoints=1, loc=2, frameon=None)\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"result, _ = fit_SIR(\"Italy\")\nprint(result.fit_report())\nfitted_plot(result, \"Italy\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"result, _ = fit_SIR(\"Spain\")\nprint(result.fit_report())\nfitted_plot(result, \"Spain\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"result, _ = fit_SIR(\"Germany\")\nprint(result.fit_report())\nfitted_plot(result, \"Germany\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"result, _ = fit_SIR(\"France\")\nprint(result.fit_report())\nfitted_plot(result, \"France\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"result, _ = fit_SIR(\"US\")\nprint(result.fit_report())\nfitted_plot(result, \"US\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"result, _ = fit_SIR(\"United Kingdom\")\nprint(result.fit_report())\nfitted_plot(result, \"United Kingdom\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"result, _ = fit_SIR(\"China\")\nprint(result.fit_report())\nfitted_plot(result, \"China\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"result, _ = fit_SIR(\"Iran\")\nprint(result.fit_report())\nfitted_plot(result, \"Iran\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **2.4 SIR with time-dependent R_0 and CFR** <a id=\"section24\"></a>"},{"metadata":{},"cell_type":"markdown","source":"While the prior models are able to capture some of the aspects of the virus quite well, it's not that hard to fit the curves to the outbreak period as they all look quite similar. To make better predictions, we now treat R_0 and CFR as functions. For example, there is no determined \"Lockdown\" date anymore at which R_0 jumps to a different value; it can now change continuously. Also, the CFR was until now treated as constant, however, with more people infected, treatment becomes less available and the case fatality rate increases. Now, CFR is treated as a function of the ratio $\\frac{I(t)}{N}$ (the fraction of infected of the total population):\n\n$CFR(t) = s \\cdot \\frac{I(t)}{N} + \\alpha_{OPT}$, with $s$ being some arbitrary but fixed scaling factor and $\\alpha_{OPT}$ being the CFR with optimal treatment available.\n\n$R_{0}$ will be fitted to one of several different possible distributions we'll look at."},{"metadata":{"trusted":true},"cell_type":"code","source":"def extended_deriv(y, t, N, beta, gamma):\n    S, I, R = y\n    dSdt = -beta(t) * S * I / N\n    dIdt = beta(t) * S * I / N - gamma * I\n    dRdt = gamma * I\n    return dSdt, dIdt, dRdt","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def extended_SIR(N, D, max_days, CFR_OPT, CFR_scaling_factor, R_0, **R_0_kwargs):\n    '''\n    R_0: callable\n    '''\n    I0, R0 = 1, 0  # Initial number of infected and recovered individuals (1 infected, 0 recovered) [this R0 has nothing to do with the basic reproduction number R0]\n    S0 = N - I0 - R0 # Initial number of susceptible (everyone else)\n\n    gamma = 1.0 / D  # see texts above\n\n    def beta(t):\n        return R_0(t, **R_0_kwargs) * gamma\n\n    t = np.linspace(0, max_days, max_days)  # Grid of time points (in days)\n    \n    # Initial conditions vector\n    y0 = S0, I0, R0\n    # Integrate the SIR equations over the time grid, t.\n    ret = odeint(extended_deriv, y0, t, args=(N, beta, gamma))\n    S, I, R = ret.T\n\n    def CFR(t):\n        return CFR_OPT + CFR_scaling_factor * (I[t] / N)\n\n    # Adding deaths\n    X = np.zeros(max_days)\n    for day in range(13, max_days):\n        for valid_day in range(day-13):\n            X[day] += CFR(valid_day) * beta(valid_day) * I[valid_day]\n\n    return t, S, I, R, X, [R_0(t, **R_0_kwargs) for t in range(max_days)], N, [CFR(t) for t in range(max_days)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_extended_SIR(t, S, I, R, X, R_0, N, CFR):\n    # Plot the data on three separate curves for S(t), I(t) and R(t)\n    f, ax = plt.subplots(1,1,figsize=(10,4))\n    ax.plot(t, S, 'b', alpha=0.7, linewidth=2, label='Susceptible')\n    ax.plot(t, I, 'y', alpha=0.7, linewidth=2, label='Infected')\n    ax.plot(t, X, 'r', alpha=0.7, linewidth=2, label='Dead')\n    ax.plot(t, R, 'g', alpha=0.7, linewidth=2, label='Recovered')\n\n    ax.set_xlabel('Time (days)')\n    ax.title.set_text('SIR-Model with varying R_0 and CFR')\n    # ax.set_ylabel('Number (1000s)')\n    # ax.set_ylim(0,1.2)\n    ax.yaxis.set_tick_params(length=0)\n    ax.xaxis.set_tick_params(length=0)\n    ax.grid(b=True, which='major', c='w', lw=2, ls='-')\n    legend = ax.legend()\n    legend.get_frame().set_alpha(0.5)\n    for spine in ('top', 'right', 'bottom', 'left'):\n        ax.spines[spine].set_visible(False)\n    plt.show();\n    \n    \n    # plt.figure(figsize=(10,4))\n    \n    f = plt.figure(figsize=(10,4))\n    \n    # sp1\n    ax1 = f.add_subplot(121)\n    ax1.plot(t, R_0, 'b--', alpha=0.7, linewidth=2, label='R_0')\n    \n    ax1.set_xlabel('Time (days)')\n    ax1.title.set_text('R_0 over time')\n    # ax.set_ylabel('Number (1000s)')\n    # ax.set_ylim(0,1.2)\n    ax1.yaxis.set_tick_params(length=0)\n    ax1.xaxis.set_tick_params(length=0)\n    ax1.grid(b=True, which='major', c='w', lw=2, ls='-')\n    legend = ax1.legend()\n    legend.get_frame().set_alpha(0.5)\n    for spine in ('top', 'right', 'bottom', 'left'):\n        ax.spines[spine].set_visible(False)\n\n    # sp2\n    ax2 = f.add_subplot(122)\n    ax2.plot(t, CFR, 'r--', alpha=0.7, linewidth=2, label='CFR')\n    \n    ax2.set_xlabel('Time (days)')\n    ax2.title.set_text('CFR over time')\n    # ax.set_ylabel('Number (1000s)')\n    # ax.set_ylim(0,1.2)\n    ax2.yaxis.set_tick_params(length=0)\n    ax2.xaxis.set_tick_params(length=0)\n    ax2.grid(b=True, which='major', c='w', lw=2, ls='-')\n    legend = ax2.legend()\n    legend.get_frame().set_alpha(0.5)\n    for spine in ('top', 'right', 'bottom', 'left'):\n        ax.spines[spine].set_visible(False)\n\n    plt.show();","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"N = 1_000\nD = 4\nmax_days = 100\n\nI0, R0 = 1, 0\nS0 = N - I0 - R0\ns = CFR_scaling_factor = 0.1\nCFR_OPT = 0.02  # noone in hospital -> only 2% die\n\ndef new_R0(t, a, b, c):\n    return a / (1 + (t/c)**b)\n\n\nplot_extended_SIR(*extended_SIR(N, D, max_days, CFR_OPT, CFR_scaling_factor, new_R0, a=3.0, b=1.5, c=50))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## **2.4.1. Fitting extended SIR to data** <a id=\"section241\"></a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"def fit_extended_SIR(country_name, R_0_function, region_name=None, fit_method=\"least_squares\", **R_0_kwargs):\n\n    y_data = train[(train[\"Country_Region\"] == country_name)].Fatalities.values\n    max_days = len(train.groupby(\"Date\").sum().index) # constant for all countries\n    # country specific values\n    N = world_population.loc[world_population['Country (or dependency)'] == country_name][\"Population (2020)\"].values[0]\n\n    # x_data is just [0, 1, ..., max_days] array\n    x_data = np.linspace(0, max_days - 1, max_days, dtype=int)\n\n    # curve fitting from here\n    def extended_SIR_deaths(x, N, D, max_days, CFR_OPT, CFR_scaling_factor, **R_0_kwargs):\n        t_, S_, I_, R_, X, R_0_, N_, CFR_ = extended_SIR(N, D, max_days, CFR_OPT, CFR_scaling_factor, R_0=R_0_function, **R_0_kwargs)\n        return X[x]\n\n    mod = Model(extended_SIR_deaths)\n\n    # initial values and bounds\n    mod.set_param_hint('N', value=N, vary=False)\n    mod.set_param_hint('max_days', value=max_days, vary=False)\n\n    mod.set_param_hint('D', value=10, min=4, max=25)\n    mod.set_param_hint('CFR_OPT', value=0.01, min=0.0001, max=0.1)\n    mod.set_param_hint('CFR_scaling_factor', value=0.1, min=0.0001, max=1.0)\n    if R_0_kwargs:\n        for arg in R_0_kwargs:\n            mod.set_param_hint(arg, value=R_0_kwargs[arg])\n\n    params = mod.make_params()\n    # print(params)\n    result = mod.fit(y_data, params, method=fit_method, x=x_data)\n    \n    # fetch some result parameters\n    CFR_OPT = result.params[\"CFR_OPT\"].value\n    CFR_scaling_factor = result.params[\"CFR_scaling_factor\"].value\n    R_0_result_params = {}\n    for val in R_0_kwargs:\n        R_0_result_params[val] = result.params[val].value\n\n    \n    # return result, country_name\n    return result, country_name, N, D, max_days, CFR_OPT, CFR_scaling_factor, R_0_function, R_0_result_params\n\ndef fitted_plot_extended(result, country_name, region_name=None):\n    y_data = train[(train[\"Country_Region\"] == country_name)].Fatalities.values\n    max_days = len(train.groupby(\"Date\").sum().index) # constant for all countries\n    x_data = np.linspace(0, max_days - 1, max_days, dtype=int)\n    x_ticks = train[train[\"Country_Region\"] == \"Germany\"].Date.values  # same for all countries\n    \n    plt.figure(figsize=(10,5))\n    \n    real_data, = plt.plot(x_data, y_data, 'bo', label=\"real data\")\n    SIR_fit = plt.plot(x_data, result.best_fit, 'r-', label=\"SIR model\")\n    \n    plt.xlabel(\"Day\")\n    plt.xticks(x_data[::10], x_ticks[::10])\n    plt.ylabel(\"Fatalities\")\n    plt.title(\"Real Data vs SIR-Model in \" + country_name)\n    plt.legend(numpoints=1, loc=2, frameon=None)\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def new_R0(t, a, b, c):\n    return a / (1 + (t/c)**b)\n\nresult, country_name, N, D, max_days, CFR_OPT, CFR_scaling_factor, R_0_function, R_0_result_params = fit_extended_SIR(\"Italy\", new_R0, region_name=None, fit_method=\"least_squares\", a=3.0, b=1.5, c=50)\nprint(result.fit_report())\nfitted_plot(result, \"Italy\");\nplot_extended_SIR(*extended_SIR(N, D, max_days, CFR_OPT, CFR_scaling_factor, R_0_function, **R_0_result_params))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def new_R0(t, a, b, c):\n    return a / (1 + (t/c)**b)\n\nresult, country_name, N, D, max_days, CFR_OPT, CFR_scaling_factor, R_0_function, R_0_result_params = fit_extended_SIR(\"Spain\", new_R0, region_name=None, fit_method=\"least_squares\", a=3.0, b=1.5, c=50)\nprint(result.fit_report())\nfitted_plot(result, \"Spain\");\nplot_extended_SIR(*extended_SIR(N, D, max_days, CFR_OPT, CFR_scaling_factor, R_0_function, **R_0_result_params))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def new_R0(t, a, b, c):\n    return a / (1 + (t/c)**b)\n\nresult, country_name, N, D, max_days, CFR_OPT, CFR_scaling_factor, R_0_function, R_0_result_params = fit_extended_SIR(\"US\", new_R0, region_name=None, fit_method=\"least_squares\", a=3.0, b=1.5, c=50)\nprint(result.fit_report())\nfitted_plot(result, \"US\");\nplot_extended_SIR(*extended_SIR(N, D, max_days, CFR_OPT, CFR_scaling_factor, R_0_function, **R_0_result_params))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def new_R0(t, a, b, c):\n    return a / (1 + (t/c)**b)\n\nresult, country_name, N, D, max_days, CFR_OPT, CFR_scaling_factor, R_0_function, R_0_result_params = fit_extended_SIR(\"Germany\", new_R0, region_name=None, fit_method=\"least_squares\", a=3.0, b=1.5, c=50)\nprint(result.fit_report())\nfitted_plot(result, \"Germany\");\nplot_extended_SIR(*extended_SIR(N, D, max_days, CFR_OPT, CFR_scaling_factor, R_0_function, **R_0_result_params))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def new_R0(t, a, b, c):\n    return a / (1 + (t/c)**b)\n\nresult, country_name, N, D, max_days, CFR_OPT, CFR_scaling_factor, R_0_function, R_0_result_params = fit_extended_SIR(\"United Kingdom\", new_R0, region_name=None, fit_method=\"least_squares\", a=3.0, b=1.5, c=50)\nprint(result.fit_report())\nfitted_plot(result, \"United Kingdom\");\nplot_extended_SIR(*extended_SIR(N, D, max_days, CFR_OPT, CFR_scaling_factor, R_0_function, **R_0_result_params))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def new_R0(t, a, b, c):\n    return a / (1 + (t/c)**b)\n\nresult, country_name, N, D, max_days, CFR_OPT, CFR_scaling_factor, R_0_function, R_0_result_params = fit_extended_SIR(\"China\", new_R0, region_name=None, fit_method=\"least_squares\", a=3.0, b=1.5, c=50)\nprint(result.fit_report())\nfitted_plot(result, \"China\");\nplot_extended_SIR(*extended_SIR(N, D, max_days, CFR_OPT, CFR_scaling_factor, R_0_function, **R_0_result_params))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def new_R0(t, a, b, c):\n    return a / (1 + (t/c)**b)\n\nresult, country_name, N, D, max_days, CFR_OPT, CFR_scaling_factor, R_0_function, R_0_result_params = fit_extended_SIR(\"Iran\", new_R0, region_name=None, fit_method=\"least_squares\", a=3.0, b=1.5, c=50)\nprint(result.fit_report())\nfitted_plot(result, \"Iran\");\nplot_extended_SIR(*extended_SIR(N, D, max_days, CFR_OPT, CFR_scaling_factor, R_0_function, **R_0_result_params))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **3. Prediction** <a id=\"section3\"></a>"},{"metadata":{},"cell_type":"markdown","source":"## **3.1 Logistic model** <a id=\"section31\"></a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"import seaborn as sns\nfrom sklearn.utils import shuffle\nfrom sklearn.svm import SVC\nfrom sklearn.metrics import confusion_matrix,classification_report\nfrom sklearn.model_selection import cross_val_score, GridSearchCV\nimport scipy.optimize as opt\nimport os","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission_example = pd.read_csv(\"../input/covid19-global-forecasting-week-4/submission.csv\")\ntest = pd.read_csv(\"../input/covid19-global-forecasting-week-4/test.csv\")\ntrain = pd.read_csv(\"../input/covid19-global-forecasting-week-4/train.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_ = train[train[\"ConfirmedCases\"] >= 0]\ntrain_.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Replace all na (Province_State) with country:"},{"metadata":{"trusted":true},"cell_type":"code","source":"EMPTY_VAL = \"EMPTY_VAL\"\n\ndef fillState(state, country):\n    if state == EMPTY_VAL: return country\n    return state\n\ntrain_['Province_State'].fillna(EMPTY_VAL, inplace=True)\ntrain_['Province_State'] = train_.loc[:, ['Province_State', 'Country_Region']].apply(lambda x : fillState(x['Province_State'], x['Country_Region']), axis=1)\ntest['Province_State'].fillna(EMPTY_VAL, inplace=True)\ntest['Province_State'] = test.loc[:, ['Province_State', 'Country_Region']].apply(lambda x : fillState(x['Province_State'], x['Country_Region']), axis=1)\ntest.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_['row_number'] = train_.groupby(['Country_Region', 'Province_State']).cumcount()\nx = train_[train_[\"Country_Region\"] == 'US'][train_[\"Province_State\"] == 'New York']['row_number']\ny = train_[train_[\"Country_Region\"] == 'US'][train_[\"Province_State\"] == 'New York']['ConfirmedCases']\ny_ = train_[train_[\"Country_Region\"] == 'US'][train_[\"Province_State\"] == 'New York']['Fatalities']\n\ndef f(x, L, b, k, x_0):\n    return L / (1. + np.exp(-k * (x - x_0))) + b\n\n\ndef logistic(xs, L, k, x_0):\n    result = []\n    for x in xs:\n        xp = k*(x-x_0)\n        if xp >= 0:\n            result.append(L / ( 1. + np.exp(-xp) ) )\n        else:\n            result.append(L * np.exp(xp) / ( 1. + np.exp(xp) ) )\n    return result\n\np0 = [max(y), 0.0,max(x)]\np0_ = [max(y_), 0.0,max(x)]\nx_ = np.arange(0, 100, 1).tolist()\ntry:\n    popt, pcov = opt.curve_fit(logistic, x, y,p0)\n    yfit = logistic(x_, *popt)\n    popt_, pcov_ = opt.curve_fit(logistic, x, y_,p0_)\n    yfit_ = logistic(x_, *popt_)\nexcept:\n    popt, pcov = opt.curve_fit(f, x, y, method=\"lm\", maxfev=5000)\n    yfit = f(x_, *popt)\n    popt_, pcov_ = opt.curve_fit(f, x, y_, method=\"lm\", maxfev=5000)\n    yfit_ = f(x_, *popt_)\n    #print(\"problem\")\n\n\nfig, ax = plt.subplots(1, 1, figsize=(10, 8))\nax.plot(x, y, 'o', label ='Actual Cases')\nax.plot(x_, yfit, '-', label ='Fitted Cases')\n\nax.plot(x, y_, 'o', label ='Actual Fatalities')\nax.plot(x_, yfit_, '-', label ='Fitted fatalities')\nax.title.set_text('US - New York')\nplt.legend(loc=\"center right\")\nplt.show()\n\ncorrelation_matrix = np.corrcoef(y[1:73], yfit[1:73])\ncorrelation_xy = correlation_matrix[0,1]\nr_squared = correlation_xy**2\nr_squared\n\ncorrelation_matrix = np.corrcoef(y_[1:73], yfit_[1:73])\ncorrelation_xy = correlation_matrix[0,1]\nr_squared1 = correlation_xy**2\nr_squared1\n\nprint(\"The R^2 for the Actual Cases is:\", r_squared,\"\\n\\n The R^2 for the Fatalities is:\",r_squared1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_['row_number'] = train_.groupby(['Country_Region', 'Province_State']).cumcount()\nx = train_[train_[\"Country_Region\"] == 'Italy'][train_[\"Province_State\"] == 'Italy']['row_number']\ny = train_[train_[\"Country_Region\"] == 'Italy'][train_[\"Province_State\"] == 'Italy']['ConfirmedCases']\ny_ = train_[train_[\"Country_Region\"] == 'Italy'][train_[\"Province_State\"] == 'Italy']['Fatalities']\n\nfig, ax = plt.subplots(1, 1, figsize=(10, 8))\nax.plot(x, y, 'o', label ='Actual Cases')\nax.plot(x_, yfit, '-', label ='Fitted Cases')\n\nax.plot(x, y_, 'o', label ='Actual Fatalities')\nax.plot(x_, yfit_, '-', label ='Fitted fatalities')\nax.title.set_text('Italy')\nplt.legend(loc=\"center right\")\nplt.show()\n\ncorrelation_matrix = np.corrcoef(y[1:73], yfit[1:73])\ncorrelation_xy = correlation_matrix[0,1]\nr_squared = correlation_xy**2\nr_squared\n\ncorrelation_matrix = np.corrcoef(y_[1:73], yfit_[1:73])\ncorrelation_xy = correlation_matrix[0,1]\nr_squared1 = correlation_xy**2\nr_squared1\n\nprint(\"The R^2 for the Actual Cases is:\", r_squared,\"\\n\\n The R^2 for the Fatalities is:\",r_squared1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_['row_number'] = train_.groupby(['Country_Region', 'Province_State']).cumcount()\nx = train_[train_[\"Country_Region\"] == 'Spain'][train_[\"Province_State\"] == 'Spain']['row_number']\ny = train_[train_[\"Country_Region\"] == 'Spain'][train_[\"Province_State\"] == 'Spain']['ConfirmedCases']\ny_ = train_[train_[\"Country_Region\"] == 'Spain'][train_[\"Province_State\"] == 'Spain']['Fatalities']\n\nfig, ax = plt.subplots(1, 1, figsize=(10, 8))\nax.plot(x, y, 'o', label ='Actual Cases')\nax.plot(x_, yfit, '-', label ='Fitted Cases')\n\nax.plot(x, y_, 'o', label ='Actual Fatalities')\nax.plot(x_, yfit_, '-', label ='Fitted fatalities')\nax.title.set_text('Spain')\nplt.legend(loc=\"center right\")\nplt.show()\n\ncorrelation_matrix = np.corrcoef(y[1:73], yfit[1:73])\ncorrelation_xy = correlation_matrix[0,1]\nr_squared = correlation_xy**2\nr_squared\n\ncorrelation_matrix = np.corrcoef(y_[1:73], yfit_[1:73])\ncorrelation_xy = correlation_matrix[0,1]\nr_squared1 = correlation_xy**2\nr_squared1\n\nprint(\"The R^2 for the Actual Cases is:\", r_squared,\"\\n\\n The R^2 for the Fatalities is:\",r_squared1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_['row_number'] = train_.groupby(['Country_Region', 'Province_State']).cumcount()\nx = train_[train_[\"Country_Region\"] == 'Germany'][train_[\"Province_State\"] == 'Germany']['row_number']\ny = train_[train_[\"Country_Region\"] == 'Germany'][train_[\"Province_State\"] == 'Germany']['ConfirmedCases']\ny_ = train_[train_[\"Country_Region\"] == 'Germany'][train_[\"Province_State\"] == 'Germany']['Fatalities']\n\nfig, ax = plt.subplots(1, 1, figsize=(10, 8))\nax.plot(x, y, 'o', label ='Actual Cases')\nax.plot(x_, yfit, '-', label ='Fitted Cases')\n\nax.plot(x, y_, 'o', label ='Actual Fatalities')\nax.plot(x_, yfit_, '-', label ='Fitted fatalities')\nax.title.set_text('Germany')\nplt.legend(loc=\"center right\")\nplt.show()\n\ncorrelation_matrix = np.corrcoef(y[1:73], yfit[1:73])\ncorrelation_xy = correlation_matrix[0,1]\nr_squared = correlation_xy**2\nr_squared\n\ncorrelation_matrix = np.corrcoef(y_[1:73], yfit_[1:73])\ncorrelation_xy = correlation_matrix[0,1]\nr_squared1 = correlation_xy**2\nr_squared1\n\nprint(\"The R^2 for the Actual Cases is:\", r_squared,\"\\n\\n The R^2 for the Fatalities is:\",r_squared1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_['row_number'] = train_.groupby(['Country_Region', 'Province_State']).cumcount()\nx = train_[train_[\"Country_Region\"] == 'United Kingdom'][train_[\"Province_State\"] == 'United Kingdom']['row_number']\ny = train_[train_[\"Country_Region\"] == 'United Kingdom'][train_[\"Province_State\"] == 'United Kingdom']['ConfirmedCases']\ny_ = train_[train_[\"Country_Region\"] == 'United Kingdom'][train_[\"Province_State\"] == 'United Kingdom']['Fatalities']\n\nfig, ax = plt.subplots(1, 1, figsize=(10, 8))\nax.plot(x, y, 'o', label ='Actual Cases')\nax.plot(x_, yfit, '-', label ='Fitted Cases')\n\nax.plot(x, y_, 'o', label ='Actual Fatalities')\nax.plot(x_, yfit_, '-', label ='Fitted fatalities')\nax.title.set_text('United Kingdom')\nplt.legend(loc=\"center right\")\nplt.show()\n\ncorrelation_matrix = np.corrcoef(y[1:73], yfit[1:73])\ncorrelation_xy = correlation_matrix[0,1]\nr_squared = correlation_xy**2\nr_squared\n\ncorrelation_matrix = np.corrcoef(y_[1:73], yfit_[1:73])\ncorrelation_xy = correlation_matrix[0,1]\nr_squared1 = correlation_xy**2\nr_squared1\n\nprint(\"The R^2 for the Actual Cases is:\", r_squared,\"\\n\\n The R^2 for the Fatalities is:\",r_squared1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_['row_number'] = train_.groupby(['Country_Region', 'Province_State']).cumcount()\nx = train_[train_[\"Country_Region\"] == 'Iran'][train_[\"Province_State\"] == 'Iran']['row_number']\ny = train_[train_[\"Country_Region\"] == 'Iran'][train_[\"Province_State\"] == 'Iran']['ConfirmedCases']\ny_ = train_[train_[\"Country_Region\"] == 'Iran'][train_[\"Province_State\"] == 'Iran']['Fatalities']\n\nfig, ax = plt.subplots(1, 1, figsize=(10, 8))\nax.plot(x, y, 'o', label ='Actual Cases')\nax.plot(x_, yfit, '-', label ='Fitted Cases')\n\nax.plot(x, y_, 'o', label ='Actual Fatalities')\nax.plot(x_, yfit_, '-', label ='Fitted fatalities')\nax.title.set_text('Iran')\nplt.legend(loc=\"center right\")\nplt.show()\n\ncorrelation_matrix = np.corrcoef(y[1:73], yfit[1:73])\ncorrelation_xy = correlation_matrix[0,1]\nr_squared = correlation_xy**2\nr_squared\n\ncorrelation_matrix = np.corrcoef(y_[1:73], yfit_[1:73])\ncorrelation_xy = correlation_matrix[0,1]\nr_squared1 = correlation_xy**2\nr_squared1\n\nprint(\"The R^2 for the Actual Cases is:\", r_squared,\"\\n\\n The R^2 for the Fatalities is:\",r_squared1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## **3.2. Gompertz model** <a id=\"section32\"></a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"from itertools import cycle, islice\nimport seaborn as sb\nimport matplotlib.dates as dates\nimport datetime as dt\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nfrom itertools import cycle, islice\n\nimport plotly.offline as py\npy.init_notebook_mode(connected=True)\nfrom plotly import tools, subplots\nimport plotly.figure_factory as ff\nimport plotly.express as px\nimport plotly.graph_objects as go\n\nfrom sklearn.linear_model import Ridge\nfrom sklearn.preprocessing import PolynomialFeatures \nfrom sklearn.pipeline import make_pipeline\nfrom tqdm import tqdm\n\nfrom scipy.optimize.minpack import curve_fit\nfrom sklearn.metrics import r2_score\nfrom scipy.special import expit","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_data = pd.read_csv(\"../input/covid19-global-forecasting-week-4/test.csv\")\ntrain_data = pd.read_csv(\"../input/covid19-global-forecasting-week-4/train.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data['NewConfirmedCases'] = train_data['ConfirmedCases'] - train_data['ConfirmedCases'].shift(1)\ntrain_data['NewConfirmedCases'] = train_data['NewConfirmedCases'].fillna(0.0)\ntrain_data['NewFatalities']     = train_data['Fatalities'] - train_data['Fatalities'].shift(1)\ntrain_data['NewFatalities']     = train_data['NewFatalities'].fillna(0.0)#.astype(int)\n\ntrain_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def getColumnInfo(df):\n    n_province =  df['Province_State'].nunique()\n    n_country  =  df['Country_Region'].nunique()\n    n_days     =  df['Date'].nunique()\n    start_date =  df['Date'].unique()[0]\n    end_date   =  df['Date'].unique()[-1]\n    return n_province, n_country, n_days, start_date, end_date\n\nn_train = train_data.shape[0]\nn_test = test_data.shape[0]\n\nn_prov_train, n_count_train, n_train_days, start_date_train, end_date_train = getColumnInfo(train_data)\nn_prov_test,  n_count_test,  n_test_days,  start_date_test,  end_date_test  = getColumnInfo(test_data)\ndf_test = test_data.loc[test_data.Date > '2020-04-03']\noverlap_days = n_test_days - df_test.Date.nunique()\n\nprob_confirm_check_train = train_data.ConfirmedCases.value_counts(normalize=True)\nprob_fatal_check_train = train_data.Fatalities.value_counts(normalize=True)\n\nn_confirm_train = train_data.ConfirmedCases.value_counts()[1:].sum()\nn_fatal_train = train_data.Fatalities.value_counts()[1:].sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#train_data_by_country = train_data.groupby(['Country_Region'],as_index=True).agg({'ConfirmedCases': 'max', 'Fatalities': 'max'})\n#train_data_by_country_confirm = train_data_by_country.sort_values(by=[\"ConfirmedCases\"], ascending=False)\ntrain_data_by_country = train_data.groupby(['Date','Country_Region'],as_index=False).agg({'ConfirmedCases': 'sum', 'Fatalities': 'sum'\n                                                                                         })\n                                                       #'GrowthRate':'mean'\nmax_train_date = train_data['Date'].max()\ntrain_data_by_country_confirm = train_data_by_country.query('(Date == @max_train_date) & (ConfirmedCases > 100)').sort_values('ConfirmedCases', ascending=False)\ntrain_data_by_country_confirm.set_index('Country_Region', inplace=True)\ndisplay(train_data_by_country_confirm.head())\n\nfrom itertools import cycle, islice\ndiscrete_col = list(islice(cycle(['orange', 'r', 'g', 'k', 'b', 'c', 'm']), None, len(train_data_by_country_confirm.head(30))))\nplt.rcParams.update({'font.size': 22})\ntrain_data_by_country_confirm.head(20).plot(figsize=(20,15), kind='barh', color=discrete_col)\nplt.legend([\"Confirmed Cases\", \"Fatalities\"]);\nplt.xlabel(\"Number of Covid-19 Affectees\")\nplt.title(\"First 20 Countries with Highest Confirmed Cases\")\nylocs, ylabs = plt.yticks()\nfor i, v in enumerate(train_data_by_country_confirm.head(20)[\"ConfirmedCases\"][:]):\n    plt.text(v+0.01, ylocs[i]-0.25, str(int(v)), fontsize=12)\nfor i, v in enumerate(train_data_by_country_confirm.head(20)[\"Fatalities\"][:]):\n    if v > 0: #disply for only >300 fatalities\n        plt.text(v+0.01,ylocs[i]+0.1,str(int(v)),fontsize=12)  ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"''''#train_data_by_country = train_data.groupby(['Country_Region'],as_index=True).agg({'ConfirmedCases': 'max', 'Fatalities': 'max'})\n#train_data_by_country_confirm = train_data_by_country.sort_values(by=[\"ConfirmedCases\"], ascending=False)\n\ntrain_data['Date'] = pd.to_datetime(train_data['Date'])\ntrain_data_by_date = train_data.groupby(['Date'],as_index=True).agg({'ConfirmedCases': 'max','Fatalities': 'max', \n                                                                     'NewConfirmedCases':'max', 'NewFatalities':'max'})\n\n## ======= Sort by countries with fatalities > 200 ========\ntrain_data_by_country_fatal = train_data_by_country[train_data_by_country['Fatalities']>200]\ntrain_data_by_country_fatal = train_data_by_country_fatal.sort_values(by=['Fatalities'],ascending=False).reset_index()\n#display(train_data_by_country_fatal.head(20))\n\ndf_merge_by_country = pd.merge(train_data,train_data_by_country_fatal['Country_Region'],on=['Country_Region'],how='inner')\ndf_max_fatality_country = df_merge_by_country.groupby(['Date','Country_Region'],as_index=False).agg({'ConfirmedCases': 'sum',\n                                                                                                     'Fatalities': 'sum',\n                                                                                                     'NewConfirmedCases':'sum',\n                                                                                                     'NewFatalities':'sum'})\n\n\n# convert -ve numbers to zeros, and set Date as new index\nnum = df_max_fatality_country._get_numeric_data() \nnum[num < 0.0] = 0.0\ndf_max_fatality_country.set_index('Date',inplace=True)\n#display(df_max_fatality_country.head(20))\n\ncountries = train_data_by_country_fatal['Country_Region'].unique()''''''\n\n\n   ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def reformat_time(reformat, ax):\n    ax.xaxis.set_major_locator(dates.WeekdayLocator())\n    ax.xaxis.set_major_formatter(dates.DateFormatter('%b %d'))    \n    if reformat: #reformat again if you wish\n        date_list = train_data_by_date.reset_index()[\"Date\"].tolist()\n        x_ticks = [dt.datetime.strftime(t,'%Y-%m-%d') for t in date_list]\n        x_ticks = [tick for i,tick in enumerate(x_ticks) if i%8==0 ]# split labels into same number of ticks as by pandas\n        ax.set_xticklabels(x_ticks, rotation=90)\n    # cosmetics\n    ax.yaxis.grid(linestyle='dotted')\n    ax.spines['right'].set_color('none')\n    ax.spines['top'].set_color('none')\n    ax.spines['left'].set_color('none')\n    ax.spines['bottom'].set_color('none')\n\ntrain_data['Date'] = pd.to_datetime(train_data['Date'])\ntrain_data_by_date = train_data.groupby(['Date'],as_index=True).agg({'ConfirmedCases': 'sum','Fatalities': 'sum', \n                                                                     'NewConfirmedCases':'sum', 'NewFatalities':'sum'})\n#                                             MortalityRate':'mean'\nnum0 = train_data_by_date._get_numeric_data() \nnum0[num0 < 0.0] = 0.0\n#display(train_data_by_date.head())\n\n## ======= Sort by countries with fatalities > 500 ========\n\ntrain_data_by_country_max = train_data.groupby(['Country_Region'],as_index=True).agg({'ConfirmedCases': 'max', 'Fatalities': 'max'})\ntrain_data_by_country_fatal = train_data_by_country_max[train_data_by_country_max['Fatalities']>500]\ntrain_data_by_country_fatal = train_data_by_country_fatal.sort_values(by=['Fatalities'],ascending=False).reset_index()\ndisplay(train_data_by_country_fatal.head(20))\n\ndf_merge_by_country = pd.merge(train_data,train_data_by_country_fatal['Country_Region'],on=['Country_Region'],how='inner')\ndf_max_fatality_country = df_merge_by_country.groupby(['Date','Country_Region'],as_index=False).agg({'ConfirmedCases': 'sum',\n                                                                                                     'Fatalities': 'sum',\n                                                                                                     'NewConfirmedCases':'sum',\n                                                                                                     'NewFatalities':'sum'\n                                                                                                     })\n#                                               MortalityRate':'mean'\n\nnum1 = df_max_fatality_country._get_numeric_data() \nnum1[num1 < 0.0] = 0.0\ndf_max_fatality_country.set_index('Date',inplace=True)\n#display(df_max_fatality_country.head(20))\n\ncountries = train_data_by_country_fatal['Country_Region'].unique()\n\nplt.rcParams.update({'font.size': 16})\n\nfig,(ax0,ax1) = plt.subplots(1,2,figsize=(15, 8))\nfig,(ax2,ax3) = plt.subplots(1,2,figsize=(15, 8))#,sharey=True)\n\ntrain_data_by_date.ConfirmedCases.plot(ax=ax0, x_compat=True, title='Confirmed Cases Globally', legend='Confirmed Cases',\n                                       color=discrete_col)#, logy=True)\nreformat_time(0,ax0)\ntrain_data_by_date.NewConfirmedCases.plot(ax=ax0, x_compat=True, linestyle='dotted', legend='New Confirmed Cases',\n                                          color=discrete_col)#, logy=True)\nreformat_time(0,ax0)\n\ntrain_data_by_date.Fatalities.plot(ax=ax2, x_compat=True, title='Fatalities Globally', legend='Fatalities', color='r')\nreformat_time(0,ax2)\ntrain_data_by_date.NewFatalities.plot(ax=ax2, x_compat=True, linestyle='dotted', legend='Daily Deaths',color='r')#tell pandas not to use its own datetime format\nreformat_time(0,ax2)\n\nfor country in countries:\n    match = df_max_fatality_country.Country_Region==country\n    df_fatality_by_country = df_max_fatality_country[match] \n    df_fatality_by_country.ConfirmedCases.plot(ax=ax1, x_compat=True, title='Cumulative Confirmed Cases Nationally')\n    reformat_time(0,ax1)\n    df_fatality_by_country.Fatalities.plot(ax=ax3, x_compat=True, title='Cumulative Fatalities Nationally')\n    reformat_time(0,ax3)\n    \nax1.legend(countries)\nax3.legend(countries)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import PolynomialFeatures \nfrom sklearn.pipeline import make_pipeline\nfrom tqdm import tqdm\n\nplt.rcParams.update({'font.size': 12})\nfig,(ax0,ax1) = plt.subplots(2,1,figsize=(20, 20))\ncountries_europe = ['Italy', 'France', 'Spain', 'Germany', 'United Kingdom']\n\n# Take the 1st day as 2020-02-23\ndf = train_data.loc[train_data.Date >= '2020-02-23']\nn_days_europe = df.Date.nunique()\n\nfor country in tqdm(countries): \n    df_country_train = df_max_fatality_country[df_max_fatality_country['Country_Region']==country] \n    df_country_test = test_data[test_data['Country_Region']==country]  \n    df_country_train = df_country_train.reset_index()[df_country_train.reset_index().Date > '2020-02-22']\n    \n    x_train = np.arange(1, n_days_europe+1).reshape((-1,1))\n    x_test  = (np.arange(1,n_test_days+1+overlap_days)).reshape((-1,1)) \n    #print (range(n_days_europe))\n    \n    y_train_f = df_country_train['Fatalities']\n    #print(y_train_f)\n    model_f = make_pipeline(PolynomialFeatures(degree=3), Ridge(fit_intercept=False)) \n    model_f = model_f.fit(x_train, y_train_f)\n    y_predict_f = model_f.predict(x_test) \n    \n    y_train_c = df_country_train['ConfirmedCases'] \n    model_c = make_pipeline(PolynomialFeatures(degree=3), Ridge(fit_intercept=False)) \n    model_c = model_c.fit(x_train, y_train_c)\n    y_predict_c = model_c.predict(x_test)\n    \n    ax0.plot(x_test, y_predict_c,linewidth=2, label='predict_'+country)\n    ax0.plot(x_train, y_train_c, linewidth=2, color='r', linestyle='dotted', label='train_'+country)\n    ax0.set_title(\"Prediction vs Training for Confirmed Cases\")\n    ax0.set_xlabel(\"Number of days\")\n    ax0.set_ylabel(\"Confirmed Cases\")\n    ax0.legend(loc='center left',bbox_to_anchor=(1.0, 0.5))\n    \n    ax1.plot(x_test, y_predict_f,linewidth=2, label='predict_'+country)\n    ax1.plot(x_train, y_train_f, linewidth=2, color='r', linestyle='dotted', label='train_'+country)\n    ax1.set_title(\"Prediction vs Training for Fatalities\")\n    ax1.set_xlabel(\"Number of days\")\n    ax1.set_ylabel(\"Fatalities\")\n    ax1.legend(loc='center left',bbox_to_anchor=(1.0, 0.5))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#only selected countries\n#countries= countries[0:9]\nfrom tqdm import tqdm\nfrom scipy.optimize.minpack import curve_fit\nfrom sklearn.metrics import r2_score\nfrom scipy.special import expit\n\ndef Gompertz(a, c, t, t0):    \n    Q = a * np.exp(-np.exp(-c*(t-t0)))\n    return Q\ndef Boltzman(a, c, t, t0):\n    Q = a / (1 + np.exp(-c*(t-t0)))\n    return Q\n\nplt.rcParams.update({'font.size': 12})\nfig,(ax0,ax1) = plt.subplots(2,1,figsize=(20, 20))\n#countries_europe=['US', 'China', 'Iran', 'France', 'Italy', 'Spain', 'Germany', 'Belgium', 'Turkey', 'Netherlands', 'Switzerland', 'United Kingdom']\n#countries_europe=['France']\nfor country in tqdm(countries): \n    #print('\\n\\n\\n\\n country ==>', country)\n    df_country_train = df_max_fatality_country[df_max_fatality_country['Country_Region']==country] \n    df_country_test = test_data[test_data['Country_Region']==country]  \n    if country != 'China':\n        df_country_train = df_country_train.reset_index().loc[df_country_train.reset_index().Date>'2020-02-22'] #17\n        n_days_sans_China =train_data.Date.nunique() - df_country_train.Date.nunique()        \n    else:\n        df_country_train = df_country_train.reset_index()\n        n_days_sans_China = 0\n        \n    n_train_days =df_country_train.Date.nunique()    \n    x_train = range(n_train_days)\n    x_test  = range(n_train_days+n_test_days-overlap_days)#n_test_days+overlap_days)\n    y_train_f = df_country_train['Fatalities']\n    y_train_c = df_country_train['ConfirmedCases']    \n    \n    if country == 'China':\n        lower = [100, 0.02, 0]\n        upper = [2.0*max(y_train_f),0.2, 40]\n    elif country == 'Iran':\n        lower = [200, 0.00, 0]\n        upper = [3.0*max(y_train_f),0.14, 65]\n    elif country == 'Italy':\n        lower = [100, 0.00, 0]\n        upper = [3.5*max(y_train_f),0.15, 72]\n    elif country == 'US':\n        lower = [0, 0.02, 0]\n        upper = [4.0*max(y_train_f),0.22, 83] \n    elif country == 'France':\n        lower = [0, 0.02, 0]\n        upper = [4.0*max(y_train_f),0.18, 82]    \n    elif country == 'Spain':\n        lower = [0, 0.02, 0]\n        upper = [3.5*max(y_train_f),0.18, 75]\n    elif country == 'Germany':\n        lower = [0.0, 0.02, 0]\n        upper = [3.5*max(y_train_f),0.25, 80] \n    elif country == 'Belgium':\n        lower = [0.0, 0.02, 0]\n        upper = [3.5*max(y_train_f),0.25, 80] \n    elif country == 'Turkey':\n        lower = [0.0, 0.02, 0]\n        upper = [4.0*max(y_train_f),0.25, 83]\n    elif country == 'Netherlands':\n        lower = [0.0, 0.02, 0]\n        upper = [4.0*max(y_train_f),0.18, 80] \n    elif country == 'Switzerland':\n        lower = [0.0, 0.02, 0]\n        upper = [4.0*max(y_train_f),0.18, 80] \n    elif country == 'United Kingdom':\n        lower = [0.0, 0.02, 0]\n        upper = [4.5*max(y_train_f),0.25, 85]     \n    else:\n        lower = [0.0, 0.02, 0]\n        upper = [4.5*max(y_train_f),0.25, 80]    \n    \n    popt_f, pcov_f = curve_fit(Gompertz, x_train, y_train_f, method='trf', bounds=(lower,upper))\n    a_max, estimated_c, estimated_t0 = popt_f\n    y_predict_f = Gompertz(a_max, estimated_c, x_test, estimated_t0)\n    y_predict_f_at_t0 =  Gompertz(a_max, estimated_c, estimated_t0, estimated_t0)\n    print(\"\\n\\n\\n\\n\",country,'\\nfatalities ==>, max: ',a_max, ', slope: %.2f'% estimated_c, ', inflection point: ', \n          estimated_t0, ', r2 score: %.2f'% r2_score(y_train_f[:], y_predict_f[0:n_train_days]))\n   \n    ###### Confirmed cases:    \n        \n    if country == 'China':\n        lower_c = [100, 0.02, 0]\n        upper_c = [2.0*max(y_train_c),0.25,30]\n    elif country == 'Iran':\n        lower_c = [100, 0.00, 0]\n        upper_c = [3.0*max(y_train_c),0.15,65]\n    elif country == 'Italy':\n        lower_c = [1000, 0.00, 0]\n        upper_c = [3.0*max(y_train_c),0.15, 64]\n    elif country == 'US':\n        lower_c = [0, 0.02, 0]\n        upper_c = [3.5*max(y_train_c),0.23, 78] \n    elif country == 'France':\n        lower_c = [10, 0.02, 0]\n        upper_c = [4.5*max(y_train_c),0.15, 85]\n    elif country == 'Spain':\n        lower_c = [10, 0.02, 0]\n        upper_c = [3.5*max(y_train_c),0.15, 74] \n    elif country == 'Germany':\n        lower_c = [10, 0.02, 0]\n        upper_c = [3.5*max(y_train_c),0.15, 75] \n    elif country == 'Belgium':\n        lower_c = [100, 0.02, 0]\n        upper_c = [4.0*max(y_train_c),0.15, 80]\n    elif country == 'Turkey':\n        lower_c = [100, 0.02, 0]\n        upper_c = [4.0*max(y_train_c),0.25, 83] \n    elif country == 'Netherlands':\n        lower_c = [100, 0.02, 0]\n        upper_c = [4.0*max(y_train_c),0.14, 78] \n    elif country == 'Switzerland':\n        lower_c = [100, 0.02, 0]\n        upper_c = [3.5*max(y_train_c),0.14, 70]  \n    elif country == 'United Kingdom':\n        lower_c = [100, 0.02, 0]\n        upper_c = [4.5*max(y_train_c),0.15, 85]    \n    else:\n        lower_c = [100, 0.02, 0]\n        upper_c = [4.5*max(y_train_c),0.15, 80]\n        \n    \n    popt_c, pcov_c = curve_fit(Gompertz, x_train, y_train_c, method='trf', bounds=(lower_c,upper_c))\n    a_max_c, estimated_c_c, estimated_t0_c = popt_c\n    y_predict_c = Gompertz(a_max_c, estimated_c_c, x_test, estimated_t0_c)\n    y_predict_c_at_t0 =  Gompertz(a_max_c, estimated_c_c, estimated_t0_c, estimated_t0_c)\n    print('confirmed ==> max: ',a_max_c, ', slope: %.2f'% estimated_c_c, ', inflection point: ', \n          estimated_t0_c, ', r2 score: %.2f'% r2_score(y_train_c[:], y_predict_c[0:n_train_days]))\n    \n    ## ===== Move the x-axis of trained and test datasets to allign with dates in China ======\n    extend_days_test = [i+len(x_test) for i in range(n_days_sans_China)]\n    x_test      = np.append(x_test, extend_days_test) \n    y_predict_c = np.pad(y_predict_c, (n_days_sans_China, 0), 'constant')\n    y_predict_f = np.pad(y_predict_f, (n_days_sans_China, 0), 'constant')\n    inflection_c = estimated_t0_c+n_days_sans_China\n\n    extend_days_train = [i+len(x_train) for i in range(n_days_sans_China)]\n    x_train     = np.append(x_train, extend_days_train)\n    y_train_c   = np.pad(y_train_c, (n_days_sans_China, 0), 'constant')\n    y_train_f   = np.pad(y_train_f, (n_days_sans_China, 0), 'constant')\n    inflection_f = estimated_t0+n_days_sans_China\n    \n    ## ===== Plot =======\n    ax0.plot(x_test, y_predict_c, linewidth=2, label='predict_'+country) \n    ax0.plot(inflection_c, y_predict_c_at_t0, marker='o', markersize=6, color='green')#, label='inflection')\n    ax0.plot(x_train, y_train_c, linewidth=2, color='r', linestyle='dotted', label='train_'+country)   \n    ax0.set_title(\"Prediction vs Training for Confirmed Cases\")\n    ax0.set_xlabel(\"Number of days\")\n    ax0.set_ylabel(\"Confirmed Cases\")\n    ax0.legend(loc='center left',bbox_to_anchor=(1.0, 0.5))\n    \n    \n    ax1.plot(x_test, y_predict_f, linewidth=2, label='predict_'+country) \n    ax1.plot(inflection_f, y_predict_f_at_t0, marker='o', markersize=6, color='green')\n    ax1.plot(x_train, y_train_f, linewidth=2, color='r', linestyle='dotted', label='train_'+country)    \n    ax1.set_title(\"Prediction vs Training for Fatalities\")\n    ax1.set_xlabel(\"Number of days\")\n    ax1.set_ylabel(\"Fatalities\")\n    ax1.legend(loc='center left',bbox_to_anchor=(1.0, 0.5))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## **3.3. Final submission using Gompertz model**"},{"metadata":{"trusted":true,"_kg_hide-output":true},"cell_type":"code","source":"nCountries= train_data['Country_Region'].unique() \nisState = bool\n\ndef get_bounds_fatal (country, isState, y_train):\n    maximum = max(y_train)\n    if maximum == 0.0: maximum = 1.0 \n\n    if country == 'China':\n        lower = [0.0, 0.02, 0]\n        upper = [2.0*maximum,0.2, 40]\n    elif country == 'Iran':\n        lower = [200, 0.00, 0]\n        upper = [3.0*maximum,0.14, 65]\n    elif country == 'Italy':\n        lower = [100, 0.00, 0]\n        upper = [3.5*maximum,0.15, 70]\n    elif country == 'US':\n        lower = [0, 0.02, 0]\n        if maximum <=10:upper = [4.0*maximum, 0.30, 85] \n        else:           upper = [4.0*maximum,0.23, 85] \n    elif country == 'France':\n        lower = [0, 0.02, 0]\n        if maximum <=10:upper = [4.0*maximum,0.18, 80]\n        else:           upper = [4.0*maximum,0.18, 80] \n    elif country == 'Spain':\n        lower = [0, 0.02, 0]\n        upper = [3.5*maximum,0.18, 75]\n    elif country == 'Germany':\n        lower = [0.0, 0.02, 0]\n        upper = [3.5*maximum,0.25, 80] \n    elif country == 'Belgium':\n        lower = [0.0, 0.02, 0]\n        upper = [3.5*maximum,0.25, 80] \n    elif country == 'Turkey':\n        lower = [0.0, 0.02, 0]\n        upper = [4.0*maximum,0.25, 83]\n    elif country == 'Netherlands':\n        lower = [0.0, 0.02, 0]\n        upper = [4.0*maximum,0.18, 80] \n    elif country == 'Switzerland':\n        lower = [0.0, 0.02, 0]\n        upper = [4.0*maximum,0.18, 80] \n    elif country == 'United Kingdom':\n        lower = [0.0, 0.02, 0]\n        upper = [4.5*maximum,0.25, 85] \n    elif country == 'Denmark':\n        lower = [0, 0.02, 0]\n        if maximum <=10:upper = [4.0*maximum, 0.30, 80] \n        else:           upper = [4.0*maximum,0.23, 80]  \n    elif country == 'Australia':\n        lower = [0, 0.02, 0]\n        if maximum <=10: upper = [2.0*maximum, 0.20, 45] \n        else:            upper = [2.5*maximum,0.20, 65]  \n    elif country == 'Canada':\n        lower = [0, 0.02, 0]\n        if maximum <=10: upper = [2.0*maximum, 0.20, 65] \n        else:            upper = [3.5*maximum, 0.30, 80] \n    elif country == 'Pakistan':\n        lower = [0.0, 0.02, 0] \n        upper = [4.5*maximum,0.20,85]   \n    elif country == 'India':\n        lower = [0.0, 0.02, 0] \n        upper = [4.5*maximum,0.25,85]       \n    else:\n        lower = [0.0, 0.02, 0] \n        if isState:\n            if maximum <=10:upper = [4.0*maximum,0.30,80] \n            else:           upper = [4.5*maximum,0.15,80]\n        else: \n            if maximum <=10:upper = [4.0*maximum,0.60,85] \n            else:           upper = [4.5*maximum,0.25,85]    \n    return lower, upper \n\ndef get_bounds_confirm (country, isState, y_train):\n    maximum = max(y_train)\n    if maximum == 0.0: maximum = 1.0\n\n    if country == 'China':\n        lower_c = [0, 0.02, 0]\n        upper_c = [2.0*maximum,0.25,30]\n    elif country == 'Iran':\n        lower_c = [100, 0.00, 0]\n        upper_c = [3.0*maximum,0.15,65]\n    elif country == 'Italy':\n        lower_c = [1000, 0.00, 0]\n        upper_c = [3.0*maximum,0.15, 64]\n    elif country == 'US':\n        lower_c = [0, 0.02, 0]\n        if maximum <=10:upper_c = [4.0*maximum, 0.30, 80] \n        else:           upper_c = [3.5*maximum, 0.23, 78] \n    elif country == 'France':\n        lower_c = [10, 0.02, 0]\n        if maximum <=10:upper_c = [4.0*maximum, 0.15, 80] \n        else:           upper_c = [4.5*maximum, 0.15, 80] \n    elif country == 'Spain':\n        lower_c = [10, 0.02, 0]\n        upper_c = [3.5*maximum,0.15, 74] \n    elif country == 'Germany':\n        lower_c = [10, 0.02, 0]\n        upper_c = [3.5*maximum,0.15, 75] \n    elif country == 'Belgium':\n        lower_c = [100, 0.02, 0]\n        upper_c = [4.0*maximum,0.15, 80]\n    elif country == 'Turkey':\n        lower_c = [100, 0.02, 0]\n        upper_c = [4.0*maximum,0.25, 83] \n    elif country == 'Netherlands':\n        lower_c = [0.0, 0.02, 0]\n        upper_c = [4.0*maximum,0.14, 78] \n    elif country == 'Switzerland':\n        lower_c = [100, 0.02, 0]\n        upper_c = [3.5*maximum,0.14, 70] \n    elif country == 'United Kingdom':\n        lower_c = [0.0, 0.02, 0]\n        upper_c = [4.5*maximum,0.15, 85] \n    elif country == 'Denmark':\n        lower_c = [0, 0.02, 0]\n        if maximum <=10: upper_c = [2.0*maximum, 0.30, 40] \n        else:            upper_c = [2.5*maximum,0.30, 55]   \n    elif country == 'Australia':\n        lower_c = [0, 0.02, 0]\n        if maximum <=10: upper_c = [2.0*maximum, 0.25, 45] \n        else:            upper_c = [2.5*maximum,0.25, 65]  \n    elif country == 'Canada':\n        lower_c = [0, 0.02, 0]\n        if maximum <=10: upper_c = [3.0*maximum, 0.28, 75] \n        else:            upper_c = [3.5*maximum,0.28, 80]\n    elif country == 'Pakistan':\n        lower_c = [0.0, 0.02, 0] \n        upper_c = [4.5*maximum,0.15,85] \n    elif country == 'India':\n        lower_c = [0.0, 0.02, 0] \n        upper_c = [4.5*maximum,0.20,85]     \n    else:\n        lower_c = [0.0, 0.02, 0] \n        if isState:\n            if maximum <= 200: upper_c = [2.0*maximum,0.20,80] \n            else:              upper_c = [4.5*maximum,0.20,80]\n        else:  \n            if maximum <= 200: upper_c = [3.0*maximum,0.20,85]  \n            else:              upper_c = [4.5*maximum,0.15,80]    \n    return lower_c, upper_c \n\n#nCountries = ['United Kingdom']  \nx_train = range(n_train_days)\nx_test  = range(n_train_days+n_test_days-overlap_days)\n\nfor country in tqdm(nCountries): \n    fig,(ax0,ax1) = plt.subplots(2,1,figsize=(20, 20))\n    #print('\\n\\n\\n\\n country ==>', country) \n    \n    df_country_train = train_data[train_data['Country_Region']==country] \n    df_country_test = test_data[test_data['Country_Region']==country]  \n    \n    if country != 'China':\n        df_country_train = df_country_train.reset_index().loc[df_country_train.reset_index().Date>'2020-02-22'] #17\n        n_days_sans_China =train_data.Date.nunique() - df_country_train.Date.nunique()        \n    else:\n        df_country_train = df_country_train.reset_index()\n        n_days_sans_China = 0\n        \n    n_train_days =df_country_train.Date.nunique()    \n    x_train = range(n_train_days)\n    x_test  = range(n_train_days+n_test_days-overlap_days)   \n    nvalues = df_country_train['Province_State'].isna().nunique() #fix for problem with Denmark data\n    \n    if (df_country_train['Province_State'].isna().unique()==True).any() and nvalues<2: \n        isState = False        \n        y_train_f = df_country_train['Fatalities']\n        y_train_c = df_country_train['ConfirmedCases']  \n        \n        if y_train_f.empty == False:\n            lower, upper = get_bounds_fatal (country, isState, y_train_f)\n            popt_f, pcov_f = curve_fit(Gompertz, x_train, y_train_f, method='trf', bounds=(lower,upper))\n            a_max, estimated_c, estimated_t0 = popt_f\n            y_predict_f = Gompertz(a_max, estimated_c, x_test, estimated_t0)            \n            #print('\\nfatalities ==>, max: ',a_max, ', slope: %.2f'% estimated_c, ', inflection point: ', \n             #     estimated_t0, ', r2 score: %.2f'% r2_score(y_train_f[:], y_predict_f[0:n_train_days]))\n            \n            \n        if y_train_c.empty == False:  \n            lower_c, upper_c = get_bounds_confirm (country, isState, y_train_c)\n            popt_c, pcov_c = curve_fit(Gompertz, x_train, y_train_c, method='trf', bounds=(lower_c,upper_c))\n            a_max_c, estimated_c_c, estimated_t0_c = popt_c\n            y_predict_c = Gompertz(a_max_c, estimated_c_c, x_test, estimated_t0_c)\n            #print('\\nconfirmed ==> max: ',a_max_c, ', slope: %.2f'% estimated_c_c, ', inflection point: ', \n             #     estimated_t0_c, ', r2 score: %.2f'% r2_score(y_train_c[:], y_predict_c[0:n_train_days]))\n            \n            \n        ## ===== Move the x-axis of trained and test datasets to allign with dates in China ======\n        extend_days_test = [i+len(x_test) for i in range(n_days_sans_China)]\n        x_test      = np.append(x_test, extend_days_test)                         \n        y_predict_c = np.pad(y_predict_c, (n_days_sans_China, 0), 'constant') \n        y_predict_f = np.pad(y_predict_f, (n_days_sans_China, 0), 'constant')\n        inflection_f = estimated_t0+n_days_sans_China\n            \n        extend_days_train = [i+len(x_train) for i in range(n_days_sans_China)]\n        x_train     = np.append(x_train, extend_days_train)           \n        y_train_c   = np.pad(y_train_c, (n_days_sans_China, 0), 'constant')\n        y_train_f   = np.pad(y_train_f, (n_days_sans_China, 0), 'constant')\n        inflection_c = estimated_t0_c+n_days_sans_China           \n        \n        ax0.plot(x_test, y_predict_c, linewidth=2, label='predict_'+country) \n        ax0.plot(x_train, y_train_c, linewidth=2, color='r', linestyle='dotted', label='train_'+country)\n        ax0.set_title(\"Prediction vs Training for Confirmed Cases\")\n        ax0.set_xlabel(\"Number of days\")\n        ax0.set_ylabel(\"Confirmed Cases\")\n        ax0.legend()\n        test_data.loc[test_data['Country_Region']==country,'ConfirmedCases'] = y_predict_c[-n_test_days:]\n        \n        ax1.plot(x_test, y_predict_f, linewidth=2, label='predict_'+country) \n        ax1.plot(x_train, y_train_f, linewidth=2, color='r', linestyle='dotted', label='train_'+country)    \n        ax1.set_title(\"Prediction vs Training for Fatalities\")\n        ax1.set_xlabel(\"Number of days\")\n        ax1.set_ylabel(\"Fatalities\")\n        ax1.legend()\n        test_data.loc[test_data['Country_Region']==country,'Fatalities'] = y_predict_f[-n_test_days:]             \n    else: # use Province/State data when available\n        isState = True\n        state_list = []\n        y_predict_c_dict = {}; y_train_c_dict = {}\n        y_predict_f_dict = {}; y_train_f_dict = {}\n        for state in df_country_train['Province_State'].unique():\n            df_state_train = df_country_train[df_country_train['Province_State']==state] \n            df_state_test = df_country_test[df_country_test['Province_State']==state]   \n            state_list.append(state)\n            y_train_f = df_state_train['Fatalities']\n            y_train_c = df_state_train['ConfirmedCases']   \n            \n            if y_train_f.empty== False:                 \n                lower, upper = get_bounds_fatal (country, isState, y_train_f)\n                popt_f, pcov_f = curve_fit(Gompertz, x_train, y_train_f, method='trf', bounds=(lower,upper))\n                a_max, estimated_c, estimated_t0 = popt_f\n                y_predict_f = Gompertz(a_max, estimated_c, x_test, estimated_t0) \n                y_predict_f_dict[state] =  y_predict_f\n                y_train_f_dict[state]   =  y_train_f                \n                #print('\\nfatalities state ==>, max: ',a_max, ', slope: %.2f'% estimated_c, ', inflection point: ', \n                #    estimated_t0, ', r2 score: %.2f'% r2_score(y_train_f[:], y_predict_f[0:70]))                     \n                                \n            if y_train_c.empty == False:  \n                lower_c, upper_c = get_bounds_confirm (country, isState, y_train_c)\n                popt_c, pcov_c = curve_fit(Gompertz, x_train, y_train_c, method='trf', bounds=(lower_c,upper_c))\n                a_max_c, estimated_c_c, estimated_t0_c = popt_c\n                y_predict_c = Gompertz(a_max_c, estimated_c_c, x_test, estimated_t0_c)\n                y_predict_c_dict[state] =  y_predict_c\n                y_train_c_dict[state]   =  y_train_c\n                #print('\\nconfirmed state ==> max: ',a_max_c, ', slope: %.2f'% estimated_c_c, ', inflection point: ', \n                #  estimated_t0_c, ', r2 score: %.2f'% r2_score(y_train_c[:], y_predict_c[0:70]))\n                            \n        ## ====== Plot and Store the Results: ======\n        ## ====== Move the x-axis of trained and test datasets to allign with dates in China ======       \n        extend_days_test = [i+len(x_test) for i in range(n_days_sans_China)]\n        x_test      = np.append(x_test, extend_days_test) \n        extend_days_train = [i+len(x_train) for i in range(n_days_sans_China)]\n        x_train     = np.append(x_train, extend_days_train)           \n            \n        for state, y_predict in y_predict_f_dict.items():\n            y_predict = np.pad(y_predict, (n_days_sans_China, 0), 'constant') \n            ax1.plot(x_test, y_predict, linewidth=2, label=state) \n            #ax1.legend(loc='center left',bbox_to_anchor=(1.0, 0.5)) \n            test_data.loc[(test_data['Country_Region']==country)&(test_data['Province_State']==state),'Fatalities'] = y_predict[-n_test_days:]\n        for state, y_train in y_train_f_dict.items():\n            y_train   = np.pad(y_train, (n_days_sans_China, 0), 'constant')\n            ax1.plot(x_train, y_train, linewidth=2, color='r', linestyle='dotted', label='train_'+state)             \n        ax1.set_title(\"Prediction vs Training for Fatalities\")\n        ax1.set_xlabel(\"Number of days\")\n        ax1.set_ylabel(\"Fatalities\")   \n        \n        \n        for state, y_predict in y_predict_c_dict.items():\n            y_predict = np.pad(y_predict, (n_days_sans_China, 0), 'constant') \n            ax0.plot(x_test, y_predict, linewidth=2, label=state) \n            ax0.legend(loc='center left',bbox_to_anchor=(1.0, 0.5)) \n            test_data.loc[(test_data['Country_Region']==country)&(test_data['Province_State']==state),'ConfirmedCases'] = y_predict[-n_test_days:]\n        for state, y_train in y_train_c_dict.items():\n            y_train   = np.pad(y_train, (n_days_sans_China, 0), 'constant')\n            ax0.plot(x_train, y_train, linewidth=2, color='r', linestyle='dotted', label='train_'+country+'_'+state)             \n        ax0.set_title(\"Prediction vs Training for ConfirmedCases\")\n        ax0.set_xlabel(\"Number of days\")\n        ax0.set_ylabel(\"Confirmed Cases\")   \n        ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submit_data = pd.read_csv(\"../input/covid19-global-forecasting-week-4/submission.csv\")#, index_col=0)\n\ntest_data['Fatalities'] = test_data['Fatalities'].fillna(0.0).astype(int)\ntest_data['ConfirmedCases'] = test_data['ConfirmedCases'].fillna(0.0).astype(int)\n\n#submit_data['Country_Region'] = test_data['Country_Region']\n#submit_data['Date'] = test_data['Date']\nsubmit_data['Fatalities'] = test_data['Fatalities'].astype('int')\nsubmit_data['ConfirmedCases'] = test_data['ConfirmedCases'].astype('int')\n\nsubmit_data.to_csv('submission.csv', index=False)\n\n#submit_data = submit_data[['Date','Country_Region','ConfirmedCases', 'Fatalities']]\nsubmit_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submit_data_1 = submit_data.groupby('Country_Region')[['ConfirmedCases', 'Fatalities']].sum().reset_index()\nsubmit_data.to_csv('prova.csv', index=False)\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"select_countries [\"US\"] = submit_data_1[(submit_data_1['Country_Region'] == 'US')]\nselect_countries","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **4. NLTK Sentiment Analysis** <a id=\"section4\"></a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"from IPython import display\nimport math\nfrom pprint import pprint\nimport nltk\nimport seaborn as sns\nsns.set(style='darkgrid', context='talk', palette='Dark2')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"BN = pd.read_csv(\"../input/twitter-covid19/BreakingNews.csv\")\nCNN = pd.read_csv(\"../input/twitter-covid19/cnn.csv\")\nNYT = pd.read_csv(\"../input/twitter-covid19/NYT.csv\")\n\nframes = [BN,CNN,NYT]\nnews = pd.concat(frames)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nlabels = news.username.unique()\nsizes = news.username.value_counts()\nexplode = (0.1, 0, 0)\nfig, ax = plt.subplots()\nax.pie(sizes, labels=labels, autopct='%.1f%%', shadow=True, startangle=90)\nax.set_aspect('equal')\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"text = news.text\n\nfrom nltk.sentiment.vader import SentimentIntensityAnalyzer as SIA\n\nsia = SIA()\nresults = []\n\nfor line in text:\n    pol_score = sia.polarity_scores(line)\n    pol_score['text'] = line\n    results.append(pol_score)\n\npprint(results[:3], width=100)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.DataFrame.from_records(results)\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['label'] = 0\ndf.loc[df['compound'] > 0.2, 'label'] = 1\ndf.loc[df['compound'] < -0.2, 'label'] = -1\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df2 = df[['text', 'label']]\ndf.label.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Positive news:\\n\")\npprint(list(df[df['label'] == 1].text)[:5], width=200)\n\nprint(\"\\nNegative news:\\n\")\npprint(list(df[df['label'] == -1].text)[:5], width=200)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.label.value_counts(normalize=True) * 100","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(8, 8))\n\ncounts = df.label.value_counts(normalize=True) * 100\n\nsns.barplot(x=counts.index, y=counts, ax=ax)\n\nax.set_xticklabels(['Negative', 'Neutral', 'Positive'])\nax.set_ylabel(\"Percentage\")\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import nltk\nfrom nltk.tokenize import word_tokenize, RegexpTokenizer\nfrom nltk.corpus import stopwords\ntokenizer = RegexpTokenizer(r'\\w+')\nstop_words = stopwords.words('english')\n\ndef process_text(headlines):\n    tokens = []\n    for line in headlines:\n        line = line.lower()\n        toks = tokenizer.tokenize(line)\n        toks = [t for t in toks if t not in stop_words]\n        tokens.extend(toks)\n    \n    return tokens","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pos_lines = list(df[df.label == 1].text)\n\npos_tokens = process_text(pos_lines)\npos_freq = nltk.FreqDist(pos_tokens)\n\npos_freq.most_common(20)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from wordcloud import WordCloud,STOPWORDS\ndf_pos = df[df.label == 1].text\ndf_neg = df[df.label == -1].text\n\ndef wordcloud_draw(data, color = 'black'):\n    words = ' '.join(data)\n    cleaned_word = \" \".join([word for word in words.split()\n                            if 'http' not in word\n                                and not word.startswith('@')\n                                and not word.startswith('#')\n                                and word != 'RT'\n                            ])\n    wordcloud = WordCloud(stopwords=STOPWORDS,\n                      background_color=color,\n                      width=2500,\n                      height=2000\n                     ).generate(cleaned_word)\n    plt.figure(1,figsize=(13, 13))\n    plt.imshow(wordcloud)\n    plt.axis('off')\n    plt.show()\n    \nprint(\"Positive words\")\nwordcloud_draw(df_pos,'white')\nprint(\"Negative words\")\nwordcloud_draw(df_neg)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}